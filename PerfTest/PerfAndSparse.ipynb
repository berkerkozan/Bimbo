{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import nltk.corpus\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import datasets, linear_model\n",
    "import scipy.sparse as sps\n",
    "from scipy.sparse import coo_matrix, hstack, vstack, csr_matrix\n",
    "from scipy import io\n",
    "from datetime import datetime\n",
    "import gc\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have to load it everytime..Stupid.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ../Library/LoggingForIPython.py\n",
    "def printIpython(data,head=5,level=1):\n",
    "    '''Level = 1,2,3,4 -> 4 is print everything'''\n",
    "    currentLevel = 2\n",
    "    if(level <= currentLevel ):\n",
    "        print data.head(head),'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def myPrint(data,head=5,level=1):\n",
    "    '''Level = 1,2,3,4 -> 4 is print everything'''\n",
    "    currentLevel = 2\n",
    "    if(level <= currentLevel ):\n",
    "        print data.head(3),'\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Log..Delete.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename='mylog.log', mode='a')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "logging.error('hello!')\n",
    "logging.debug('This is a debug message')\n",
    "logging.info('this is an info message')\n",
    "logging.warning('tbllalfhldfhd, warning.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Products.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Producto_ID                          NombreProducto\n",
      "0            0                       NO IDENTIFICADO 0\n",
      "1            9               Capuccino Moka 750g NES 9\n",
      "2           41  Bimbollos Ext sAjonjoli 6p 480g BIM 41 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>brand</th>\n",
       "      <th>weight</th>\n",
       "      <th>pieces</th>\n",
       "      <th>short_name_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>NES</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>capuccin mok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>BIM</td>\n",
       "      <td>480.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>bimboll ext sajonjoli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>LON</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>burrit sincr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>TR</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>div tir mini doradit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73</td>\n",
       "      <td>BIM</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pan multigran linaz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Producto_ID brand  weight  pieces   short_name_processed\n",
       "1            9   NES   750.0     1.0           capuccin mok\n",
       "2           41   BIM   480.0     6.0  bimboll ext sajonjoli\n",
       "3           53   LON   170.0     1.0           burrit sincr\n",
       "4           72    TR    45.0     4.0   div tir mini doradit\n",
       "5           73   BIM   540.0     1.0    pan multigran linaz"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All columns can fit one line..\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "\n",
    "products = pd.read_csv(\"../../input/producto_tabla.csv\")\n",
    "myPrint(products,3,2)\n",
    "products['short_name'] = products.NombreProducto.str.extract('^(\\D*)', expand=True)\n",
    "myPrint(products,3,4)\n",
    "products['brand'] = products.NombreProducto.str.extract('^.+\\s(\\D+) \\d+$', expand=False)\n",
    "myPrint(products,3,4)\n",
    "w = products.NombreProducto.str.extract('(\\d+)(Kg|g)', expand=True)\n",
    "myPrint(products,3,4)\n",
    "w.head(3)\n",
    "products['weight'] = w[0].astype('float') * w[1].map({'Kg': 1000, 'g': 1})\n",
    "products['pieces'] = products.NombreProducto.str.extract('(\\d+)p ', expand=False).astype('float')\n",
    "myPrint(products,3,4)\n",
    "products['short_name_processed'] = (products['short_name'].map(\n",
    "    lambda x: \" \".join([i for i in x.lower().split() if i not in nltk.corpus.stopwords.words(\"spanish\")])))\n",
    "myPrint(products,3,4)\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "products['short_name_processed'] = (\n",
    "products['short_name_processed'].map(lambda x: \" \".join([stemmer.stem(i) for i in x.lower().split()])))\n",
    "myPrint(products,3,4)\n",
    "products[\"pieces\"].fillna(1, inplace=True)\n",
    "products.drop(0,inplace=True)\n",
    "products.drop([\"short_name\",\"NombreProducto\"],axis=1,inplace=True)\n",
    "products.head(5)\n",
    "#products.isnull().sum()\n",
    "#products[pd.isnull(products).any(1)]\n",
    "products[pd.isnull(products.brand)]\n",
    "products[products.brand == 'BIM']\n",
    "#Temporary solution..\n",
    "products.fillna(products.mean(),inplace=True).head(5)\n",
    "########################################\n",
    "### Find missing values on internet!..\n",
    "###Missing brand is bimbo!!!\n",
    "######################################\n",
    "#print products.shape\n",
    "#print len(products.Producto_ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Semana  Agencia_ID  Canal_ID  Cliente_ID  Producto_ID\n",
      "0       3        1110         7       15766         1212\n",
      "   Semana  Agencia_ID  Canal_ID  Cliente_ID  Producto_ID\n",
      "0      11        4037         1     4639078        35305\n",
      "   Semana  Agencia_ID  Canal_ID  Cliente_ID  Producto_ID\n",
      "0       3        1110         7       15766         1212\n",
      "shape:  (81179715, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>brand</th>\n",
       "      <th>weight</th>\n",
       "      <th>pieces</th>\n",
       "      <th>short_name_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>15766</td>\n",
       "      <td>1212</td>\n",
       "      <td>BIM</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rol canel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>15766</td>\n",
       "      <td>1216</td>\n",
       "      <td>BIM</td>\n",
       "      <td>135.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rol glass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>15766</td>\n",
       "      <td>1238</td>\n",
       "      <td>BIM</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>panquecit got choc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>15766</td>\n",
       "      <td>1240</td>\n",
       "      <td>BIM</td>\n",
       "      <td>125.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>mantec vainill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>15766</td>\n",
       "      <td>1242</td>\n",
       "      <td>BIM</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>donit espolvor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Semana  Agencia_ID  Canal_ID  Cliente_ID  Producto_ID brand  weight  pieces short_name_processed\n",
       "0       3        1110         7       15766         1212   BIM   120.0     2.0            rol canel\n",
       "1       3        1110         7       15766         1216   BIM   135.0     2.0            rol glass\n",
       "2       3        1110         7       15766         1238   BIM   140.0     2.0   panquecit got choc\n",
       "3       3        1110         7       15766         1240   BIM   125.0     4.0       mantec vainill\n",
       "4       3        1110         7       15766         1242   BIM   105.0     6.0       donit espolvor"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train = pd.read_csv('../../input/train_100.csv',dtype={'Semana': np.int8, 'Agencia_ID': np.int32,\n",
    "#'Canal_ID': np.int8,'Ruta_SAK': np.int32,'Cliente_ID': np.int32,'Producto_ID': np.int32\n",
    "#                                    })\n",
    "#test = pd.read_csv('../../input/test_100.csv',dtype={'Semana': np.int8, 'Agencia_ID': np.int32,\n",
    "#'Canal_ID': np.int8,'Ruta_SAK': np.int32,'Cliente_ID': np.int32,'Producto_ID': np.int32\n",
    "#                               })\n",
    "    \n",
    "train = pd.read_csv('../../input/train.csv',usecols=['Semana', 'Agencia_ID', \n",
    "                                                     'Canal_ID', 'Cliente_ID', 'Producto_ID', 'Demanda_uni_equil'])\n",
    "                                                      \n",
    "test = pd.read_csv('../../input/test.csv',usecols=['id', 'Semana', 'Agencia_ID', 'Canal_ID', 'Cliente_ID', 'Producto_ID']\n",
    "                                                      )\n",
    "\n",
    "\n",
    "\n",
    "testIds = test['id']\n",
    "test.drop(['id'],axis = 1,inplace=True)\n",
    "trainY = train['Demanda_uni_equil']\n",
    "trainX = train[test.columns.values]\n",
    "print trainX.head(1)\n",
    "print test.head(1)\n",
    "trainTest = trainX.append(test,ignore_index=True)\n",
    "print trainTest.head(1)\n",
    "print \"shape: \" ,trainTest.shape\n",
    "mergedTrainedTestProduct = trainTest.merge(products,on=\"Producto_ID\",how=\"left\")\n",
    "mergedTrainedTestProduct.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semana                    int64\n",
      "Agencia_ID                int64\n",
      "Canal_ID                  int64\n",
      "Cliente_ID                int64\n",
      "Producto_ID               int64\n",
      "brand                    object\n",
      "weight                  float64\n",
      "pieces                  float64\n",
      "short_name_processed     object\n",
      "dtype: object\n",
      "Semana               int64\n",
      "Agencia_ID           int64\n",
      "Canal_ID             int64\n",
      "Cliente_ID           int64\n",
      "Producto_ID          int64\n",
      "Demanda_uni_equil    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print mergedTrainedTestProduct.dtypes\n",
    "print train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowsize = test.shape[0]\n",
    "\n",
    "del trainTest,test,trainX\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#brand names are single..\n",
    "#print products[\"brand\"][products[\"brand\"].astype(str).map(lambda x:len(x.split()))>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<81179715x542 sparse matrix of type '<type 'numpy.int8'>'\n",
       "\twith 145774286 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mergedTrainedTestProduct = mergedTrainedTestProduct[0:5]\n",
    "\n",
    "\n",
    "#print mergedTrainedTestProduct\n",
    "\n",
    "countvec = CountVectorizer()\n",
    "shortname_sparse =  countvec.fit_transform(mergedTrainedTestProduct.short_name_processed)\n",
    "#print shortname_sparse.toarray()\n",
    "shortname_sparse = shortname_sparse.astype(np.int8)\n",
    "shortname_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brand Dummy Variable.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<81179715x33 sparse matrix of type '<type 'numpy.int8'>'\n",
       "\twith 81179715 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_sparse = countvec.fit_transform(mergedTrainedTestProduct.brand)\n",
    "#print brand_sparse.toarray()\n",
    "brand_sparse = brand_sparse.astype(np.int8)\n",
    "brand_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping unnecessary columns.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Semana', u'Agencia_ID', u'Canal_ID', u'Cliente_ID', u'Producto_ID',\n",
      "       u'brand', u'weight', u'pieces', u'short_name_processed'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 81179715 entries, 0 to 81179714\n",
      "Data columns (total 2 columns):\n",
      "weight    float16\n",
      "pieces    float16\n",
      "dtypes: float16(2)\n",
      "memory usage: 929.0 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>pieces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight  pieces\n",
       "0   120.0     2.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print mergedTrainedTestProduct.columns\n",
    "mergedTrainedTestProduct.drop(mergedTrainedTestProduct.columns[[0,1,2,3,4,5,8]],axis=1,inplace=True)\n",
    "mergedTrainedTestProduct = mergedTrainedTestProduct.astype(np.float16)\n",
    "print mergedTrainedTestProduct.info()\n",
    "mergedTrainedTestProduct.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating traintest data and sparse matrixes as sparse.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mergedTrainedTestProduct_sparse = coo_matrix(mergedTrainedTestProduct)\n",
    "\n",
    "del mergedTrainedTestProduct\n",
    "gc.collect()\n",
    "\n",
    "#mergedTrainedTestProduct_sparse\n",
    "#print fittedmergedTrainedTestProduct.astype(object).tocoo()\n",
    "completeSparseData = hstack((mergedTrainedTestProduct_sparse, shortname_sparse,brand_sparse), format='csr')\n",
    "#print completeSparseData.toarray()\n",
    "completeSparseData\n",
    "io.mmwrite(\"../../sparse/completeSparseData.mtx\", completeSparseData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del  shortname_sparse, brand_sparse\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if indexing doesn't work after merging, use below but looks like slow..\n",
    "## But, we shouldn't drop semana column, it's working like if semana > 9, it is test.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Use if necessary!!..\n",
    "#print completeSparseData.toarray()\n",
    "#print (completeSparseData[:,0]>9).toarray()\n",
    "#indices = np.where((completeSparseData[:,0]>9).toarray())[0]\n",
    "#indices\n",
    "#completeSparseData[indices,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print completeSparseData.toarray(), \"\\n\"\n",
    "train_sparse = completeSparseData[0:train.shape[0]]\n",
    "test_sparse = completeSparseData[train.shape[0]:]\n",
    "#print train_sparse.get_shape()\n",
    "test_sparse\n",
    "io.mmwrite(\"../../sparse/test_sparse.mtx\", test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del completeSparseData\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root mean square logarithmic square evaluation function.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle_eval(y, y0):\n",
    "    y0=y0.get_label()    \n",
    "    assert len(y) == len(y0)\n",
    "    return 'error',np.sqrt(np.mean(np.power(np.log1p(y)-np.log1p(y0), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until train error hasn't decreased in 20 rounds.\n",
      "[0]\ttrain-error:1.364675\n",
      "[10]\ttrain-error:0.916528\n",
      "[20]\ttrain-error:0.790882\n",
      "[30]\ttrain-error:0.765360\n",
      "[40]\ttrain-error:0.770126\n",
      "[50]\ttrain-error:0.783478\n",
      "Stopping. Best iteration:\n",
      "[32]\ttrain-error:0.764680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "params = {}\n",
    "params['objective'] = \"reg:linear\"\n",
    "params['eta'] = 0.1\n",
    "params['max_depth'] = 5\n",
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 0.6\n",
    "params['silent'] = True\n",
    "\n",
    "test_preds = np.zeros(rowsize)\n",
    "\n",
    "xg_train = xgb.DMatrix(train_sparse, label=trainY)\n",
    "xg_test = xgb.DMatrix(test_sparse)\n",
    "\n",
    "del train_sparse,test_sparse,trainY\n",
    "gc.collect()\n",
    "\n",
    "watchlist = [(xg_train, 'train')]\n",
    "num_rounds = 100\n",
    "\n",
    "\n",
    "xgclassifier = xgb.train( params, xg_train, num_rounds, watchlist, feval = rmsle_eval, \n",
    "                         early_stopping_rounds= 20, verbose_eval = 10)\n",
    "#fold_preds = np.around(xgclassifier.predict(xg_test, ntree_limit=xgclassifier.best_iteration))\n",
    "fold_preds = np.rint(xgclassifier.predict(xg_test, ntree_limit=xgclassifier.best_iteration))\n",
    "\n",
    "test_preds += fold_preds\n",
    "\n",
    "submission = pd.DataFrame({'id':testIds, 'Demanda_uni_equil': test_preds})\n",
    "submission[[\"id\",\"Demanda_uni_equil\"]].to_csv('../../submissions/' + \n",
    "                                              datetime.now().strftime('%Y-%m-%d-%H-%M-%S') +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6999251 entries, 0 to 6999250\n",
      "Data columns (total 2 columns):\n",
      "Demanda_uni_equil    float64\n",
      "id                   int64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 106.8 MB\n"
     ]
    }
   ],
   "source": [
    "submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
