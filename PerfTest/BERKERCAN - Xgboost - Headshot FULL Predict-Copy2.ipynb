{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.datasets import load_iris, load_digits, load_boston\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
    "from collections import OrderedDict\n",
    "import gc\n",
    "from sklearn import datasets, linear_model,preprocessing\n",
    "from IPython.display import display, HTML\n",
    "import time\n",
    "import nltk.corpus\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSE(y_true,y_pred):\n",
    "    mse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print 'MSE: %2.3f' % mse\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take 1 CSV, then split it to 3..\n",
    "class FeatureEngineering:\n",
    "\n",
    "    def __init__(self, ValidationStart, ValidationEnd, trainHdfPath, trainHdfFile, testHdfPath1, testHdfPath2, testHdfFile, \n",
    "                 testTypes, trainTypes, trainCsvPath, testCsvPath, maxLag=0):\n",
    "        self.ValidationStart = ValidationStart\n",
    "        self.ValidationEnd = ValidationEnd\n",
    "        self.maxLag = maxLag\n",
    "        self.trainHdfPath = trainHdfPath\n",
    "        self.trainHdfFile = trainHdfFile\n",
    "        self.testHdfPath1 = testHdfPath1\n",
    "        self.testHdfPath2 = testHdfPath2\n",
    "        self.testHdfFile = testHdfFile\n",
    "        self.testTypes = testTypes\n",
    "        self.trainTypes = trainTypes\n",
    "        self.trainCsvPath = trainCsvPath\n",
    "        self.testCsvPath = testCsvPath\n",
    "        \n",
    "    @staticmethod\n",
    "    def __printDataFrameBasics__(data):\n",
    "        display(data.head(2))\n",
    "        #print data.dtypes\n",
    "        gc.collect()\n",
    "        print(data.info(memory_usage=True))\n",
    "        \n",
    "    @staticmethod    \n",
    "    def changeIndexTypeToLowerMemory(data):\n",
    "        ##########\n",
    "        #This is very critical, i accept max number is 2^32. Also, if don't do that, memory gets so much higher..\n",
    "        ##########\n",
    "        #data.reset_index(inplace=True)\n",
    "        #data.drop(\"index\",axis=1, inplace=True)\n",
    "        #data.index = data.index.astype('uint32')\n",
    "        gc.collect()\n",
    "        \n",
    "    def ReadHdf(self, trainOrTestOrBoth):\n",
    "        '''Reads and holds Df in object memory'''            \n",
    "        if trainOrTestOrBoth == 'train' or trainOrTestOrBoth=='both':\n",
    "            self.train = pd.read_hdf(self.trainHdfPath,self.trainHdfFile)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.train)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.train)\n",
    "            \n",
    "        if trainOrTestOrBoth == 'test' or trainOrTestOrBoth=='both':\n",
    "            self.test1 = pd.read_hdf(self.testHdfPath1,self.testHdfFile)\n",
    "            self.test2 = pd.read_hdf(self.testHdfPath2,self.testHdfFile)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.test1)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.test2)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test1)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test2)\n",
    "        \n",
    "    def ReadCsv(self, trainOrTestOrBoth):\n",
    "        '''Reads and holds Df in memory'''\n",
    "        if trainOrTestOrBoth == 'train' or trainOrTestOrBoth == 'both':\n",
    "            self.train = pd.read_csv(self.trainCsvPath, usecols=self.trainTypes.keys(), dtype=self.trainTypes)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.train)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.train)\n",
    "        if trainOrTestOrBoth == 'test' or trainOrTestOrBoth=='both':\n",
    "            tempTest = pd.read_csv(self.testCsvPath, usecols=self.testTypes.keys(), dtype=self.testTypes)\n",
    "            self.test1 = tempTest.loc[tempTest.Semana.values == self.ValidationStart]\n",
    "            self.test2 = tempTest.loc[tempTest.Semana.values == self.ValidationEnd]\n",
    "            del tempTest\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.test1)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.test2)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test1)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test2)\n",
    "            \n",
    "    @staticmethod\n",
    "    def ConvertCsvToHdf(csvPath, HdfPath, HdfName, ColumnTypeDict ):\n",
    "        tempDf = pd.read_csv(csvPath, usecols=ColumnTypeDict.keys(), dtype=ColumnTypeDict,index=False)\n",
    "        tempDf.to_hdf(HdfPath, HdfName, format='t')\n",
    "        del tempDf\n",
    "        gc.collect()\n",
    "        print \"ConvertCsvToHdf is done..\"\n",
    "\n",
    "    def Preprocess(self, trainOrTestOrBoth, columnFunctionTypeList):\n",
    "        '''columnFunctionTypeList = [ ['C1',Func1,Type], ['C2',Func2,Type],..    ]'''\n",
    "        for column, func, localType in columnFunctionTypeList:\n",
    "            if trainOrTestOrBoth == 'train' or trainOrTestOrBoth =='both':\n",
    "                self.train.loc[:,column] =  np.apply_along_axis(func,0,FE.train[column].values).astype(localType)\n",
    "                #np.apply_along_axis(lambda x: x+1,0,FE.train[\"Semana\"]).astype(\"int32\")\n",
    "            if trainOrTestOrBoth == 'test' or trainOrTestOrBoth == 'both':\n",
    "                self.test1.loc[:,column] =  np.apply_along_axis(func,0,FE.test1[column].values).astype(localType)\n",
    "                self.test2.loc[:,column] =  np.apply_along_axis(func,0,FE.test2[column].values).astype(localType)\n",
    "        gc.collect()\n",
    "        \n",
    "    def SaveDataFrameToHdf(self,trainOrTestOrBoth):\n",
    "        if trainOrTestOrBoth == 'train' or trainOrTestOrBoth=='both':\n",
    "            self.train.to_hdf(self.trainHdfPath, self.trainHdfFile, format='t', index=\"False\")\n",
    "        if trainOrTestOrBoth == 'test' or trainOrTestOrBoth=='both':\n",
    "            self.test1.to_hdf(self.testHdfPath1, self.testHdfFile, format='t', index=\"False\")\n",
    "            self.test2.to_hdf(self.testHdfPath2, self.testHdfFile, format='t', index=\"False\")\n",
    "        \n",
    "    def AddDemandaGeneralMean(self,trainOrTestOrBoth): \n",
    "        #self.train.loc[:,\"DemandaGeneralMean\"] = self.train[\"Demanda_uni_equil\"].loc[\n",
    "         #   self.train.loc[:,'Semana'] < 10].mean().astype(\"float32\")\n",
    "            \n",
    "        meanOfDemanda = self.train[\"Demanda_uni_equil\"].values.mean().astype(\"float32\")\n",
    "        \n",
    "        if trainOrTestOrBoth == 'train' or trainOrTestOrBoth=='both':\n",
    "            self.train.loc[:,\"DemandaGeneralMean\"] = meanOfDemanda\n",
    "        if trainOrTestOrBoth == 'test' or trainOrTestOrBoth=='both':\n",
    "            self.test1.loc[:,\"DemandaGeneralMean\"] = meanOfDemanda\n",
    "            self.test2.loc[:,\"DemandaGeneralMean\"] = meanOfDemanda\n",
    "        \n",
    "        #self.train.loc[:,\"DemandaGeneralMean\"] = self.train[\"Demanda_uni_equil\"].values[\n",
    "        #(self.train.loc[:,'Semana'].values < self.ValidationStart).values].mean().astype(\"float32\")\n",
    "        gc.collect()\n",
    "        \n",
    "    '''ConfigElements(0,[ (\"A\",[\"Semana\",\"Agencia_ID\"],[\"count\",\"count\"]),'''\n",
    "    def AddConfigurableFeaturesToTrain(self, config):\n",
    "        if config.lag > self.maxLag:\n",
    "            self.maxLag = config.lag\n",
    "        \n",
    "        tempData = self.train[self.train['Semana'].values <= (self.ValidationEnd - config.lag)]\n",
    "        #display(tempData)\n",
    "        if(config.lag != 0):\n",
    "            tempData.loc[:,'Semana'] = tempData['Semana'].values + config.lag\n",
    "        #display(tempData)\n",
    "        \n",
    "        #Means iterative.. eliminate as long as np.nan exists..If there is already one, don't create, use the existing\n",
    "        if config.targetVariable != \"\" and  config.targetVariable not in self.train.columns:\n",
    "            self.train.loc[:,config.targetVariable] = np.nan\n",
    "            self.test1.loc[:,config.targetVariable] = np.nan\n",
    "            \n",
    "            if config.lag != 1:\n",
    "                self.test2.loc[:,config.targetVariable] = np.nan\n",
    "        \n",
    "        for name,groups,aggregate in config.nameAndGroups:\n",
    "            if name not in self.train.columns:\n",
    "                print \"{} is not in columns..\".format(name)            \n",
    "                \n",
    "                groupedDataframe = tempData[groups+['Demanda_uni_equil']].copy().groupby(groups).agg(aggregate[0])\n",
    "                gc.collect()\n",
    "                #groupedDataframe.columns = groupedDataframe.columns.droplevel(0)\n",
    "                groupedDataframe.columns = [name]\n",
    "                \n",
    "                #This is means of the counts of the semana-columns tuples!..!!!\n",
    "                #If no lag and mean, mean of the columns without semana!!..\n",
    "                #If there is lag and count, count of the columns x weeks before\n",
    "                #If there is lag and mean, mean of the columns x weeks before\n",
    "                #if(config.lag == 0 and aggregate == \"count\"):\n",
    "                if(len(aggregate)>1):\n",
    "                    groupedDataframe.reset_index(inplace=True)\n",
    "                    groupedDataframe.drop(\"Semana\",axis=1, inplace=True)\n",
    "                    groups = groups[1:]\n",
    "                    groupedDataframe = groupedDataframe.groupby(groups).agg(aggregate[1])\n",
    "                    groupedDataframe.columns = [name]\n",
    "                    gc.collect()\n",
    "                \n",
    "                display(groupedDataframe)\n",
    "                self.train = self.train.merge( groupedDataframe, left_on=groups,\n",
    "                    right_index=True, how='left', sort=False,copy=False)\n",
    "                gc.collect()\n",
    "                self.test1 = self.test1.merge( groupedDataframe, left_on=groups,\n",
    "                    right_index=True, how='left', sort=False,copy=False)\n",
    "                gc.collect()\n",
    "                if config.lag != 1:\n",
    "                    self.test2 = self.test2.merge( groupedDataframe, left_on=groups,\n",
    "                        right_index=True, how='left', sort=False,copy=False)\n",
    "                \n",
    "                del groupedDataframe\n",
    "                gc.collect()\n",
    "            else:\n",
    "                print \"{} is in columns..\".format(name)\n",
    "            \n",
    "            display(self.train)\n",
    "            display(self.test1)\n",
    "            display(self.test2)\n",
    "            \n",
    "            #Means iterative..!!!!!\n",
    "            if config.targetVariable != \"\":\n",
    "                self.train.loc[pd.isnull(self.train[config.targetVariable].values), \n",
    "                    config.targetVariable] = self.train.loc[pd.isnull(self.train[config.targetVariable].values)\n",
    "                    , name].values\n",
    "                self.test1.loc[pd.isnull(self.test1[config.targetVariable].values), \n",
    "                    config.targetVariable] = self.test1.loc[pd.isnull(self.test1[config.targetVariable].values),\n",
    "                    name].values\n",
    "                if config.lag != 1:\n",
    "                    self.test2.loc[pd.isnull(self.test2[config.targetVariable].values), \n",
    "                        config.targetVariable] = self.test2.loc[pd.isnull(self.test2[config.targetVariable].values)\n",
    "                        , name].values\n",
    "                    \n",
    "                count = self.test1[config.targetVariable].isnull().sum()\n",
    "                print \"Count of missing numbers after {} in validation part 1 in column {} is {}\".format(name, \n",
    "                    config.targetVariable,str(count))\n",
    "                if config.lag != 1:\n",
    "                    count = self.test2.loc[:,config.targetVariable].isnull().sum()\n",
    "                    print \"Count of missing numbers after {} in validation part 2 in column {} is {}\".format(name, \n",
    "                        config.targetVariable,str(count))\n",
    "                \n",
    "                \n",
    "                #display(self.train)\n",
    "                #If column is already in Dataframe and we want to fill target variable, this deletes columns!!!\n",
    "                if(config.deleteColumns):\n",
    "                    self.train.drop(name, axis=1, inplace=True)\n",
    "                    self.test1.drop(name, axis=1, inplace=True)\n",
    "                    if config.lag != 1:\n",
    "                        self.test2.drop(name, axis=1, inplace=True)\n",
    "                gc.collect()\n",
    "                #Only in tesst\n",
    "                #if count == 0:\n",
    "                 #   break\n",
    "        del tempData\n",
    "        display(self.train)   \n",
    "        display(self.test1)   \n",
    "        display(self.test2)\n",
    "        gc.collect()\n",
    "        return \n",
    "    \n",
    "    def DeleteLaggedWeeksFromTrain(self):\n",
    "        self.train = self.train[self.train['Semana'].values >= (3 + self.maxLag)]\n",
    "        gc.collect()\n",
    "        display(self.train.head(2))\n",
    "        \n",
    "    def ReadFirstNRowsOfACsv(self, nrows, trainOrTestOrBoth) :\n",
    "        if trainOrTestOrBoth == 'train' or trainOrTestOrBoth=='both':\n",
    "            self.train = pd.read_csv(self.trainCsvPath, usecols=self.trainTypes.keys(), dtype=self.trainTypes, nrows = nrows)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.train)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.train)\n",
    "        if trainOrTestOrBoth == 'test' or trainOrTestOrBoth=='both':\n",
    "            tempTest = pd.read_csv(self.testCsvPath, usecols=self.testTypes.keys(), dtype=self.testTypes, nrows = nrows*2)\n",
    "            self.test1 = tempTest.loc[tempTest.Semana == self.ValidationStart]\n",
    "            self.test2 = tempTest.loc[tempTest.Semana == self.ValidationEnd]\n",
    "            del tempTest\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.test1)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.test2)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test1)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test2)\n",
    "    \n",
    "    #Use when concatanating train and validation before predict test for example..\n",
    "    def AppendTestToTrain(self,deleteTest = True):\n",
    "        self.train = self.train.append(self.test1,ignore_index=True)\n",
    "        gc.collect()\n",
    "        if(deleteTest):\n",
    "            del self.test1\n",
    "            gc.collect()\n",
    "        try:\n",
    "            self.train = self.train.append(self.test2,ignore_index=True)\n",
    "            gc.collect()\n",
    "            if(deleteTest):\n",
    "                del self.test2\n",
    "                gc.collect()\n",
    "        except:\n",
    "            pass\n",
    "        #BAD PERFORMANCE!!\n",
    "    #Split train data to train and test1 and test2 (validation)\n",
    "    #def SplitTrainToTestUsingValidationStart(self):\n",
    "     #   boolCondition = self.train.Semana == self.ValidationStart\n",
    "      #  self.test1 = self.train.loc[boolCondition]\n",
    "       # self.train.drop((self.train.loc[boolCondition].index), axis=0,inplace=True)\n",
    "        \n",
    "       # boolCondition = self.train.Semana == self.ValidationEnd\n",
    "       # self.test2 = self.train.loc[boolCondition]\n",
    "       # self.train.drop((self.train.loc[boolCondition].index), axis=0,inplace=True)\n",
    "      #  del boolCondition\n",
    "      #  gc.collect()\n",
    "    \n",
    "    #Reaches 3x memory from train, because of test1, test2 and train itself at the end.. GC fixed in the end..\n",
    "    def SplitTrainToTestUsingValidationStart(self):\n",
    "        boolCondition = self.train.Semana.values == self.ValidationStart\n",
    "        self.test1 = self.train[boolCondition]\n",
    "        boolCondition = self.train.Semana.values == self.ValidationEnd\n",
    "        self.test2 = self.train[boolCondition]\n",
    "        FE.train = FE.train[ FE.train.Semana.values < FE.ValidationStart ]\n",
    "        del boolCondition\n",
    "        gc.collect()\n",
    "        \n",
    "    def XgboostPredictAndSee(self, Test1OrTest2):\n",
    "        self.train_y = self.train[\"Demanda_uni_equil\"].copy()\n",
    "        self.train.drop(\"Demanda_uni_equil\",axis=1, inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trainCsvPath': '../../input/train.csv', 'maxLag': 3, 'testTypes': {'Cliente_ID': <type 'numpy.uint32'>, 'Ruta_SAK': <type 'numpy.uint16'>, 'Canal_ID': <type 'numpy.uint8'>, 'Producto_ID': <type 'numpy.uint16'>, 'Agencia_ID': <type 'numpy.uint16'>, 'Semana': <type 'numpy.uint8'>, 'id': <type 'numpy.uint32'>}, 'testHdfFile': 'test', 'trainTypes': {'Dev_proxima': <type 'numpy.float32'>, 'Venta_uni_hoy': <type 'numpy.uint16'>, 'Cliente_ID': <type 'numpy.uint32'>, 'Demanda_uni_equil': <type 'numpy.uint32'>, 'Ruta_SAK': <type 'numpy.uint16'>, 'Canal_ID': <type 'numpy.uint8'>, 'Venta_hoy': <type 'numpy.float32'>, 'Producto_ID': <type 'numpy.uint16'>, 'Agencia_ID': <type 'numpy.uint16'>, 'Dev_uni_proxima': <type 'numpy.uint32'>, 'Semana': <type 'numpy.uint8'>}, 'testHdfPath1': '../../input/test1_full_wz2.h5', 'ValidationEnd': 11, 'testHdfPath2': '../../input/test2_full_wz2.h5', 'testCsvPath': '../../input/test.csv', 'ValidationStart': 10, 'trainHdfFile': 'train', 'trainHdfPath': '../../input/train_full_wz2.h5'}\n"
     ]
    }
   ],
   "source": [
    "parameterDict =       {\"ValidationStart\":10, \n",
    " \"ValidationEnd\":11,\n",
    "   \"maxLag\":3,\n",
    "    \"trainHdfPath\":'../../input/train_full_wz2.h5',\n",
    "    \"trainHdfFile\":\"train\",\n",
    "    \"testHdfPath1\":\"../../input/test1_full_wz2.h5\",\n",
    "    \"testHdfPath2\":\"../../input/test2_full_wz2.h5\",\n",
    "    \"testHdfFile\":\"test\", \n",
    "    \"trainTypes\" : {'Semana':np.uint8, 'Agencia_ID':np.uint16, 'Canal_ID':np.uint8,'Ruta_SAK':np.uint16, \n",
    "        'Cliente_ID':np.uint32, 'Producto_ID':np.uint16,'Venta_uni_hoy':np.uint16, 'Venta_hoy':np.float32,\n",
    "                    'Dev_uni_proxima': np.uint32, 'Dev_proxima':np.float32,'Demanda_uni_equil':np.uint32}, \n",
    "    \"testTypes\" : {'id':np.uint32,'Semana':np.uint8, 'Agencia_ID':np.uint16, 'Canal_ID':np.uint8,'Ruta_SAK':np.uint16,\n",
    "        'Cliente_ID':np.uint32, 'Producto_ID':np.uint16},\n",
    "    \"trainCsvPath\":'../../input/train.csv'   ,\n",
    "    \"testCsvPath\":'../../input/test.csv'}\n",
    "\n",
    "FE = FeatureEngineering(**parameterDict)\n",
    "print FE.__dict__\n",
    "\n",
    "FE.ReadHdf('both')\n",
    "\n",
    "FE.DeleteLaggedWeeksFromTrain()\n",
    "\n",
    "test2columns = ['State_ID',\n",
    "       'weight', 'pieces', 'Brand_ID', 'Lag0',\n",
    "       'Lag2', 'Lag3', 'weightppieces', 'Client_Sum_Venta_hoy',\n",
    "       'Client_Sum_Venta_uni_hoy', 'Client_Sum_venta_div_venta_uni',\n",
    "       'prod_name_sum_Venta_hoy', 'prod_name_sum_Venta_uni_hoy',\n",
    "       'prod_name_sum_venta_div_venta_uni', 'Producto_sum_Venta_hoy',\n",
    "       'Producto_sum_Venta_uni_hoy', 'Producto_sum_venta_div_venta_uni',\n",
    "       'Producto_ID_sum_demanda_divide_sum_venta_uni',\n",
    "       'Prod_name_ID_sum_demanda_divide_sum_venta_uni',\n",
    "       'Cliente_ID_sum_demanda_divide_sum_venta_uni', 'ClientPerTown',\n",
    "       'client_return_sum', 'client_return_count', 'Client_return_rate',\n",
    "       'producto_return_sum', 'producto_return_count',\n",
    "       'producto_return_rate', 'prod_name_return_sum',\n",
    "       'prod_name_return_count', 'prod_name_return_rate']\n",
    "\n",
    "columns_to_remove = ['client_return_sum', 'client_return_count',\n",
    "                     'Client_Sum_Venta_uni_hoy', 'Producto_sum_venta_div_venta_uni'\n",
    "                    ]\n",
    "\n",
    "test2columns = list ( set(test2columns) - set(columns_to_remove))\n",
    "\n",
    "test1columns = test2columns + ['Lag1']\n",
    "\n",
    "X_train = FE.train[test1columns]\n",
    "X_test = FE.test1[test1columns]\n",
    "y_train = FE.train[\"Demanda_uni_equil\"]\n",
    "#y_test = FE.test1[\"Demanda_uni_equil\"]\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "#print y_test.shape\n",
    "\n",
    "## Predict test1\n",
    "\n",
    "clf1 = pickle.load(open(\"../../input/LastShot.pkl\", \"rb\"))\n",
    "clf1.set_params(**{\"n_estimators\" : clf1.best_iteration+1})\n",
    "\n",
    "clf1.fit(X_train,y_train, verbose=1, eval_set=[(X_train, y_train)])\n",
    "\n",
    "predictions = clf1.predict(X_train,ntree_limit  = clf1.best_iteration+1)\n",
    "predictionsTest = clf1.predict(X_test,ntree_limit  = clf1.best_iteration+1)\n",
    "\n",
    "print \"trainResult: \", np.sqrt(mean_squared_error(y_train, predictions))\n",
    "#print \"testResult: \", np.sqrt(mean_squared_error(y_test, predictionsTest))\n",
    "print \"Best Iteration: \", clf1.best_iteration\n",
    "print \"Best Score: \", clf1.best_score\n",
    "print xgb.plot_importance(clf1)\n",
    "\n",
    "submission1 = pd.DataFrame({'id':FE.test1.id, 'Demanda_uni_equil': predictionsTest})\n",
    "\n",
    "\n",
    "\n",
    "## Predict test2\n",
    "\n",
    "X_train = FE.train[test2columns]\n",
    "X_test = FE.test2[test2columns]\n",
    "y_train = FE.train[\"Demanda_uni_equil\"]\n",
    "#y_test = FE.test2[\"Demanda_uni_equil\"]\n",
    "\n",
    "clf2 = pickle.load(open(\"../../input/LastShot2.pkl\", \"rb\"))\n",
    "\n",
    "clf2.set_params(**{\"n_estimators\" : clf2.best_iteration+1})\n",
    "\n",
    "clf2.fit(X_train,y_train, verbose=1, eval_set=[(X_train, y_train)])\n",
    "\n",
    "predictions = clf2.predict(X_train,ntree_limit  = clf2.best_iteration+1)\n",
    "predictionsTest = clf2.predict(X_test,ntree_limit  = clf2.best_iteration+1)\n",
    "\n",
    "print \"trainResult: \", np.sqrt(mean_squared_error(y_train, predictions))\n",
    "#print \"testResult: \", np.sqrt(mean_squared_error(y_test, predictionsTest))\n",
    "print \"Best Iteration: \", clf2.best_iteration\n",
    "print \"Best Score: \", clf2.best_score\n",
    "print xgb.plot_importance(clf2)\n",
    "\n",
    "submission2 = pd.DataFrame({'id':FE.test2.id, 'Demanda_uni_equil': predictionsTest})\n",
    "\n",
    "## Arrange Submission File\n",
    "\n",
    "submission = submission2.append(submission1)\n",
    "\n",
    "submission.loc[:,\"Demanda_uni_equil\"] = np.round(np.expm1(submission[\"Demanda_uni_equil\"]))\n",
    "\n",
    "submission.sort_values(by=\"id\",inplace=True)\n",
    "\n",
    "(submission.id == 0).sum()\n",
    "\n",
    "submission.head(20)\n",
    "\n",
    "submission.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "submission[[\"id\",\"Demanda_uni_equil\"]].to_csv('../../input/' + \n",
    "                                              datetime.now().strftime('%Y-%m-%d-%H-%M-%S') +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#FE.ReadCsv('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "FE.test2 =  pd.DataFrame({\"id\":  FE.test2[\"id\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#FE.test2.loc[:,\"Demanda_uni_equil\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "submission = FE.test2.append(submission1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(submission.id == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(submission1.id == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(FE.test1.Semana == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(FE.test2.Semana == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(FE.test2.id != 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(FE.test1.id != 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "FE.test2[(FE.test2.id == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "submission.sort_values(by=\"id\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "submission[[\"id\",\"Demanda_uni_equil\"]].to_csv('../../input/' + \n",
    "                                              datetime.now().strftime('%Y-%m-%d-%H-%M-%S') +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test2 XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "X_train = FE.train[test2columns]\n",
    "X_test = FE.test2[test2columns]\n",
    "y_train = FE.train[\"Demanda_uni_equil\"]\n",
    "y_test = FE.test2[\"Demanda_uni_equil\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "defaultParams = {\"max_depth\":6, \"subsample\":1., \"min_child_weight\":5, \"colsample_bytree\":0.4, \"missing\":np.nan\n",
    "                ,\"n_estimators\":500, \"learning_rate\":0.1}\n",
    "xgb_model2 = xgb.XGBRegressor(**defaultParams) \n",
    "\n",
    "\n",
    "xgb_model2.fit(X_train,y_train,eval_set=[(X_train, y_train),(X_test, y_test)],\n",
    "         verbose=1, early_stopping_rounds = 10)\n",
    "\n",
    "\n",
    "predictions = xgb_model2.predict(X_train,ntree_limit  = xgb_model2.best_iteration+1)\n",
    "predictionsTest = xgb_model2.predict(X_test,ntree_limit  = xgb_model2.best_iteration+1)\n",
    "\n",
    "print \"trainResult: \", np.sqrt(mean_squared_error(y_train, predictions))\n",
    "print \"testResult: \", np.sqrt(mean_squared_error(y_test, predictionsTest))\n",
    "print \"Best Iteration: \", xgb_model2.best_iteration\n",
    "print \"Best Score: \", xgb_model2.best_score\n",
    "print xgb.plot_importance(xgb_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(\"Pickling sklearn API models\")\n",
    "# must open in binary format to pickle\n",
    "pickle.dump(xgb_model2, open(\"../../input/test2.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "clf2 = pickle.load(open(\"../../input/test2.pkl\", \"rb\"))\n",
    "\n",
    "clf2.set_params(**{\"n_estimators\" : clf2.best_iteration+1})\n",
    "\n",
    "clf2.fit(X_train,y_train, verbose=1, eval_set=[(X_train, y_train)])\n",
    "\n",
    "predictions = clf2.predict(X_train,ntree_limit  = clf2.best_iteration+1)\n",
    "predictionsTest = clf2.predict(X_test,ntree_limit  = clf2.best_iteration+1)\n",
    "\n",
    "print \"trainResult: \", np.sqrt(mean_squared_error(y_train, predictions))\n",
    "print \"testResult: \", np.sqrt(mean_squared_error(y_test, predictionsTest))\n",
    "print \"Best Iteration: \", clf2.best_iteration\n",
    "print \"Best Score: \", clf2.best_score\n",
    "print xgb.plot_importance(clf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "corrDf = FE.train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "corrDf.to_csv('../../input/coordf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "corrDf.loc[:,0:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def GiveBestParameterWithoutCV(defaultParams, testParams, X_train, X_test, Y_train, Y_test, fitParams):\n",
    "    xgb_model = xgb.XGBRegressor(**defaultParams) \n",
    "    \n",
    "    minRmse = 10000\n",
    "    minRmseParameter = 10000\n",
    "    bestIteration = 1000\n",
    "        \n",
    "    for key,values in testParams:\n",
    "        minRmseParameter = xgb_model.get_xgb_params()[key]\n",
    "        \n",
    "        for value in values:\n",
    "            \n",
    "            xgb_model.set_params(**{key:value})\n",
    "            xgb_model.fit(X_train,Y_train, eval_set=[(X_train, Y_train),(X_test, Y_test)],\n",
    "                  **fitParams)\n",
    "            if xgb_model.best_score < minRmse:\n",
    "                minRmse = xgb_model.best_score\n",
    "                minRmseParameter = value\n",
    "                bestIteration = xgb_model.best_iteration\n",
    "                \n",
    "        xgb_model.set_params(**{key:minRmseParameter})\n",
    "        print \"Parameters are finished for {}. Best Iteration is {}\".format(key, bestIteration)\n",
    "        print \"Minimum Rmse : {}, optimum parameter is {} between {}\".format(minRmse, minRmseParameter, values)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "defaultParams = {\"max_depth\":10, \"subsample\":1., \"min_child_weight\":5, \"colsample_bytree\":0.4, \"missing\":np.nan\n",
    "                ,\"n_estimators\":500, \"learning_rate\":0.1}\n",
    "testParams = [(\"max_depth\",[12,8,6,14]), (\"subsample\",[0.9,0.8,0.6]), (\"min_child_weight\",[1,3,7]),\n",
    "                  (\"colsample_bytree\",[0.3,0.5,0.6, 0.8,1]), (\"learning_rate\",[0.05])]\n",
    "fitParams = {\"verbose\":2, \"early_stopping_rounds\": 10}\n",
    "\n",
    "GiveBestParameterWithoutCV(defaultParams,testParams, X_train, X_test, y_train, y_test, fitParams )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pd.DataFrame([np.round(np.expm1(predictionsTest[:20])),np.round(np.expm1(y_test[0:20]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "np.sqrt(mean_squared_error(y_test, predictionsTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "berker = pd.DataFrame( {\"Predict\": np.round(np.expm1(predictionsTest)),\n",
    "    \"Real\" : np.round(np.expm1(y_test))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "berker.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "np.mean(predictionsTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "np.mean(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "print(\"Pickling sklearn API models\")\n",
    "# must open in binary format to pickle\n",
    "pickle.dump(xgb_model, open(\"best_boston.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
