{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.datasets import load_iris, load_digits, load_boston\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
    "from collections import OrderedDict\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(31337)\n",
    "boston = load_boston()\n",
    "y = boston['target']\n",
    "X = boston['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-1, -1, -1, -1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = boston['data']\n",
    "y = boston['target']\n",
    "print X.shape\n",
    "print y.shape\n",
    "X_train = X[:400]\n",
    "X_test = X[400:]\n",
    "y_train = y[:400]\n",
    "y_test = y[400:]\n",
    "\n",
    "tempX = 400 * [-1] + y_test.shape[0] * [0]\n",
    "tempX[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSE(y_true,y_pred):\n",
    "    mse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print 'MSE: %2.3f' % mse\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't have early stop option!!!!!!!!So didn't use so far..\n",
    "## Semi-Automatic Hyperparameter Tuning, it can't predict. Only gives optimum parameter..\n",
    "## Predict doesn't work, because when refit = False, it doesn't assign best estimator!!!\n",
    "## Doesn't do 2 fold, this is what i want for Bimbo.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston Housing: regression\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "MSE: 5.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.PredefinedSplit(test_fold=[-1 -1 ...,  0  0]),\n",
       "       error_score='raise',\n",
       "       estimator=XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.4,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=5, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1.0),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [200]}, pre_dispatch='2*n_jobs',\n",
       "       refit=False, scoring=make_scorer(RMSE, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Boston Housing: regression\")\n",
    "boston = load_boston()\n",
    "y = boston['target']\n",
    "X = boston['data']\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1729)\n",
    "\n",
    "\n",
    "'''base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
    "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=1\n",
    "        \n",
    "        \n",
    "learning_rate=0.1\n",
    "max_depth=3\n",
    "missing=np.nan, learning_rate=0.02, subsample=0.9, colsample_bytree=0.85\n",
    "'''\n",
    "\n",
    "#in order depth= 10, subsample=1.0, min_child_weight = 5, col_sample_bytree = 0.2, eta = 0.1, \n",
    "#col_sample_bytree = 0.4 - 1\n",
    "#gamma = 0.05,0.1 0.3, 0.5, 0.7, 1\n",
    "#lambda = 0.01, 0.1, 1\n",
    "#alpha = 0.01, 0.1, 1\n",
    "#n_estimators is last..\n",
    "\n",
    "#Start from 10 and play up down..\n",
    "depth = [12,8]\n",
    "subsample = [0.8,0.6]\n",
    "min_child_weight = [3,7]\n",
    "col_sample_bytree = [0.3,0.5,0.8,1]\n",
    "#lambdaa = [0.01, 0.1, 1]\n",
    "#alpha = [0.01, 0.1]\n",
    "#Use this eta to find the optimum iteration\n",
    "eta = [0.05]\n",
    "\n",
    "defaultParams = {\"max_depth\":10, \"subsample\":1., \"min_child_weight\":5, \"colsample_bytree\":0.4, \"missing\":np.nan}\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import PredefinedSplit\n",
    "#ps = PredefinedSplit(test_fold=[-1, -1, -1, 0,0])\n",
    "ps = PredefinedSplit(test_fold=tempX)\n",
    "\n",
    "#ps = PredefinedSplit(test_fold=[0, 1, 2, 1])\n",
    "#len(ps)\n",
    "\n",
    "\n",
    "\n",
    "#xgb_model.fit(X_train,y_train,eval_set=[(X_train, y_train),(X_test, y_test)],\n",
    " #        verbose=10, early_stopping_rounds = 50)\n",
    "\n",
    "cv_params = {'n_estimators': [200]}\n",
    "\n",
    "\n",
    "optimized_Xgb = GridSearchCV(xgb.XGBRegressor(**defaultParams), \n",
    "    cv_params, cv = ps, n_jobs = -1,verbose=1,refit=False, scoring = make_scorer(RMSE, greater_is_better=False)) \n",
    "\n",
    "optimized_Xgb.fit(X,y)\n",
    "\n",
    "#optimized_GBM.best_estimator_ = optimized_GBM.estimator\n",
    "\n",
    "#print(optimized_GBM.best_score_)\n",
    "#print(optimized_GBM.best_params_)\n",
    "\n",
    "\n",
    "#predictions = optimized_GBM.predict(X_train)\n",
    "#predictionsTest = optimized_GBM.predict(X_test)\n",
    "#print( np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "#print( np.sqrt(mean_squared_error(y_test, predictionsTest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle, Save Model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling sklearn API models\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "need to call fit beforehand",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e82f90905f3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_boston.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_boston.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# pylint: disable=missing-docstring,invalid-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mtest_dmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         return self.booster().predict(test_dmatrix,\n\u001b[0m\u001b[1;32m    205\u001b[0m                                       \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                                       ntree_limit=ntree_limit)\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mbooster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \"\"\"\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need to call fit beforehand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: need to call fit beforehand"
     ]
    }
   ],
   "source": [
    "print(\"Pickling sklearn API models\")\n",
    "# must open in binary format to pickle\n",
    "pickle.dump(xgb_model, open(\"best_boston.pkl\", \"wb\"))\n",
    "clf2 = pickle.load(open(\"best_boston.pkl\", \"rb\"))\n",
    "print(np.allclose(xgb_model.predict(X_train), clf2.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manuel Hyperparameter Tuning Davut "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston Housing: regression\n",
      "[0]\tvalidation_0-rmse:23.1009\tvalidation_1-rmse:14.6234\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-rmse:21.0086\tvalidation_1-rmse:12.6123\n",
      "[2]\tvalidation_0-rmse:19.1358\tvalidation_1-rmse:11.3087\n",
      "[3]\tvalidation_0-rmse:17.4515\tvalidation_1-rmse:10.0673\n",
      "[4]\tvalidation_0-rmse:15.8429\tvalidation_1-rmse:8.91073\n",
      "[5]\tvalidation_0-rmse:14.3663\tvalidation_1-rmse:7.99402\n",
      "[6]\tvalidation_0-rmse:13.1263\tvalidation_1-rmse:6.84218\n",
      "[7]\tvalidation_0-rmse:12.0237\tvalidation_1-rmse:6.22083\n",
      "[8]\tvalidation_0-rmse:11.019\tvalidation_1-rmse:5.59899\n",
      "[9]\tvalidation_0-rmse:10.13\tvalidation_1-rmse:5.06344\n",
      "[10]\tvalidation_0-rmse:9.26016\tvalidation_1-rmse:4.56539\n",
      "[11]\tvalidation_0-rmse:8.51636\tvalidation_1-rmse:4.21592\n",
      "[12]\tvalidation_0-rmse:7.77885\tvalidation_1-rmse:3.95813\n",
      "[13]\tvalidation_0-rmse:7.13544\tvalidation_1-rmse:3.70216\n",
      "[14]\tvalidation_0-rmse:6.54363\tvalidation_1-rmse:3.5417\n",
      "[15]\tvalidation_0-rmse:6.01406\tvalidation_1-rmse:3.5099\n",
      "[16]\tvalidation_0-rmse:5.5481\tvalidation_1-rmse:3.43295\n",
      "[17]\tvalidation_0-rmse:5.13642\tvalidation_1-rmse:3.4163\n",
      "[18]\tvalidation_0-rmse:4.76883\tvalidation_1-rmse:3.43239\n",
      "[19]\tvalidation_0-rmse:4.4397\tvalidation_1-rmse:3.44221\n",
      "[20]\tvalidation_0-rmse:4.14469\tvalidation_1-rmse:3.51449\n",
      "[21]\tvalidation_0-rmse:3.90818\tvalidation_1-rmse:3.6203\n",
      "[22]\tvalidation_0-rmse:3.65727\tvalidation_1-rmse:3.71067\n",
      "[23]\tvalidation_0-rmse:3.39814\tvalidation_1-rmse:3.75526\n",
      "[24]\tvalidation_0-rmse:3.20688\tvalidation_1-rmse:3.91971\n",
      "[25]\tvalidation_0-rmse:3.02649\tvalidation_1-rmse:3.99591\n",
      "[26]\tvalidation_0-rmse:2.87184\tvalidation_1-rmse:4.05241\n",
      "[27]\tvalidation_0-rmse:2.709\tvalidation_1-rmse:4.34476\n",
      "[28]\tvalidation_0-rmse:2.55144\tvalidation_1-rmse:4.40314\n",
      "[29]\tvalidation_0-rmse:2.38869\tvalidation_1-rmse:4.61618\n",
      "[30]\tvalidation_0-rmse:2.26553\tvalidation_1-rmse:4.66014\n",
      "[31]\tvalidation_0-rmse:2.13536\tvalidation_1-rmse:4.69092\n",
      "[32]\tvalidation_0-rmse:2.01661\tvalidation_1-rmse:4.6982\n",
      "[33]\tvalidation_0-rmse:1.9245\tvalidation_1-rmse:4.81974\n",
      "[34]\tvalidation_0-rmse:1.84394\tvalidation_1-rmse:4.84937\n",
      "[35]\tvalidation_0-rmse:1.7792\tvalidation_1-rmse:4.92667\n",
      "[36]\tvalidation_0-rmse:1.69011\tvalidation_1-rmse:4.95501\n",
      "[37]\tvalidation_0-rmse:1.6253\tvalidation_1-rmse:5.04373\n",
      "[38]\tvalidation_0-rmse:1.55237\tvalidation_1-rmse:5.06142\n",
      "[39]\tvalidation_0-rmse:1.50998\tvalidation_1-rmse:5.08716\n",
      "[40]\tvalidation_0-rmse:1.45577\tvalidation_1-rmse:5.16585\n",
      "[41]\tvalidation_0-rmse:1.40875\tvalidation_1-rmse:5.17191\n",
      "[42]\tvalidation_0-rmse:1.35395\tvalidation_1-rmse:5.21664\n",
      "[43]\tvalidation_0-rmse:1.30369\tvalidation_1-rmse:5.22831\n",
      "[44]\tvalidation_0-rmse:1.28235\tvalidation_1-rmse:5.24863\n",
      "[45]\tvalidation_0-rmse:1.22978\tvalidation_1-rmse:5.33154\n",
      "[46]\tvalidation_0-rmse:1.18519\tvalidation_1-rmse:5.35776\n",
      "[47]\tvalidation_0-rmse:1.14698\tvalidation_1-rmse:5.343\n",
      "Stopping. Best iteration:\n",
      "[17]\tvalidation_0-rmse:5.13642\tvalidation_1-rmse:3.4163\n",
      "\n",
      "trainResult:  5.13642232447\n",
      "testResult:  3.41629732029\n",
      "Best Iteration:  17\n",
      "Best Score:  3.416297\n",
      "Axes(0.125,0.125;0.775x0.775)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAFtCAYAAAD4VDh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ne7uP1H6xMAgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10617d0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Boston Housing: regression\")\n",
    "#y = boston['target']\n",
    "#X = boston['data']\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1729)\n",
    "\n",
    "\n",
    "'''base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
    "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=1\n",
    "        \n",
    "        \n",
    "learning_rate=0.1\n",
    "max_depth=3\n",
    "missing=np.nan, learning_rate=0.02, subsample=0.9, colsample_bytree=0.85\n",
    "'''\n",
    "\n",
    "#in order depth= 10, subsample=1.0, min_child_weight = 5, col_sample_bytree = 0.2, eta = 0.1, \n",
    "\n",
    "#col_sample_bytree = 0.4 - 1\n",
    "#gamma = 0.05,0.1 0.3, 0.5, 0.7, 1\n",
    "#lambda = 0.01, 0.1, 1\n",
    "#alpha = 0.01, 0.1, 1\n",
    "#n_estimators is last..\n",
    "\n",
    "\n",
    "defaultParams = {\"max_depth\":10, \"subsample\":1., \"min_child_weight\":5, \"colsample_bytree\":0.4, \"missing\":np.nan\n",
    "                ,\"n_estimators\":300}\n",
    "xgb_model = xgb.XGBRegressor(**defaultParams) \n",
    "\n",
    "\n",
    "xgb_model.fit(X_train,y_train,eval_set=[(X_train, y_train),(X_test, y_test)],\n",
    "         verbose=1, early_stopping_rounds = 30)\n",
    "\n",
    "\n",
    "predictions = xgb_model.predict(X_train,ntree_limit  = xgb_model.best_iteration+1)\n",
    "predictionsTest = xgb_model.predict(X_test,ntree_limit  = xgb_model.best_iteration+1)\n",
    "\n",
    "print \"trainResult: \", np.sqrt(mean_squared_error(y_train, predictions))\n",
    "print \"testResult: \", np.sqrt(mean_squared_error(y_test, predictionsTest))\n",
    "print \"Best Iteration: \", xgb_model.best_iteration\n",
    "print \"Best Score: \", xgb_model.best_score\n",
    "print xgb.plot_importance(xgb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GiveBestParameterWithoutCV(defaultParams, testParams, X_train, X_test, Y_train, Y_test, fitParams):\n",
    "    xgb_model = xgb.XGBRegressor(**defaultParams) \n",
    "    \n",
    "    minRmse = 10000\n",
    "    minRmseParameter = 10000\n",
    "    bestIteration = 1000\n",
    "        \n",
    "    for key,values in testParams:\n",
    "        minRmseParameter = xgb_model.get_xgb_params()[key]\n",
    "        \n",
    "        for value in values:\n",
    "            \n",
    "            xgb_model.set_params(**{key:value})\n",
    "            xgb_model.fit(X_train,Y_train, eval_set=[(X_train, Y_train),(X_test, Y_test)],\n",
    "                  **fitParams)\n",
    "            if xgb_model.best_score < minRmse:\n",
    "                minRmse = xgb_model.best_score\n",
    "                minRmseParameter = value\n",
    "                bestIteration = xgb_model.best_iteration\n",
    "                \n",
    "        xgb_model.set_params(**{key:minRmseParameter})\n",
    "        print \"Parameters are finished for {}. Best Iteration is {}\".format(key, bestIteration)\n",
    "        print \"Minimum Rmse : {}, optimum parameter is {} between {}\".format(minRmse, minRmseParameter, values)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:23.1009\tvalidation_1-rmse:14.6234\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 50 rounds.\n",
      "[10]\tvalidation_0-rmse:9.25949\tvalidation_1-rmse:4.56019\n",
      "[20]\tvalidation_0-rmse:4.13939\tvalidation_1-rmse:3.47237\n",
      "[30]\tvalidation_0-rmse:2.25765\tvalidation_1-rmse:4.62288\n",
      "[40]\tvalidation_0-rmse:1.48033\tvalidation_1-rmse:5.12618\n",
      "[50]\tvalidation_0-rmse:1.05455\tvalidation_1-rmse:5.39472\n",
      "[60]\tvalidation_0-rmse:0.818546\tvalidation_1-rmse:5.48539\n",
      "Stopping. Best iteration:\n",
      "[17]\tvalidation_0-rmse:5.13125\tvalidation_1-rmse:3.37505\n",
      "\n",
      "[0]\tvalidation_0-rmse:23.1009\tvalidation_1-rmse:14.6234\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 50 rounds.\n",
      "[10]\tvalidation_0-rmse:9.26368\tvalidation_1-rmse:4.569\n",
      "[20]\tvalidation_0-rmse:4.15646\tvalidation_1-rmse:3.53157\n",
      "[30]\tvalidation_0-rmse:2.3231\tvalidation_1-rmse:4.61501\n",
      "[40]\tvalidation_0-rmse:1.57235\tvalidation_1-rmse:5.05125\n",
      "[50]\tvalidation_0-rmse:1.15644\tvalidation_1-rmse:5.24142\n",
      "[60]\tvalidation_0-rmse:0.949572\tvalidation_1-rmse:5.35413\n",
      "Stopping. Best iteration:\n",
      "[17]\tvalidation_0-rmse:5.13832\tvalidation_1-rmse:3.40469\n",
      "\n",
      "[0]\tvalidation_0-rmse:23.1009\tvalidation_1-rmse:14.6234\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 50 rounds.\n",
      "[10]\tvalidation_0-rmse:9.31532\tvalidation_1-rmse:4.40814\n",
      "[20]\tvalidation_0-rmse:4.23619\tvalidation_1-rmse:3.64106\n",
      "[30]\tvalidation_0-rmse:2.45596\tvalidation_1-rmse:4.72876\n",
      "[40]\tvalidation_0-rmse:1.74568\tvalidation_1-rmse:5.3155\n",
      "[50]\tvalidation_0-rmse:1.37812\tvalidation_1-rmse:5.51213\n",
      "[60]\tvalidation_0-rmse:1.15878\tvalidation_1-rmse:5.63725\n",
      "Stopping. Best iteration:\n",
      "[14]\tvalidation_0-rmse:6.61782\tvalidation_1-rmse:3.42212\n",
      "\n",
      "[0]\tvalidation_0-rmse:23.1009\tvalidation_1-rmse:14.6234\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 50 rounds.\n",
      "[10]\tvalidation_0-rmse:9.25949\tvalidation_1-rmse:4.56019\n",
      "[20]\tvalidation_0-rmse:4.13939\tvalidation_1-rmse:3.47237\n",
      "[30]\tvalidation_0-rmse:2.25105\tvalidation_1-rmse:4.64958\n",
      "[40]\tvalidation_0-rmse:1.46294\tvalidation_1-rmse:5.21827\n",
      "[50]\tvalidation_0-rmse:1.03271\tvalidation_1-rmse:5.45265\n",
      "[60]\tvalidation_0-rmse:0.799139\tvalidation_1-rmse:5.47378\n",
      "Stopping. Best iteration:\n",
      "[17]\tvalidation_0-rmse:5.13125\tvalidation_1-rmse:3.37505\n",
      "\n",
      "Parameters are finished for max_depth. Best Iteration is 17\n",
      "Minimum Rmse : 3.375049, optimum parameter is 12 between [12, 8, 6, 14]\n",
      "[0]\tvalidation_0-rmse:23.1357\tvalidation_1-rmse:14.6704\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 50 rounds.\n",
      "[10]\tvalidation_0-rmse:9.26179\tvalidation_1-rmse:5.07983\n",
      "[20]\tvalidation_0-rmse:4.16007\tvalidation_1-rmse:3.52149\n",
      "[30]\tvalidation_0-rmse:2.29019\tvalidation_1-rmse:3.76932\n",
      "[40]\tvalidation_0-rmse:1.50586\tvalidation_1-rmse:4.29741\n",
      "[50]\tvalidation_0-rmse:1.09813\tvalidation_1-rmse:4.49722\n",
      "[60]\tvalidation_0-rmse:0.860887\tvalidation_1-rmse:4.62065\n",
      "[70]\tvalidation_0-rmse:0.729688\tvalidation_1-rmse:4.64544\n",
      "Stopping. Best iteration:\n",
      "[23]\tvalidation_0-rmse:3.39533\tvalidation_1-rmse:3.45794\n",
      "\n",
      "[0]\tvalidation_0-rmse:23.1311\tvalidation_1-rmse:14.6504\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 50 rounds.\n",
      "[10]\tvalidation_0-rmse:9.3422\tvalidation_1-rmse:4.92696\n",
      "[20]\tvalidation_0-rmse:4.27159\tvalidation_1-rmse:3.47751\n",
      "[30]\tvalidation_0-rmse:2.43132\tvalidation_1-rmse:3.94522\n",
      "[40]\tvalidation_0-rmse:1.62856\tvalidation_1-rmse:4.61188\n",
      "[50]\tvalidation_0-rmse:1.23497\tvalidation_1-rmse:4.90079\n",
      "[60]\tvalidation_0-rmse:1.01843\tvalidation_1-rmse:4.92244\n",
      "[70]\tvalidation_0-rmse:0.870206\tvalidation_1-rmse:4.94707\n",
      "Stopping. Best iteration:\n",
      "[21]\tvalidation_0-rmse:3.99694\tvalidation_1-rmse:3.46199\n",
      "\n",
      "[0]\tvalidation_0-rmse:23.1689\tvalidation_1-rmse:14.4585\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 50 rounds.\n",
      "[10]\tvalidation_0-rmse:9.49453\tvalidation_1-rmse:4.89482\n",
      "[20]\tvalidation_0-rmse:4.52327\tvalidation_1-rmse:3.36061\n",
      "[30]\tvalidation_0-rmse:2.74588\tvalidation_1-rmse:3.88089\n",
      "[40]\tvalidation_0-rmse:1.98074\tvalidation_1-rmse:4.63384\n",
      "[50]\tvalidation_0-rmse:1.62241\tvalidation_1-rmse:4.94427\n",
      "[60]\tvalidation_0-rmse:1.38143\tvalidation_1-rmse:4.96434\n",
      "[70]\tvalidation_0-rmse:1.21575\tvalidation_1-rmse:5.03616\n",
      "Stopping. Best iteration:\n",
      "[21]\tvalidation_0-rmse:4.24937\tvalidation_1-rmse:3.34964\n",
      "\n",
      "Parameters are finished for subsample. Best Iteration is 21\n",
      "Minimum Rmse : 3.34964, optimum parameter is 0.6 between [0.9, 0.8, 0.6]\n",
      "[0]\tvalidation_0-rmse:23.1669\tvalidation_1-rmse:14.4448\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 50 rounds.\n",
      "[10]\tvalidation_0-rmse:9.50477\tvalidation_1-rmse:5.03958\n",
      "[20]\tvalidation_0-rmse:4.35999\tvalidation_1-rmse:3.50421\n",
      "[30]\tvalidation_0-rmse:2.30223\tvalidation_1-rmse:4.02064\n",
      "[40]\tvalidation_0-rmse:1.39416\tvalidation_1-rmse:4.33344\n",
      "[50]\tvalidation_0-rmse:0.946493\tvalidation_1-rmse:4.57353\n",
      "[60]\tvalidation_0-rmse:0.654698\tvalidation_1-rmse:4.52167\n",
      "[70]\tvalidation_0-rmse:0.488918\tvalidation_1-rmse:4.52862\n",
      "Stopping. Best iteration:\n",
      "[21]\tvalidation_0-rmse:4.0553\tvalidation_1-rmse:3.4612\n",
      "\n",
      "[0]\tvalidation_0-rmse:23.1689\tvalidation_1-rmse:14.4585\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 50 rounds.\n",
      "[10]\tvalidation_0-rmse:9.49097\tvalidation_1-rmse:4.87041\n",
      "[20]\tvalidation_0-rmse:4.42863\tvalidation_1-rmse:3.41862\n",
      "[30]\tvalidation_0-rmse:2.51471\tvalidation_1-rmse:4.04275\n",
      "[40]\tvalidation_0-rmse:1.68336\tvalidation_1-rmse:4.59555\n",
      "[50]\tvalidation_0-rmse:1.27202\tvalidation_1-rmse:4.82867\n",
      "[60]\tvalidation_0-rmse:1.00495\tvalidation_1-rmse:4.82548\n",
      "[70]\tvalidation_0-rmse:0.830243\tvalidation_1-rmse:4.88545\n",
      "Stopping. Best iteration:\n",
      "[21]\tvalidation_0-rmse:4.14396\tvalidation_1-rmse:3.40125\n",
      "\n",
      "[0]\tvalidation_0-rmse:23.1719\tvalidation_1-rmse:14.52\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 50 rounds.\n",
      "[10]\tvalidation_0-rmse:9.49537\tvalidation_1-rmse:4.9334\n",
      "[20]\tvalidation_0-rmse:4.60121\tvalidation_1-rmse:3.42628\n",
      "[30]\tvalidation_0-rmse:2.9609\tvalidation_1-rmse:3.88435\n",
      "[40]\tvalidation_0-rmse:2.25678\tvalidation_1-rmse:4.62512\n",
      "[50]\tvalidation_0-rmse:1.91498\tvalidation_1-rmse:5.13788\n",
      "[60]\tvalidation_0-rmse:1.68605\tvalidation_1-rmse:5.13746\n",
      "[70]\tvalidation_0-rmse:1.5325\tvalidation_1-rmse:5.17637\n",
      "Stopping. Best iteration:\n",
      "[21]\tvalidation_0-rmse:4.33243\tvalidation_1-rmse:3.40319\n",
      "\n",
      "Parameters are finished for min_child_weight. Best Iteration is 21\n",
      "Minimum Rmse : 3.34964, optimum parameter is 5 between [1, 3, 7]\n",
      "[0]\tvalidation_0-rmse:23.1689\tvalidation_1-rmse:14.4585\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 50 rounds.\n",
      "[10]\tvalidation_0-rmse:9.88914\tvalidation_1-rmse:4.99878\n",
      "[20]\tvalidation_0-rmse:4.97883\tvalidation_1-rmse:3.76321\n",
      "[30]\tvalidation_0-rmse:3.10184\tvalidation_1-rmse:4.20663\n",
      "[40]\tvalidation_0-rmse:2.31316\tvalidation_1-rmse:4.44139\n",
      "[50]\tvalidation_0-rmse:1.90928\tvalidation_1-rmse:4.58226\n",
      "[60]\tvalidation_0-rmse:1.61882\tvalidation_1-rmse:4.51654\n",
      "[70]\tvalidation_0-rmse:1.42519\tvalidation_1-rmse:4.58678\n",
      "Stopping. Best iteration:\n",
      "[21]\tvalidation_0-rmse:4.68548\tvalidation_1-rmse:3.72324\n",
      "\n",
      "[0]\tvalidation_0-rmse:23.1689\tvalidation_1-rmse:14.4585\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 50 rounds.\n",
      "[10]\tvalidation_0-rmse:9.26309\tvalidation_1-rmse:5.2064\n",
      "[20]\tvalidation_0-rmse:4.3763\tvalidation_1-rmse:3.4378\n",
      "[30]\tvalidation_0-rmse:2.61578\tvalidation_1-rmse:3.85868\n",
      "[40]\tvalidation_0-rmse:1.91017\tvalidation_1-rmse:4.57216\n",
      "[50]\tvalidation_0-rmse:1.58671\tvalidation_1-rmse:5.02669\n",
      "[60]\tvalidation_0-rmse:1.34684\tvalidation_1-rmse:4.95244\n",
      "[70]\tvalidation_0-rmse:1.18685\tvalidation_1-rmse:5.03754\n",
      "Stopping. Best iteration:\n",
      "[21]\tvalidation_0-rmse:4.07516\tvalidation_1-rmse:3.31956\n",
      "\n",
      "[0]\tvalidation_0-rmse:23.1689\tvalidation_1-rmse:14.4585\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 50 rounds.\n",
      "[10]\tvalidation_0-rmse:9.22915\tvalidation_1-rmse:4.65883\n",
      "[20]\tvalidation_0-rmse:4.26305\tvalidation_1-rmse:3.47611\n",
      "[30]\tvalidation_0-rmse:2.56199\tvalidation_1-rmse:4.27327\n",
      "[40]\tvalidation_0-rmse:1.82264\tvalidation_1-rmse:5.29472\n",
      "[50]\tvalidation_0-rmse:1.52288\tvalidation_1-rmse:5.6959\n",
      "[60]\tvalidation_0-rmse:1.28711\tvalidation_1-rmse:5.74956\n",
      "Stopping. Best iteration:\n",
      "[16]\tvalidation_0-rmse:5.71638\tvalidation_1-rmse:3.38698\n",
      "\n",
      "[0]\tvalidation_0-rmse:23.1308\tvalidation_1-rmse:14.4589\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 50 rounds.\n",
      "[10]\tvalidation_0-rmse:9.12842\tvalidation_1-rmse:5.5446\n",
      "[20]\tvalidation_0-rmse:4.2457\tvalidation_1-rmse:3.551\n",
      "[30]\tvalidation_0-rmse:2.55036\tvalidation_1-rmse:3.53024\n",
      "[40]\tvalidation_0-rmse:1.81198\tvalidation_1-rmse:3.80701\n",
      "[50]\tvalidation_0-rmse:1.50879\tvalidation_1-rmse:4.02066\n",
      "[60]\tvalidation_0-rmse:1.3\tvalidation_1-rmse:4.23002\n",
      "[70]\tvalidation_0-rmse:1.12413\tvalidation_1-rmse:4.28942\n",
      "Stopping. Best iteration:\n",
      "[22]\tvalidation_0-rmse:3.72739\tvalidation_1-rmse:3.27842\n",
      "\n",
      "[0]\tvalidation_0-rmse:23.1308\tvalidation_1-rmse:14.4589\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 50 rounds.\n",
      "[10]\tvalidation_0-rmse:9.09155\tvalidation_1-rmse:5.91676\n",
      "[20]\tvalidation_0-rmse:4.24267\tvalidation_1-rmse:3.63427\n",
      "[30]\tvalidation_0-rmse:2.47653\tvalidation_1-rmse:3.61376\n",
      "[40]\tvalidation_0-rmse:1.76928\tvalidation_1-rmse:3.65163\n",
      "[50]\tvalidation_0-rmse:1.47105\tvalidation_1-rmse:3.66754\n",
      "[60]\tvalidation_0-rmse:1.20131\tvalidation_1-rmse:3.80876\n",
      "[70]\tvalidation_0-rmse:1.0233\tvalidation_1-rmse:3.90336\n",
      "Stopping. Best iteration:\n",
      "[27]\tvalidation_0-rmse:2.81837\tvalidation_1-rmse:3.51064\n",
      "\n",
      "Parameters are finished for colsample_bytree. Best Iteration is 22\n",
      "Minimum Rmse : 3.278419, optimum parameter is 0.8 between [0.3, 0.5, 0.6, 0.8, 1]\n",
      "[0]\tvalidation_0-rmse:24.33\tvalidation_1-rmse:15.2946\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 50 rounds.\n",
      "[10]\tvalidation_0-rmse:15.2149\tvalidation_1-rmse:9.14854\n",
      "[20]\tvalidation_0-rmse:9.70099\tvalidation_1-rmse:5.91917\n",
      "[30]\tvalidation_0-rmse:6.43744\tvalidation_1-rmse:4.08874\n",
      "[40]\tvalidation_0-rmse:4.42566\tvalidation_1-rmse:3.45971\n",
      "[50]\tvalidation_0-rmse:3.2608\tvalidation_1-rmse:3.42196\n",
      "[60]\tvalidation_0-rmse:2.53242\tvalidation_1-rmse:3.50051\n",
      "[70]\tvalidation_0-rmse:2.0896\tvalidation_1-rmse:3.69317\n",
      "[80]\tvalidation_0-rmse:1.78395\tvalidation_1-rmse:3.86358\n",
      "[90]\tvalidation_0-rmse:1.59182\tvalidation_1-rmse:4.00066\n",
      "Stopping. Best iteration:\n",
      "[45]\tvalidation_0-rmse:3.77016\tvalidation_1-rmse:3.39443\n",
      "\n",
      "Parameters are finished for learning_rate. Best Iteration is 22\n",
      "Minimum Rmse : 3.278419, optimum parameter is 0.1 between [0.05]\n"
     ]
    }
   ],
   "source": [
    "defaultParams = {\"max_depth\":10, \"subsample\":1., \"min_child_weight\":5, \"colsample_bytree\":0.4, \"missing\":np.nan\n",
    "                ,\"n_estimators\":300, \"learning_rate\":0.1}\n",
    "testParams = [(\"max_depth\",[12,8,6,14]), (\"subsample\",[0.9,0.8,0.6]), (\"min_child_weight\",[1,3,7]),\n",
    "                  (\"colsample_bytree\",[0.3,0.5,0.6, 0.8,1]), (\"learning_rate\",[0.05])]\n",
    "fitParams = {\"verbose\":10, \"early_stopping_rounds\": 50}\n",
    "\n",
    "GiveBestParameterWithoutCV(defaultParams,testParams, X_train, X_test, y_train, y_test, fitParams )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Start from 10 and play up down..\n",
    "max_depth = [12,8,6,14]\n",
    "subsample = [0.8,0.6]\n",
    "min_child_weight = [3,7]\n",
    "colsample_bytree = [0.3,0.5,0.8,1]\n",
    "#lambdaa = [0.01, 0.1, 1]\n",
    "#alpha = [0.01, 0.1]\n",
    "#Use this eta to find the optimum iteration\n",
    "eta = [0.05]\n",
    "\n",
    "xgb_model.fit(X_train,y_train,eval_set=[(X_train, y_train),(X_test, y_test)],\n",
    "         verbose=1, early_stopping_rounds = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "3.764692"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-77f616839564>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.4,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=4, missing=None, n_estimators=300, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1.0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.set_params(**{\"min_child_weight\":4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.get_xgb_params()[\"min_child_weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = OrderedDict({\"max_depth\":10, \"subsample\":1., \"min_child_weight\":5, \"colsample_bytree\":0.4, \"missing\":np.nan\n",
    "                ,\"n_estimators\":300, \"learning_rate\":0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('colsample_bytree', 0.4), ('missing', nan), ('learning_rate', 0.1), ('min_child_weight', 5), ('n_estimators', 300), ('subsample', 1.0), ('max_depth', 10)])\n",
      "OrderedDict([('colsample_bytree', 0.4), ('missing', nan), ('learning_rate', 0.1), ('min_child_weight', 5), ('n_estimators', 300), ('subsample', 1.0), ('max_depth', 10)])\n",
      "OrderedDict([('colsample_bytree', 0.4), ('missing', nan), ('learning_rate', 0.1), ('min_child_weight', 5), ('n_estimators', 300), ('subsample', 1.0), ('max_depth', 10)])\n",
      "OrderedDict([('colsample_bytree', 0.4), ('missing', nan), ('learning_rate', 0.1), ('min_child_weight', 5), ('n_estimators', 300), ('subsample', 1.0), ('max_depth', 10)])\n",
      "OrderedDict([('colsample_bytree', 0.4), ('missing', nan), ('learning_rate', 0.1), ('min_child_weight', 5), ('n_estimators', 300), ('subsample', 1.0), ('max_depth', 10)])\n",
      "OrderedDict([('colsample_bytree', 0.4), ('missing', nan), ('learning_rate', 0.1), ('min_child_weight', 5), ('n_estimators', 300), ('subsample', 1.0), ('max_depth', 10)])\n",
      "OrderedDict([('colsample_bytree', 0.4), ('missing', nan), ('learning_rate', 0.1), ('min_child_weight', 5), ('n_estimators', 300), ('subsample', 1.0), ('max_depth', 10)])\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qwe = [(\"max_depth\",[12,8]), (\"subsample\",[0.8,0.6]), (\"min_child_weight\",[3,7]),\n",
    "                  (\"colsample_bytree\",[0.3,0.5,0.8,1]), (\"learning_rate\",[0.05])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('max_depth', [12, 8])\n",
      "('subsample', [0.8, 0.6])\n",
      "('min_child_weight', [3, 7])\n",
      "('colsample_bytree', [0.3, 0.5, 0.8, 1])\n",
      "('learning_rate', [0.05])\n"
     ]
    }
   ],
   "source": [
    "for i in qwe:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
