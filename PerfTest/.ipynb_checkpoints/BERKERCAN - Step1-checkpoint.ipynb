{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import datasets, linear_model,preprocessing\n",
    "from datetime import datetime\n",
    "import gc\n",
    "%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "from pprint import pprint\n",
    "import time\n",
    "import nltk.corpus\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take 1 CSV, then split it to 3..\n",
    "class FeatureEngineering:\n",
    "\n",
    "    def __init__(self, ValidationStart, ValidationEnd, trainHdfPath, trainHdfFile, testHdfPath1, testHdfPath2, testHdfFile, \n",
    "                 testTypes, trainTypes, trainCsvPath, testCsvPath, maxLag=0):\n",
    "        self.ValidationStart = ValidationStart\n",
    "        self.ValidationEnd = ValidationEnd\n",
    "        self.maxLag = maxLag\n",
    "        self.trainHdfPath = trainHdfPath\n",
    "        self.trainHdfFile = trainHdfFile\n",
    "        self.testHdfPath1 = testHdfPath1\n",
    "        self.testHdfPath2 = testHdfPath2\n",
    "        self.testHdfFile = testHdfFile\n",
    "        self.testTypes = testTypes\n",
    "        self.trainTypes = trainTypes\n",
    "        self.trainCsvPath = trainCsvPath\n",
    "        self.testCsvPath = testCsvPath\n",
    "        \n",
    "    @staticmethod\n",
    "    def __printDataFrameBasics__(data):\n",
    "        display(data.head(2))\n",
    "        #print data.dtypes\n",
    "        gc.collect()\n",
    "        print(data.info(memory_usage=True))\n",
    "        \n",
    "    @staticmethod    \n",
    "    def changeIndexTypeToLowerMemory(data):\n",
    "        ##########\n",
    "        #This is very critical, i accept max number is 2^32. Also, if don't do that, memory gets so much higher..\n",
    "        ##########\n",
    "        #data.reset_index(inplace=True)\n",
    "        #data.drop(\"index\",axis=1, inplace=True)\n",
    "        #data.index = data.index.astype('uint32')\n",
    "        gc.collect()\n",
    "        \n",
    "    def ReadHdf(self, trainOrTestOrBoth):\n",
    "        '''Reads and holds Df in object memory'''            \n",
    "        if trainOrTestOrBoth == 'train' or trainOrTestOrBoth=='both':\n",
    "            self.train = pd.read_hdf(self.trainHdfPath,self.trainHdfFile)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.train)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.train)\n",
    "            \n",
    "        if trainOrTestOrBoth == 'test' or trainOrTestOrBoth=='both':\n",
    "            self.test1 = pd.read_hdf(self.testHdfPath1,self.testHdfFile)\n",
    "            self.test2 = pd.read_hdf(self.testHdfPath2,self.testHdfFile)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.test1)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.test2)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test1)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test2)\n",
    "        \n",
    "    def ReadCsv(self, trainOrTestOrBoth):\n",
    "        '''Reads and holds Df in memory'''\n",
    "        if trainOrTestOrBoth == 'train' or trainOrTestOrBoth == 'both':\n",
    "            self.train = pd.read_csv(self.trainCsvPath, usecols=self.trainTypes.keys(), dtype=self.trainTypes)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.train)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.train)\n",
    "        if trainOrTestOrBoth == 'test' or trainOrTestOrBoth=='both':\n",
    "            tempTest = pd.read_csv(self.testCsvPath, usecols=self.testTypes.keys(), dtype=self.testTypes)\n",
    "            self.test1 = tempTest.loc[tempTest.Semana.values == self.ValidationStart]\n",
    "            self.test2 = tempTest.loc[tempTest.Semana.values == self.ValidationEnd]\n",
    "            del tempTest\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.test1)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.test2)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test1)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test2)\n",
    "            \n",
    "    @staticmethod\n",
    "    def ConvertCsvToHdf(csvPath, HdfPath, HdfName, ColumnTypeDict ):\n",
    "        tempDf = pd.read_csv(csvPath, usecols=ColumnTypeDict.keys(), dtype=ColumnTypeDict,index=False)\n",
    "        tempDf.to_hdf(HdfPath, HdfName, format='t')\n",
    "        del tempDf\n",
    "        gc.collect()\n",
    "        print \"ConvertCsvToHdf is done..\"\n",
    "\n",
    "    def Preprocess(self, trainOrTestOrBoth, columnFunctionTypeList):\n",
    "        '''columnFunctionTypeList = [ ['C1',Func1,Type], ['C2',Func2,Type],..    ]'''\n",
    "        for column, func, localType in columnFunctionTypeList:\n",
    "            if trainOrTestOrBoth == 'train' or trainOrTestOrBoth =='both':\n",
    "                self.train.loc[:,column] =  np.apply_along_axis(func,0,FE.train[column].values).astype(localType)\n",
    "                #np.apply_along_axis(lambda x: x+1,0,FE.train[\"Semana\"]).astype(\"int32\")\n",
    "            if trainOrTestOrBoth == 'test' or trainOrTestOrBoth == 'both':\n",
    "                self.test1.loc[:,column] =  np.apply_along_axis(func,0,FE.test1[column].values).astype(localType)\n",
    "                self.test2.loc[:,column] =  np.apply_along_axis(func,0,FE.test2[column].values).astype(localType)\n",
    "        gc.collect()\n",
    "        \n",
    "    def SaveDataFrameToHdf(self,trainOrTestOrBoth):\n",
    "        if trainOrTestOrBoth == 'train' or trainOrTestOrBoth=='both':\n",
    "            self.train.to_hdf(self.trainHdfPath, self.trainHdfFile, format='t', index=\"False\")\n",
    "        if trainOrTestOrBoth == 'test' or trainOrTestOrBoth=='both':\n",
    "            self.test1.to_hdf(self.testHdfPath1, self.testHdfFile, format='t', index=\"False\")\n",
    "            self.test2.to_hdf(self.testHdfPath2, self.testHdfFile, format='t', index=\"False\")\n",
    "        \n",
    "    def AddDemandaGeneralMean(self,trainOrTestOrBoth): \n",
    "        #self.train.loc[:,\"DemandaGeneralMean\"] = self.train[\"Demanda_uni_equil\"].loc[\n",
    "         #   self.train.loc[:,'Semana'] < 10].mean().astype(\"float32\")\n",
    "            \n",
    "        meanOfDemanda = self.train[\"Demanda_uni_equil\"].values.mean().astype(\"float32\")\n",
    "        \n",
    "        if trainOrTestOrBoth == 'train' or trainOrTestOrBoth=='both':\n",
    "            self.train.loc[:,\"DemandaGeneralMean\"] = meanOfDemanda\n",
    "        if trainOrTestOrBoth == 'test' or trainOrTestOrBoth=='both':\n",
    "            self.test1.loc[:,\"DemandaGeneralMean\"] = meanOfDemanda\n",
    "            self.test2.loc[:,\"DemandaGeneralMean\"] = meanOfDemanda\n",
    "        \n",
    "        #self.train.loc[:,\"DemandaGeneralMean\"] = self.train[\"Demanda_uni_equil\"].values[\n",
    "        #(self.train.loc[:,'Semana'].values < self.ValidationStart).values].mean().astype(\"float32\")\n",
    "        gc.collect()\n",
    "        \n",
    "    '''ConfigElements(0,[ (\"A\",[\"Semana\",\"Agencia_ID\"],[\"count\",\"count\"]),'''\n",
    "    def AddConfigurableFeaturesToTrain(self, config):\n",
    "        if config.lag > self.maxLag:\n",
    "            self.maxLag = config.lag\n",
    "        \n",
    "        tempData = self.train[self.train['Semana'].values <= (self.ValidationEnd - config.lag)]\n",
    "        #display(tempData)\n",
    "        if(config.lag != 0):\n",
    "            tempData.loc[:,'Semana'] = tempData['Semana'].values + config.lag\n",
    "        #display(tempData)\n",
    "        \n",
    "        #Means iterative.. eliminate as long as np.nan exists..If there is already one, don't create, use the existing\n",
    "        if config.targetVariable != \"\" and  config.targetVariable not in self.train.columns:\n",
    "            self.train.loc[:,config.targetVariable] = np.nan\n",
    "            self.test1.loc[:,config.targetVariable] = np.nan\n",
    "            \n",
    "            if config.lag != 1:\n",
    "                self.test2.loc[:,config.targetVariable] = np.nan\n",
    "        \n",
    "        for name,groups,aggregate in config.nameAndGroups:\n",
    "            if name not in self.train.columns:\n",
    "                print \"{} is not in columns..\".format(name)            \n",
    "                \n",
    "                groupedDataframe = tempData[groups+['Demanda_uni_equil']].copy().groupby(groups).agg(aggregate[0])\n",
    "                gc.collect()\n",
    "                #groupedDataframe.columns = groupedDataframe.columns.droplevel(0)\n",
    "                groupedDataframe.columns = [name]\n",
    "                \n",
    "                #This is means of the counts of the semana-columns tuples!..!!!\n",
    "                #If no lag and mean, mean of the columns without semana!!..\n",
    "                #If there is lag and count, count of the columns x weeks before\n",
    "                #If there is lag and mean, mean of the columns x weeks before\n",
    "                #if(config.lag == 0 and aggregate == \"count\"):\n",
    "                if(len(aggregate)>1):\n",
    "                    groupedDataframe.reset_index(inplace=True)\n",
    "                    groupedDataframe.drop(\"Semana\",axis=1, inplace=True)\n",
    "                    groups = groups[1:]\n",
    "                    groupedDataframe = groupedDataframe.groupby(groups).agg(aggregate[1])\n",
    "                    groupedDataframe.columns = [name]\n",
    "                    gc.collect()\n",
    "                \n",
    "                display(groupedDataframe)\n",
    "                self.train = self.train.merge( groupedDataframe, left_on=groups,\n",
    "                    right_index=True, how='left', sort=False,copy=False)\n",
    "                gc.collect()\n",
    "                self.test1 = self.test1.merge( groupedDataframe, left_on=groups,\n",
    "                    right_index=True, how='left', sort=False,copy=False)\n",
    "                gc.collect()\n",
    "                if config.lag != 1:\n",
    "                    self.test2 = self.test2.merge( groupedDataframe, left_on=groups,\n",
    "                        right_index=True, how='left', sort=False,copy=False)\n",
    "                \n",
    "                del groupedDataframe\n",
    "                gc.collect()\n",
    "            else:\n",
    "                print \"{} is in columns..\".format(name)\n",
    "            \n",
    "            display(self.train)\n",
    "            display(self.test1)\n",
    "            display(self.test2)\n",
    "            \n",
    "            #Means iterative..!!!!!\n",
    "            if config.targetVariable != \"\":\n",
    "                self.train.loc[pd.isnull(self.train[config.targetVariable].values), \n",
    "                    config.targetVariable] = self.train.loc[pd.isnull(self.train[config.targetVariable].values)\n",
    "                    , name].values\n",
    "                self.test1.loc[pd.isnull(self.test1[config.targetVariable].values), \n",
    "                    config.targetVariable] = self.test1.loc[pd.isnull(self.test1[config.targetVariable].values),\n",
    "                    name].values\n",
    "                if config.lag != 1:\n",
    "                    self.test2.loc[pd.isnull(self.test2[config.targetVariable].values), \n",
    "                        config.targetVariable] = self.test2.loc[pd.isnull(self.test2[config.targetVariable].values)\n",
    "                        , name].values\n",
    "                    \n",
    "                count = self.test1[config.targetVariable].isnull().sum()\n",
    "                print \"Count of missing numbers after {} in validation part 1 in column {} is {}\".format(name, \n",
    "                    config.targetVariable,str(count))\n",
    "                if config.lag != 1:\n",
    "                    count = self.test2.loc[:,config.targetVariable].isnull().sum()\n",
    "                    print \"Count of missing numbers after {} in validation part 2 in column {} is {}\".format(name, \n",
    "                        config.targetVariable,str(count))\n",
    "                \n",
    "                \n",
    "                #display(self.train)\n",
    "                #If column is already in Dataframe and we want to fill target variable, this deletes columns!!!\n",
    "                if(config.deleteColumns):\n",
    "                    self.train.drop(name, axis=1, inplace=True)\n",
    "                    self.test1.drop(name, axis=1, inplace=True)\n",
    "                    if config.lag != 1:\n",
    "                        self.test2.drop(name, axis=1, inplace=True)\n",
    "                gc.collect()\n",
    "                #Only in tesst\n",
    "                #if count == 0:\n",
    "                 #   break\n",
    "        del tempData\n",
    "        display(self.train)   \n",
    "        display(self.test1)   \n",
    "        display(self.test2)\n",
    "        gc.collect()\n",
    "        return \n",
    "    \n",
    "    def DeleteLaggedWeeksFromTrain(self):\n",
    "        self.train = self.train[self.train['Semana'].values >= (3 + self.maxLag)]\n",
    "        gc.collect()\n",
    "        display(self.train.head(2))\n",
    "        \n",
    "    def ReadFirstNRowsOfACsv(self, nrows, trainOrTestOrBoth) :\n",
    "        if trainOrTestOrBoth == 'train' or trainOrTestOrBoth=='both':\n",
    "            self.train = pd.read_csv(self.trainCsvPath, usecols=self.trainTypes.keys(), dtype=self.trainTypes, nrows = nrows)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.train)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.train)\n",
    "        if trainOrTestOrBoth == 'test' or trainOrTestOrBoth=='both':\n",
    "            tempTest = pd.read_csv(self.testCsvPath, usecols=self.testTypes.keys(), dtype=self.testTypes, nrows = nrows*2)\n",
    "            self.test1 = tempTest.loc[tempTest.Semana == self.ValidationStart]\n",
    "            self.test2 = tempTest.loc[tempTest.Semana == self.ValidationEnd]\n",
    "            del tempTest\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.test1)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.test2)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test1)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test2)\n",
    "    \n",
    "    #Use when concatanating train and validation before predict test for example..\n",
    "    def AppendTestToTrain(self,deleteTest = True):\n",
    "        self.train = self.train.append(self.test1,ignore_index=True)\n",
    "        gc.collect()\n",
    "        if(deleteTest):\n",
    "            del self.test1\n",
    "            gc.collect()\n",
    "        try:\n",
    "            self.train = self.train.append(self.test2,ignore_index=True)\n",
    "            gc.collect()\n",
    "            if(deleteTest):\n",
    "                del self.test2\n",
    "                gc.collect()\n",
    "        except:\n",
    "            pass\n",
    "        #BAD PERFORMANCE!!\n",
    "    #Split train data to train and test1 and test2 (validation)\n",
    "    #def SplitTrainToTestUsingValidationStart(self):\n",
    "     #   boolCondition = self.train.Semana == self.ValidationStart\n",
    "      #  self.test1 = self.train.loc[boolCondition]\n",
    "       # self.train.drop((self.train.loc[boolCondition].index), axis=0,inplace=True)\n",
    "        \n",
    "       # boolCondition = self.train.Semana == self.ValidationEnd\n",
    "       # self.test2 = self.train.loc[boolCondition]\n",
    "       # self.train.drop((self.train.loc[boolCondition].index), axis=0,inplace=True)\n",
    "      #  del boolCondition\n",
    "      #  gc.collect()\n",
    "    \n",
    "    #Reaches 3x memory from train, because of test1, test2 and train itself at the end.. GC fixed in the end..\n",
    "    def SplitTrainToTestUsingValidationStart(self):\n",
    "        boolCondition = self.train.Semana.values == self.ValidationStart\n",
    "        self.test1 = self.train[boolCondition]\n",
    "        boolCondition = self.train.Semana.values == self.ValidationEnd\n",
    "        self.test2 = self.train[boolCondition]\n",
    "        FE.train = FE.train[ FE.train.Semana.values < FE.ValidationStart ]\n",
    "        del boolCondition\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trainCsvPath': '../../input/train.csv', 'maxLag': 3, 'testTypes': {'Cliente_ID': <type 'numpy.uint32'>, 'Ruta_SAK': <type 'numpy.uint16'>, 'Canal_ID': <type 'numpy.uint8'>, 'Producto_ID': <type 'numpy.uint16'>, 'Agencia_ID': <type 'numpy.uint16'>, 'Semana': <type 'numpy.uint8'>, 'id': <type 'numpy.uint32'>}, 'testHdfFile': 'test', 'trainTypes': {'Dev_proxima': <type 'numpy.float32'>, 'Venta_uni_hoy': <type 'numpy.uint16'>, 'Cliente_ID': <type 'numpy.uint32'>, 'Demanda_uni_equil': <type 'numpy.uint32'>, 'Ruta_SAK': <type 'numpy.uint16'>, 'Canal_ID': <type 'numpy.uint8'>, 'Venta_hoy': <type 'numpy.float32'>, 'Producto_ID': <type 'numpy.uint16'>, 'Agencia_ID': <type 'numpy.uint16'>, 'Dev_uni_proxima': <type 'numpy.uint32'>, 'Semana': <type 'numpy.uint8'>}, 'testHdfPath1': '../../input/test1.h5', 'ValidationEnd': 9, 'testHdfPath2': '../../input/test2.h5', 'testCsvPath': '../../input/test.csv', 'ValidationStart': 8, 'trainHdfFile': 'train', 'trainHdfPath': '../../input/train.h5'}\n"
     ]
    }
   ],
   "source": [
    "parameterDict =       {\"ValidationStart\":8, \n",
    " \"ValidationEnd\":9,\n",
    "   \"maxLag\":3,\n",
    "    \"trainHdfPath\":'../../input/train.h5',\n",
    "    \"trainHdfFile\":\"train\",\n",
    "    \"testHdfPath1\":\"../../input/test1.h5\",\n",
    "    \"testHdfPath2\":\"../../input/test2.h5\",\n",
    "    \"testHdfFile\":\"test\", \n",
    "    \"trainTypes\" : {'Semana':np.uint8, 'Agencia_ID':np.uint16, 'Canal_ID':np.uint8,'Ruta_SAK':np.uint16, \n",
    "        'Cliente_ID':np.uint32, 'Producto_ID':np.uint16,'Venta_uni_hoy':np.uint16, 'Venta_hoy':np.float32,\n",
    "                    'Dev_uni_proxima': np.uint32, 'Dev_proxima':np.float32,'Demanda_uni_equil':np.uint32}, \n",
    "    \"testTypes\" : {'id':np.uint32,'Semana':np.uint8, 'Agencia_ID':np.uint16, 'Canal_ID':np.uint8,'Ruta_SAK':np.uint16,\n",
    "        'Cliente_ID':np.uint32, 'Producto_ID':np.uint16},\n",
    "    \"trainCsvPath\":'../../input/train.csv'   ,\n",
    "    \"testCsvPath\":'../../input/test.csv'}\n",
    "\n",
    "FE = FeatureEngineering(**parameterDict)\n",
    "print FE.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Venta_uni_hoy</th>\n",
       "      <th>Venta_hoy</th>\n",
       "      <th>Dev_uni_proxima</th>\n",
       "      <th>Dev_proxima</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1212</td>\n",
       "      <td>3</td>\n",
       "      <td>25.139999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1216</td>\n",
       "      <td>4</td>\n",
       "      <td>33.520000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID  \\\n",
       "0       3        1110         7      3301       15766         1212   \n",
       "1       3        1110         7      3301       15766         1216   \n",
       "\n",
       "   Venta_uni_hoy  Venta_hoy  Dev_uni_proxima  Dev_proxima  Demanda_uni_equil  \n",
       "0              3  25.139999                0          0.0                  3  \n",
       "1              4  33.520000                0          0.0                  4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74180464 entries, 0 to 74180463\n",
      "Data columns (total 11 columns):\n",
      "Semana               uint8\n",
      "Agencia_ID           uint16\n",
      "Canal_ID             uint8\n",
      "Ruta_SAK             uint16\n",
      "Cliente_ID           uint32\n",
      "Producto_ID          uint16\n",
      "Venta_uni_hoy        uint16\n",
      "Venta_hoy            float32\n",
      "Dev_uni_proxima      uint32\n",
      "Dev_proxima          float32\n",
      "Demanda_uni_equil    uint32\n",
      "dtypes: float32(2), uint16(4), uint32(3), uint8(2)\n",
      "memory usage: 2.1 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "FE.ReadCsv('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add DemandaNotEqualTheDifferenceOfVentaUniAndDev to model products delivered later.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.train.loc[:,\"DemandaNotEqualTheDifferenceOfVentaUniAndDev\"] = FE.train.Demanda_uni_equil.values < (\n",
    "    FE.train.Venta_uni_hoy.values - FE.train.Dev_uni_proxima.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615828"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE.train.DemandaNotEqualTheDifferenceOfVentaUniAndDev.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Venta_uni_hoy</th>\n",
       "      <th>Venta_hoy</th>\n",
       "      <th>Dev_uni_proxima</th>\n",
       "      <th>Dev_proxima</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "      <th>DemandaNotEqualTheDifferenceOfVentaUniAndDev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>198780</td>\n",
       "      <td>1187</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>297.00</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>1307034</td>\n",
       "      <td>739</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>166.00</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>2336454</td>\n",
       "      <td>1187</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>148.50</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3302</td>\n",
       "      <td>319684</td>\n",
       "      <td>30571</td>\n",
       "      <td>3</td>\n",
       "      <td>18.75</td>\n",
       "      <td>150</td>\n",
       "      <td>937.50</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3302</td>\n",
       "      <td>1614050</td>\n",
       "      <td>4245</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>10.48</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID  \\\n",
       "91        3        1110         7      3301      198780         1187   \n",
       "230       3        1110         7      3301     1307034          739   \n",
       "385       3        1110         7      3301     2336454         1187   \n",
       "594       3        1110         7      3302      319684        30571   \n",
       "715       3        1110         7      3302     1614050         4245   \n",
       "\n",
       "     Venta_uni_hoy  Venta_hoy  Dev_uni_proxima  Dev_proxima  \\\n",
       "91               0       0.00                2       297.00   \n",
       "230              0       0.00                2       166.00   \n",
       "385              0       0.00                1       148.50   \n",
       "594              3      18.75              150       937.50   \n",
       "715              0       0.00                1        10.48   \n",
       "\n",
       "     Demanda_uni_equil DemandaNotEqualTheDifferenceOfVentaUniAndDev  \n",
       "91                   0                                         True  \n",
       "230                  0                                         True  \n",
       "385                  0                                         True  \n",
       "594                  0                                         True  \n",
       "715                  0                                         True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE.train[FE.train[\"DemandaNotEqualTheDifferenceOfVentaUniAndDev\"].values].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74180464 entries, 0 to 74180463\n",
      "Data columns (total 12 columns):\n",
      "Semana                                          uint8\n",
      "Agencia_ID                                      uint16\n",
      "Canal_ID                                        uint8\n",
      "Ruta_SAK                                        uint16\n",
      "Cliente_ID                                      uint32\n",
      "Producto_ID                                     uint16\n",
      "Venta_uni_hoy                                   uint16\n",
      "Venta_hoy                                       float32\n",
      "Dev_uni_proxima                                 uint32\n",
      "Dev_proxima                                     float32\n",
      "Demanda_uni_equil                               uint32\n",
      "DemandaNotEqualTheDifferenceOfVentaUniAndDev    bool\n",
      "dtypes: bool(1), float32(2), uint16(4), uint32(3), uint8(2)\n",
      "memory usage: 2.1 GB\n"
     ]
    }
   ],
   "source": [
    "FE.train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Demanda = 0  and Venta = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FE.train = FE.train[(FE.train.Demanda_uni_equil.values != 0) & (FE.train.Venta_uni_hoy.values != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 72843643 entries, 0 to 74180463\n",
      "Data columns (total 12 columns):\n",
      "Semana                                          uint8\n",
      "Agencia_ID                                      uint16\n",
      "Canal_ID                                        uint8\n",
      "Ruta_SAK                                        uint16\n",
      "Cliente_ID                                      uint32\n",
      "Producto_ID                                     uint16\n",
      "Venta_uni_hoy                                   uint16\n",
      "Venta_hoy                                       float32\n",
      "Dev_uni_proxima                                 uint32\n",
      "Dev_proxima                                     float32\n",
      "Demanda_uni_equil                               uint32\n",
      "DemandaNotEqualTheDifferenceOfVentaUniAndDev    bool\n",
      "dtypes: bool(1), float32(2), uint16(4), uint32(3), uint8(2)\n",
      "memory usage: 2.6 GB\n"
     ]
    }
   ],
   "source": [
    "FE.train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Venta_uni_hoy</th>\n",
       "      <th>Venta_hoy</th>\n",
       "      <th>Dev_uni_proxima</th>\n",
       "      <th>Dev_proxima</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "      <th>DemandaNotEqualTheDifferenceOfVentaUniAndDev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1212</td>\n",
       "      <td>3</td>\n",
       "      <td>25.139999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1216</td>\n",
       "      <td>4</td>\n",
       "      <td>33.520000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID  \\\n",
       "0       3        1110         7      3301       15766         1212   \n",
       "1       3        1110         7      3301       15766         1216   \n",
       "\n",
       "   Venta_uni_hoy  Venta_hoy  Dev_uni_proxima  Dev_proxima  Demanda_uni_equil  \\\n",
       "0              3  25.139999                0          0.0                  3   \n",
       "1              4  33.520000                0          0.0                  4   \n",
       "\n",
       "  DemandaNotEqualTheDifferenceOfVentaUniAndDev  \n",
       "0                                        False  \n",
       "1                                        False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE.train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge town and products.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 790 entries, 0 to 789\n",
      "Data columns (total 3 columns):\n",
      "Agencia_ID    790 non-null uint16\n",
      "Town_ID       790 non-null uint16\n",
      "State_ID      790 non-null uint8\n",
      "dtypes: uint16(2), uint8(1)\n",
      "memory usage: 3.9 KB\n"
     ]
    }
   ],
   "source": [
    "townstate = pd.read_csv(\"../../input/town_state.csv\", encoding='utf-8')\n",
    "townstate['Town_ID']=townstate['Town'].str[:4]\n",
    "states = townstate['State']\n",
    "le = preprocessing.LabelEncoder()\n",
    "townstate['State_ID']=le.fit_transform(states)\n",
    "townstate = townstate.drop(['Town', 'State'], axis=1)\n",
    "townstate = townstate.astype('uint16')\n",
    "townstate[['State_ID']] =townstate[['State_ID']] .astype('uint8')\n",
    "townstate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2592 entries, 0 to 2591\n",
      "Data columns (total 5 columns):\n",
      "Producto_ID     2592 non-null uint16\n",
      "weight          2592 non-null uint16\n",
      "pieces          2592 non-null uint8\n",
      "Prod_name_ID    2592 non-null uint16\n",
      "Brand_ID        2592 non-null uint8\n",
      "dtypes: uint16(3), uint8(2)\n",
      "memory usage: 20.3 KB\n"
     ]
    }
   ],
   "source": [
    "products = pd.read_csv(\"../../input/producto_tabla.csv\")\n",
    "products['short_name'] = products.NombreProducto.str.extract('^(\\D*)', expand=False)\n",
    "products['brand'] = products.NombreProducto.str.extract('^.+\\s(\\D+) \\d+$', expand=False)\n",
    "w = products.NombreProducto.str.extract('(\\d+)(Kg|g)', expand=True)\n",
    "products['weight'] = w[0].astype('float') * w[1].map({'Kg': 1000, 'g': 1})\n",
    "products['pieces'] = products.NombreProducto.str.extract('(\\d+)p ', expand=False).astype('float')\n",
    "\n",
    "products['short_name_processed'] = (products['short_name'].\n",
    "                                    map(lambda x: \" \".\n",
    "                                        join([i for i in x.lower().split() \n",
    "                                              if i not in nltk.corpus.stopwords.words(\"spanish\")])))\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "products['short_name_processed'] = (products['short_name_processed'].\n",
    "                                    map(lambda x: \" \".join([stemmer.stem(i) for i in x.lower().split()])))\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "products['Prod_name_ID']=le.fit_transform(products['short_name_processed'])\n",
    "products['Brand_ID']=le.fit_transform(products['brand'])\n",
    "\n",
    "products = products.drop(['short_name', 'brand', 'short_name_processed', 'NombreProducto'], axis=1)\n",
    "products.fillna(value=0, inplace=True)\n",
    "products[['pieces','Brand_ID']] = products[['pieces','Brand_ID']].astype('uint8')\n",
    "products[['Producto_ID','weight', 'Prod_name_ID']] = products[['Producto_ID','weight', 'Prod_name_ID']].astype('uint16')\n",
    "products.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE.train = pd.merge(FE.train, products, on='Producto_ID', how='left', sort=False,copy=False)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE.train = pd.merge(FE.train, townstate, on='Agencia_ID', how='left', sort=False,copy=False)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 72843643 entries, 0 to 72843642\n",
      "Data columns (total 18 columns):\n",
      "Semana                                          uint8\n",
      "Agencia_ID                                      uint16\n",
      "Canal_ID                                        uint8\n",
      "Ruta_SAK                                        uint16\n",
      "Cliente_ID                                      uint32\n",
      "Producto_ID                                     uint16\n",
      "Venta_uni_hoy                                   uint16\n",
      "Venta_hoy                                       float32\n",
      "Dev_uni_proxima                                 uint32\n",
      "Dev_proxima                                     float32\n",
      "Demanda_uni_equil                               uint32\n",
      "DemandaNotEqualTheDifferenceOfVentaUniAndDev    bool\n",
      "weight                                          uint16\n",
      "pieces                                          uint8\n",
      "Prod_name_ID                                    uint16\n",
      "Brand_ID                                        uint8\n",
      "Town_ID                                         uint16\n",
      "State_ID                                        uint8\n",
      "dtypes: bool(1), float32(2), uint16(7), uint32(3), uint8(5)\n",
      "memory usage: 3.3 GB\n"
     ]
    }
   ],
   "source": [
    "FE.train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Venta_uni_hoy</th>\n",
       "      <th>Venta_hoy</th>\n",
       "      <th>Dev_uni_proxima</th>\n",
       "      <th>Dev_proxima</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "      <th>DemandaNotEqualTheDifferenceOfVentaUniAndDev</th>\n",
       "      <th>weight</th>\n",
       "      <th>pieces</th>\n",
       "      <th>Prod_name_ID</th>\n",
       "      <th>Brand_ID</th>\n",
       "      <th>Town_ID</th>\n",
       "      <th>State_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1212</td>\n",
       "      <td>3</td>\n",
       "      <td>25.139999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>709</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID  \\\n",
       "0       3        1110         7      3301       15766         1212   \n",
       "\n",
       "   Venta_uni_hoy  Venta_hoy  Dev_uni_proxima  Dev_proxima  Demanda_uni_equil  \\\n",
       "0              3  25.139999                0          0.0                  3   \n",
       "\n",
       "  DemandaNotEqualTheDifferenceOfVentaUniAndDev  weight  pieces  Prod_name_ID  \\\n",
       "0                                        False     120       2           709   \n",
       "\n",
       "   Brand_ID  Town_ID  State_ID  \n",
       "0         4     2008        16  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE.train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FE.SaveDataFrameToHdf('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Venta_uni_hoy</th>\n",
       "      <th>Venta_hoy</th>\n",
       "      <th>Dev_uni_proxima</th>\n",
       "      <th>Dev_proxima</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "      <th>DemandaNotEqualTheDifferenceOfVentaUniAndDev</th>\n",
       "      <th>weight</th>\n",
       "      <th>pieces</th>\n",
       "      <th>Prod_name_ID</th>\n",
       "      <th>Brand_ID</th>\n",
       "      <th>Town_ID</th>\n",
       "      <th>State_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1212</td>\n",
       "      <td>3</td>\n",
       "      <td>25.139999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>709</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1216</td>\n",
       "      <td>4</td>\n",
       "      <td>33.520000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>135</td>\n",
       "      <td>2</td>\n",
       "      <td>712</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1238</td>\n",
       "      <td>4</td>\n",
       "      <td>39.320000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "      <td>630</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1240</td>\n",
       "      <td>4</td>\n",
       "      <td>33.520000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>480</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1242</td>\n",
       "      <td>3</td>\n",
       "      <td>22.920000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>105</td>\n",
       "      <td>6</td>\n",
       "      <td>271</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID  \\\n",
       "0       3        1110         7      3301       15766         1212   \n",
       "1       3        1110         7      3301       15766         1216   \n",
       "2       3        1110         7      3301       15766         1238   \n",
       "3       3        1110         7      3301       15766         1240   \n",
       "4       3        1110         7      3301       15766         1242   \n",
       "\n",
       "   Venta_uni_hoy  Venta_hoy  Dev_uni_proxima  Dev_proxima  Demanda_uni_equil  \\\n",
       "0              3  25.139999                0          0.0                  3   \n",
       "1              4  33.520000                0          0.0                  4   \n",
       "2              4  39.320000                0          0.0                  4   \n",
       "3              4  33.520000                0          0.0                  4   \n",
       "4              3  22.920000                0          0.0                  3   \n",
       "\n",
       "  DemandaNotEqualTheDifferenceOfVentaUniAndDev  weight  pieces  Prod_name_ID  \\\n",
       "0                                        False     120       2           709   \n",
       "1                                        False     135       2           712   \n",
       "2                                        False     140       2           630   \n",
       "3                                        False     125       4           480   \n",
       "4                                        False     105       6           271   \n",
       "\n",
       "   Brand_ID  Town_ID  State_ID  \n",
       "0         4     2008        16  \n",
       "1         4     2008        16  \n",
       "2         4     2008        16  \n",
       "3         4     2008        16  \n",
       "4         4     2008        16  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE.train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train to test1 test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConfigElements:\n",
    "    def __init__(self, lag, nameAndGroups, targetVariable=\"\", deleteColumns = False):\n",
    "        self.lag = lag\n",
    "        self.nameAndGroups = nameAndGroups\n",
    "        #If there is target variable, then 5 4 3 2 1, fill the np.nans..Else hold them all in Dataframe..\n",
    "        self.targetVariable = targetVariable\n",
    "        self.deleteColumns = deleteColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nameAndGroups': [('SA0CC', ['Semana', 'Agencia_ID'], ['count', 'count']), ('A0M', ['Agencia_ID'], ['mean']), ('SAMM', ['Semana', 'Agencia_ID'], ['mean', 'mean'])], 'lag': 0, 'targetVariable': 'lag0tar1V1', 'deleteColumns': False}\n"
     ]
    }
   ],
   "source": [
    "configLag0Target1DeleteColumnsFalse = ConfigElements(0,[ (\"SA0CC\",[\"Semana\",\"Agencia_ID\"],[\"count\",\"count\"]),(\n",
    "    \"A0M\",[\"Agencia_ID\"],[\"mean\"]), (\"SAMM\",[\"Semana\",\"Agencia_ID\"],[\"mean\",\"mean\"])], \"lag0tar1V1\", False)\n",
    "print  configLag0Target1DeleteColumnsFalse.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
