{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import datasets, linear_model\n",
    "from datetime import datetime\n",
    "import gc\n",
    "%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage!!!\n",
    "- Always change maxVal if iterative feature is added..5, for np.nan's add 4, then 3.. maxVal calculates according to this.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConfigElements:\n",
    "    def __init__(self, lag, nameAndGroups, targetVariable=\"\", deleteColumns = False):\n",
    "        self.lag = lag\n",
    "        self.nameAndGroups = nameAndGroups\n",
    "        #If there is target variable, then 5 4 3 2 1, fill the np.nans..Else hold them all in Dataframe..\n",
    "        self.targetVariable = targetVariable\n",
    "        self.deleteColumns = deleteColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nameAndGroups': [('A', ['Semana', 'Ruta_SAK'], ['count', 'count']), ('B', ['Ruta_SAK'], ['mean']), ('C', ['Semana', 'Ruta_SAK'], ['count', 'mean'])], 'lag': 0, 'targetVariable': 'lag0tar1', 'deleteColumns': False}\n"
     ]
    }
   ],
   "source": [
    "configLag0Target1 = ConfigElements(0,[ (\"A\",[\"Semana\",\"Ruta_SAK\"],[\"count\",\"count\"]),(\"B\",[\"Ruta_SAK\"],[\"mean\"]),\n",
    "    (\"C\",[\"Semana\",\"Ruta_SAK\"],[\"count\",\"mean\"])], \"lag0tar1\", False)\n",
    "print  configLag0Target1.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'configLag1Target1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3cbb054a6287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m configLag2Target1 = ConfigElements(2,[ (\"SA21\",[\"Semana\",\"Ruta_SAK\"],[\"count\"]),(\"L21\",[\"Semana\",\"Ruta_SAK\"],[\"mean\"])\n\u001b[1;32m      2\u001b[0m                                      ],\"lag1tar1\")\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mprint\u001b[0m  \u001b[0mconfigLag1Target1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'configLag1Target1' is not defined"
     ]
    }
   ],
   "source": [
    "configLag2Target1 = ConfigElements(2,[ (\"SA21\",[\"Semana\",\"Ruta_SAK\"],[\"count\"]),(\"L21\",[\"Semana\",\"Ruta_SAK\"],[\"mean\"])\n",
    "                                     ],\"lag1tar1\")\n",
    "print  configLag1Target1.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "configLag1Target1 = ConfigElements(1,[ (\"SA2\",[\"Semana\",\"Ruta_SAK\"],[\"count\"]),(\"L\",[\"Semana\",\"Ruta_SAK\"],[\"mean\"])\n",
    "                                     ],\"lag1tar1\")\n",
    "print  configLag1Target1.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "configLag1Target1F = ConfigElements(1,[ (\"SAP1CC\",[\"Semana\",\"Ruta_SAK\",\"Producto_ID\"],\n",
    "                                    [\"count\"]),(\"SAP1MM\",[\"Semana\",\"Ruta_SAK\",\"Producto_ID\"],[\"mean\"])],\"Lag1Target1F\",True\n",
    "                                     )\n",
    "print  configLag0Target1.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test for filling missing values that are already on a column, no need to create a target variable.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#configWithoutLag2 = ConfigElements(0,[ (\"A\",[\"Agencia_ID\"]), (\"Ca\",[\"Canal_ID\"]), (\"R\",[\"Ruta_SAK\"]), \n",
    "#    (\"Cl\",[\"Cliente_ID\"]),(\"P\",[\"Producto_ID\"]),(\"ClP\",[\"Cliente_ID\",\"Producto_ID\"])   ], \"lag2par1\")\n",
    "#print  configWithLag.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#take 1 CSV, then split it to 3..\n",
    "class FeatureEngineering:\n",
    "\n",
    "    def __init__(self, ValidationStart, ValidationEnd, trainHdfPath, trainHdfFile, testHdfPath1, testHdfPath2, testHdfFile, \n",
    "                 testTypes, trainTypes, trainCsvPath, testCsvPath, maxLag=0):\n",
    "        self.ValidationStart = ValidationStart\n",
    "        self.ValidationEnd = ValidationEnd\n",
    "        self.maxLag = maxLag\n",
    "        self.trainHdfPath = trainHdfPath\n",
    "        self.trainHdfFile = trainHdfFile\n",
    "        self.testHdfPath1 = testHdfPath1\n",
    "        self.testHdfPath2 = testHdfPath2\n",
    "        self.testHdfFile = testHdfFile\n",
    "        self.testTypes = testTypes\n",
    "        self.trainTypes = trainTypes\n",
    "        self.trainCsvPath = trainCsvPath\n",
    "        self.testCsvPath = testCsvPath\n",
    "        \n",
    "    @staticmethod\n",
    "    def __printDataFrameBasics__(data):\n",
    "        display(data.head(2))\n",
    "        #print data.dtypes\n",
    "        gc.collect()\n",
    "        print(data.info(memory_usage=True))\n",
    "        \n",
    "    @staticmethod    \n",
    "    def changeIndexTypeToLowerMemory(data):\n",
    "        ##########\n",
    "        #This is very critical, i accept max number is 2^32. Also, if don't do that, memory gets so much higher..\n",
    "        ##########\n",
    "        #data.reset_index(inplace=True)\n",
    "        #data.drop(\"index\",axis=1, inplace=True)\n",
    "        data.index = data.index.astype('uint32')\n",
    "        gc.collect()\n",
    "        \n",
    "    def ReadHdf(self, trainOrTestOrBoth):\n",
    "        '''Reads and holds Df in object memory'''            \n",
    "        if trainOrTestOrBoth == 'train' or trainOrTestOrBoth=='both':\n",
    "            self.train = pd.read_hdf(self.trainHdfPath,self.trainHdfFile)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.train)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.train)\n",
    "            \n",
    "        if trainOrTestOrBoth == 'test' or trainOrTestOrBoth=='both':\n",
    "            self.test1 = pd.read_hdf(self.testHdfPath1,self.testHdfFile)\n",
    "            self.test2 = pd.read_hdf(self.testHdfPath2,self.testHdfFile)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.test1)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.test2)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test1)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test2)\n",
    "        \n",
    "    def ReadCsv(self, trainOrTestOrBoth):\n",
    "        '''Reads and holds Df in memory'''\n",
    "        if trainOrTestOrBoth == 'train' or trainOrTestOrBoth == 'both':\n",
    "            self.train = pd.read_csv(self.trainCsvPath, usecols=self.trainTypes.keys(), dtype=self.trainTypes)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.train)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.train)\n",
    "        if trainOrTestOrBoth == 'test' or trainOrTestOrBoth=='both':\n",
    "            tempTest = pd.read_csv(self.testCsvPath, usecols=self.testTypes.keys(), dtype=self.testTypes)\n",
    "            self.test1 = tempTest.loc[tempTest.Semana == self.ValidationStart]\n",
    "            self.test2 = tempTest.loc[tempTest.Semana == self.ValidationEnd]\n",
    "            del tempTest\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.test1)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.test2)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test1)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test2)\n",
    "            \n",
    "    @staticmethod\n",
    "    def ConvertCsvToHdf(csvPath, HdfPath, HdfName, ColumnTypeDict ):\n",
    "        tempDf = pd.read_csv(csvPath, usecols=ColumnTypeDict.keys(), dtype=ColumnTypeDict,index=False)\n",
    "        tempDf.to_hdf(HdfPath, HdfName, format='t')\n",
    "        del tempDf\n",
    "        gc.collect()\n",
    "        print \"ConvertCsvToHdf is done..\"\n",
    "\n",
    "    def Preprocess(self, trainOrTestOrBoth, columnFunctionTypeList):\n",
    "        '''columnFunctionTypeList = [ ['C1',Func1,Type], ['C2',Func2,Type],..    ]'''\n",
    "        for column, func, localType in columnFunctionTypeList:\n",
    "            if trainOrTestOrBoth == 'train' or trainOrTestOrBoth =='both':\n",
    "                self.train.loc[:,column] =  self.train[column].apply(func).astype(localType)\n",
    "            if trainOrTestOrBoth == 'test' or trainOrTestOrBoth == 'both':\n",
    "                self.test1.loc[:,column] =  self.test1[column].apply(func).astype(localType)\n",
    "                self.test2.loc[:,column] =  self.test2[column].apply(func).astype(localType)\n",
    "        gc.collect()\n",
    "        \n",
    "    def SaveDataFrameToHdf(self,trainOrTestOrBoth):\n",
    "        if trainOrTestOrBoth == 'train' or trainOrTestOrBoth=='both':\n",
    "            self.train.to_hdf(self.trainHdfPath, self.trainHdfFile, format='t', index=\"False\")\n",
    "        if trainOrTestOrBoth == 'test' or trainOrTestOrBoth=='both':\n",
    "            self.test1.to_hdf(self.testHdfPath1, self.testHdfFile, format='t', index=\"False\")\n",
    "            self.test2.to_hdf(self.testHdfPath2, self.testHdfFile, format='t', index=\"False\")\n",
    "        \n",
    "    def AddDemandaGeneralMean(self): \n",
    "        self.train.loc[:,\"DemandaGeneralMean\"] = self.train[\"Demanda_uni_equil\"].loc[\n",
    "            self.train.loc[:,'Semana'] < 10].mean().astype(\"float32\")\n",
    "        #self.train.loc[:,\"DemandaGeneralMean\"] = DemandaMeanWithoutLag['Demanda_uni_equil'].mean()\n",
    "        #self.train.loc[:,\"DemandaGeneralMean\"] = self.train.loc[:,\"DemandaGeneralMean\"].astype('float32')\n",
    "        #display(self.train)\n",
    "        #del DemandaMeanWithoutLag\n",
    "        gc.collect()\n",
    "        \n",
    "    '''ConfigElements(0,[ (\"A\",[\"Semana\",\"Agencia_ID\"],[\"count\",\"count\"]),'''\n",
    "    def AddConfigurableFeaturesToTrain(self, config):\n",
    "        if config.lag > self.maxLag:\n",
    "            self.maxLag = config.lag\n",
    "        \n",
    "        tempData = self.train.loc[self.train.loc[:,'Semana'] <= self.ValidationEnd - config.lag]\n",
    "        #display(tempData)\n",
    "        if(config.lag != 0):\n",
    "            tempData.loc[:,'Semana'] = tempData['Semana'].apply(lambda x:x + config.lag)\n",
    "        #display(tempData)\n",
    "        \n",
    "        #Means iterative.. eliminate as long as np.nan exists..If there is already one, don't create, use the existing\n",
    "        if config.targetVariable != \"\" and  config.targetVariable not in self.train.columns:\n",
    "            self.train.loc[:,config.targetVariable] = np.nan\n",
    "            self.test1.loc[:,config.targetVariable] = np.nan\n",
    "            \n",
    "            if config.lag != 1:\n",
    "                self.test2.loc[:,config.targetVariable] = np.nan\n",
    "        \n",
    "        for name,groups,aggregate in config.nameAndGroups:\n",
    "            if name not in self.train.columns:\n",
    "                print \"{} is not in columns..\".format(name)            \n",
    "                \n",
    "                groupedDataframe = tempData[groups+['Demanda_uni_equil']].groupby(groups).agg(aggregate[0])\n",
    "                #groupedDataframe.columns = groupedDataframe.columns.droplevel(0)\n",
    "                groupedDataframe.columns = [name]\n",
    "                \n",
    "                #This is means of the counts of the semana-columns tuples!..!!!\n",
    "                #If no lag and mean, mean of the columns without semana!!..\n",
    "                #If there is lag and count, count of the columns x weeks before\n",
    "                #If there is lag and mean, mean of the columns x weeks before\n",
    "                #if(config.lag == 0 and aggregate == \"count\"):\n",
    "                if(len(aggregate)>1):\n",
    "                    groupedDataframe.reset_index(inplace=True)\n",
    "                    groupedDataframe.drop(\"Semana\",axis=1, inplace=True)\n",
    "                    groups = groups[1:]\n",
    "                    groupedDataframe = groupedDataframe.groupby(groups).agg(aggregate[1])\n",
    "                    groupedDataframe.columns = [name]\n",
    "                    gc.collect()\n",
    "                \n",
    "                display(groupedDataframe)\n",
    "                self.train = self.train.merge( groupedDataframe, left_on=groups,\n",
    "                    right_index=True, how='left', sort=False,copy=False)\n",
    "                self.test1 = self.test1.merge( groupedDataframe, left_on=groups,\n",
    "                    right_index=True, how='left', sort=False,copy=False)\n",
    "                if config.lag != 1:\n",
    "                    self.test2 = self.test2.merge( groupedDataframe, left_on=groups,\n",
    "                        right_index=True, how='left', sort=False,copy=False)\n",
    "                \n",
    "                del groupedDataframe\n",
    "                gc.collect()\n",
    "            else:\n",
    "                print \"{} is in columns..\".format(name)\n",
    "            \n",
    "            display(self.train)\n",
    "            display(self.test1)\n",
    "            display(self.test2)\n",
    "            \n",
    "            #Means iterative..!!!!!\n",
    "            if config.targetVariable != \"\":\n",
    "                self.train.loc[pd.isnull(self.train[config.targetVariable]), \n",
    "                    config.targetVariable] = self.train.loc[pd.isnull(self.train[config.targetVariable]), name]\n",
    "                self.test1.loc[pd.isnull(self.test1[config.targetVariable]), \n",
    "                    config.targetVariable] = self.test1.loc[pd.isnull(self.test1[config.targetVariable]), name]\n",
    "                if config.lag != 1:\n",
    "                    self.test2.loc[pd.isnull(self.test2[config.targetVariable]), \n",
    "                        config.targetVariable] = self.test2.loc[pd.isnull(self.test2[config.targetVariable]), name]\n",
    "                    \n",
    "                count = self.test1.loc[:,config.targetVariable].isnull().sum()\n",
    "                print \"Count of missing numbers after {} in validation part 1 in column {} is {}\".format(name, \n",
    "                    config.targetVariable,str(count))\n",
    "                if config.lag != 1:\n",
    "                    count = self.test2.loc[:,config.targetVariable].isnull().sum()\n",
    "                    print \"Count of missing numbers after {} in validation part 2 in column {} is {}\".format(name, \n",
    "                        config.targetVariable,str(count))\n",
    "                \n",
    "                \n",
    "                #display(self.train)\n",
    "                #If column is already in Dataframe and we want to fill target variable, this deletes columns!!!\n",
    "                if(config.deleteColumns):\n",
    "                    self.train.drop(name, axis=1, inplace=True)\n",
    "                    self.test1.drop(name, axis=1, inplace=True)\n",
    "                    if config.lag != 1:\n",
    "                        self.test2.drop(name, axis=1, inplace=True)\n",
    "                gc.collect()\n",
    "                #Only in tesst\n",
    "                #if count == 0:\n",
    "                 #   break\n",
    "        del tempData\n",
    "        display(self.train)   \n",
    "        display(self.test1)   \n",
    "        display(self.test2)\n",
    "        gc.collect()\n",
    "        return \n",
    "    \n",
    "    def DeleteLaggedWeeksFromTrain(self,trainOrTestOrBoth):\n",
    "        self.train = self.train.loc[self.train.loc[:,'Semana']>= 3 + self.maxLag]\n",
    "        gc.collect()\n",
    "        display(self.train.head(2))\n",
    "        \n",
    "    def ReadFirstNRowsOfACsv(self, nrows, trainOrTestOrBoth) :\n",
    "        if trainOrTestOrBoth == 'train' or trainOrTestOrBoth=='both':\n",
    "            self.train = pd.read_csv(self.trainCsvPath, usecols=self.trainTypes.keys(), dtype=self.trainTypes, nrows = nrows)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.train)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.train)\n",
    "        if trainOrTestOrBoth == 'test' or trainOrTestOrBoth=='both':\n",
    "            tempTest = pd.read_csv(self.testCsvPath, usecols=self.testTypes.keys(), dtype=self.testTypes, nrows = nrows*2)\n",
    "            self.test1 = tempTest.loc[tempTest.Semana == self.ValidationStart]\n",
    "            self.test2 = tempTest.loc[tempTest.Semana == self.ValidationEnd]\n",
    "            del tempTest\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.test1)\n",
    "            FeatureEngineering.changeIndexTypeToLowerMemory(self.test2)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test1)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test2)\n",
    "    \n",
    "    #Use when concatanating train and validation before predict test for example..\n",
    "    def AppendTestToTrain(self,deleteTest = True):\n",
    "        self.train = self.train.append(self.test1,ignore_index=True)\n",
    "        gc.collect()\n",
    "        if(deleteTest):\n",
    "            del self.test1\n",
    "            gc.collect()\n",
    "        try:\n",
    "            self.train = self.train.append(self.test2,ignore_index=True)\n",
    "            gc.collect()\n",
    "            if(deleteTest):\n",
    "                del self.test2\n",
    "                gc.collect()\n",
    "        except:\n",
    "            pass\n",
    "    #Split train data to train and test1 and test2 (validation)\n",
    "    def SplitTrainToTestUsingValidationStart(self):\n",
    "        boolCondition = self.train.Semana == self.ValidationStart\n",
    "        self.test1 = self.train.loc[boolCondition]\n",
    "        self.train.drop((self.train.loc[boolCondition].index), axis=0,inplace=True)\n",
    "        gc.collect()\n",
    "        \n",
    "        boolCondition = self.train.Semana == self.ValidationEnd\n",
    "        self.test2 = self.train.loc[boolCondition]\n",
    "        self.train.drop((self.train.loc[boolCondition].index), axis=0,inplace=True)\n",
    "        \n",
    "        del boolCondition\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trainCsvPath': '../../input/train_1000.csv', 'maxLag': 2, 'testTypes': {'Cliente_ID': <type 'numpy.uint32'>, 'Ruta_SAK': <type 'numpy.uint16'>, 'Canal_ID': <type 'numpy.uint8'>, 'Producto_ID': <type 'numpy.uint16'>, 'Agencia_ID': <type 'numpy.uint16'>, 'Semana': <type 'numpy.uint8'>, 'id': <type 'numpy.uint32'>}, 'testHdfFile': 'test', 'trainTypes': {'Dev_proxima': <type 'numpy.float32'>, 'Venta_uni_hoy': <type 'numpy.uint16'>, 'Cliente_ID': <type 'numpy.uint32'>, 'Demanda_uni_equil': <type 'numpy.uint32'>, 'Ruta_SAK': <type 'numpy.uint16'>, 'Canal_ID': <type 'numpy.uint8'>, 'Venta_hoy': <type 'numpy.float32'>, 'Producto_ID': <type 'numpy.uint16'>, 'Agencia_ID': <type 'numpy.uint16'>, 'Dev_uni_proxima': <type 'numpy.uint32'>, 'Semana': <type 'numpy.uint8'>}, 'testHdfPath1': '../../input/test1.h5', 'ValidationEnd': 11, 'testHdfPath2': '../../input/test2.h5', 'testCsvPath': '../../input/test_1000.csv', 'ValidationStart': 10, 'trainHdfFile': 'train', 'trainHdfPath': '../../input/train.h5'}\n"
     ]
    }
   ],
   "source": [
    "parameterDict =       {\"ValidationStart\":10, \n",
    " \"ValidationEnd\":11,\n",
    "   \"maxLag\":2,\n",
    "    \"trainHdfPath\":'../../input/train.h5',\n",
    "    \"trainHdfFile\":\"train\",\n",
    "    \"testHdfPath1\":\"../../input/test1.h5\",\n",
    "    \"testHdfPath2\":\"../../input/test2.h5\",\n",
    "    \"testHdfFile\":\"test\", \n",
    "    \"trainTypes\" : {'Semana':np.uint8, 'Agencia_ID':np.uint16, 'Canal_ID':np.uint8,'Ruta_SAK':np.uint16, \n",
    "        'Cliente_ID':np.uint32, 'Producto_ID':np.uint16,'Venta_uni_hoy':np.uint16, 'Venta_hoy':np.float32,\n",
    "                    'Dev_uni_proxima': np.uint32, 'Dev_proxima':np.float32,'Demanda_uni_equil':np.uint32}, \n",
    "    \"testTypes\" : {'id':np.uint32,'Semana':np.uint8, 'Agencia_ID':np.uint16, 'Canal_ID':np.uint8,'Ruta_SAK':np.uint16,\n",
    "        'Cliente_ID':np.uint32, 'Producto_ID':np.uint16},\n",
    "    \"trainCsvPath\":'../../input/train_1000.csv'   ,\n",
    "    \"testCsvPath\":'../../input/test_1000.csv'}\n",
    "\n",
    "FE = FeatureEngineering(**parameterDict)\n",
    "print FE.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2107</td>\n",
       "      <td>10</td>\n",
       "      <td>1124</td>\n",
       "      <td>1</td>\n",
       "      <td>2136</td>\n",
       "      <td>184044</td>\n",
       "      <td>31588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4750</td>\n",
       "      <td>10</td>\n",
       "      <td>1155</td>\n",
       "      <td>4</td>\n",
       "      <td>6607</td>\n",
       "      <td>2385912</td>\n",
       "      <td>1145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID\n",
       "0  2107      10        1124         1      2136      184044        31588\n",
       "1  4750      10        1155         4      6607     2385912         1145"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      "id             6 non-null uint32\n",
      "Semana         6 non-null uint8\n",
      "Agencia_ID     6 non-null uint16\n",
      "Canal_ID       6 non-null uint8\n",
      "Ruta_SAK       6 non-null uint16\n",
      "Cliente_ID     6 non-null uint32\n",
      "Producto_ID    6 non-null uint16\n",
      "dtypes: uint16(3), uint32(2), uint8(2)\n",
      "memory usage: 144.0 bytes\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6252</td>\n",
       "      <td>11</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>2802</td>\n",
       "      <td>766465</td>\n",
       "      <td>35305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18978</td>\n",
       "      <td>11</td>\n",
       "      <td>1342</td>\n",
       "      <td>1</td>\n",
       "      <td>1207</td>\n",
       "      <td>2229028</td>\n",
       "      <td>43251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID\n",
       "2   6252      11        1631         1      2802      766465        35305\n",
       "3  18978      11        1342         1      1207     2229028        43251"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4 entries, 2 to 7\n",
      "Data columns (total 7 columns):\n",
      "id             4 non-null uint32\n",
      "Semana         4 non-null uint8\n",
      "Agencia_ID     4 non-null uint16\n",
      "Canal_ID       4 non-null uint8\n",
      "Ruta_SAK       4 non-null uint16\n",
      "Cliente_ID     4 non-null uint32\n",
      "Producto_ID    4 non-null uint16\n",
      "dtypes: uint16(3), uint32(2), uint8(2)\n",
      "memory usage: 96.0 bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "FE.ReadFirstNRowsOfACsv(5,'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append test, memory is same??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Venta_uni_hoy</th>\n",
       "      <th>Venta_hoy</th>\n",
       "      <th>Dev_uni_proxima</th>\n",
       "      <th>Dev_proxima</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3303</td>\n",
       "      <td>324600</td>\n",
       "      <td>202</td>\n",
       "      <td>8</td>\n",
       "      <td>327.600006</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1112</td>\n",
       "      <td>1</td>\n",
       "      <td>1604</td>\n",
       "      <td>327360</td>\n",
       "      <td>303</td>\n",
       "      <td>8</td>\n",
       "      <td>36.320000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID  \\\n",
       "0       3        1110         7      3303      324600          202   \n",
       "1       3        1112         1      1604      327360          303   \n",
       "\n",
       "   Venta_uni_hoy   Venta_hoy  Dev_uni_proxima  Dev_proxima  Demanda_uni_equil  \n",
       "0              8  327.600006                0          0.0                  8  \n",
       "1              8   36.320000                0          0.0                  8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5 entries, 0 to 4\n",
      "Data columns (total 11 columns):\n",
      "Semana               5 non-null uint8\n",
      "Agencia_ID           5 non-null uint16\n",
      "Canal_ID             5 non-null uint8\n",
      "Ruta_SAK             5 non-null uint16\n",
      "Cliente_ID           5 non-null uint32\n",
      "Producto_ID          5 non-null uint16\n",
      "Venta_uni_hoy        5 non-null uint16\n",
      "Venta_hoy            5 non-null float32\n",
      "Dev_uni_proxima      5 non-null uint32\n",
      "Dev_proxima          5 non-null float32\n",
      "Demanda_uni_equil    5 non-null uint32\n",
      "dtypes: float32(2), uint16(4), uint32(3), uint8(2)\n",
      "memory usage: 190.0 bytes\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Venta_uni_hoy</th>\n",
       "      <th>Venta_hoy</th>\n",
       "      <th>Dev_uni_proxima</th>\n",
       "      <th>Dev_proxima</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3303</td>\n",
       "      <td>324600</td>\n",
       "      <td>202</td>\n",
       "      <td>8</td>\n",
       "      <td>327.600006</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1112</td>\n",
       "      <td>1</td>\n",
       "      <td>1604</td>\n",
       "      <td>327360</td>\n",
       "      <td>303</td>\n",
       "      <td>8</td>\n",
       "      <td>36.320000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1118</td>\n",
       "      <td>1</td>\n",
       "      <td>1409</td>\n",
       "      <td>81569</td>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "      <td>6.760000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1118</td>\n",
       "      <td>1</td>\n",
       "      <td>1409</td>\n",
       "      <td>81688</td>\n",
       "      <td>1242</td>\n",
       "      <td>7</td>\n",
       "      <td>53.480000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1121</td>\n",
       "      <td>1</td>\n",
       "      <td>1417</td>\n",
       "      <td>118819</td>\n",
       "      <td>1064</td>\n",
       "      <td>6</td>\n",
       "      <td>100.019997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID  \\\n",
       "0       3        1110         7      3303      324600          202   \n",
       "1       3        1112         1      1604      327360          303   \n",
       "2       3        1118         1      1409       81569         1309   \n",
       "3       3        1118         1      1409       81688         1242   \n",
       "4       3        1121         1      1417      118819         1064   \n",
       "\n",
       "   Venta_uni_hoy   Venta_hoy  Dev_uni_proxima  Dev_proxima  Demanda_uni_equil  \n",
       "0              8  327.600006                0          0.0                  8  \n",
       "1              8   36.320000                0          0.0                  8  \n",
       "2              1    6.760000                0          0.0                  1  \n",
       "3              7   53.480000                0          0.0                  7  \n",
       "4              6  100.019997                0          0.0                  6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Venta_uni_hoy</th>\n",
       "      <th>Venta_hoy</th>\n",
       "      <th>Dev_uni_proxima</th>\n",
       "      <th>Dev_proxima</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3303</td>\n",
       "      <td>324600</td>\n",
       "      <td>202</td>\n",
       "      <td>8</td>\n",
       "      <td>327.600006</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1112</td>\n",
       "      <td>1</td>\n",
       "      <td>1604</td>\n",
       "      <td>327360</td>\n",
       "      <td>303</td>\n",
       "      <td>8</td>\n",
       "      <td>36.320000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1118</td>\n",
       "      <td>1</td>\n",
       "      <td>1409</td>\n",
       "      <td>81569</td>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "      <td>6.760000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1118</td>\n",
       "      <td>1</td>\n",
       "      <td>1409</td>\n",
       "      <td>81688</td>\n",
       "      <td>1242</td>\n",
       "      <td>7</td>\n",
       "      <td>53.480000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1121</td>\n",
       "      <td>1</td>\n",
       "      <td>1417</td>\n",
       "      <td>118819</td>\n",
       "      <td>1064</td>\n",
       "      <td>6</td>\n",
       "      <td>100.019997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID  \\\n",
       "0      10        1110         7      3303      324600          202   \n",
       "1      11        1112         1      1604      327360          303   \n",
       "2      10        1118         1      1409       81569         1309   \n",
       "3      11        1118         1      1409       81688         1242   \n",
       "4      10        1121         1      1417      118819         1064   \n",
       "\n",
       "   Venta_uni_hoy   Venta_hoy  Dev_uni_proxima  Dev_proxima  Demanda_uni_equil  \n",
       "0              8  327.600006                0          0.0                  8  \n",
       "1              8   36.320000                0          0.0                  8  \n",
       "2              1    6.760000                0          0.0                  1  \n",
       "3              7   53.480000                0          0.0                  7  \n",
       "4              6  100.019997                0          0.0                  6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "      <th>Dev_proxima</th>\n",
       "      <th>Dev_uni_proxima</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Semana</th>\n",
       "      <th>Venta_hoy</th>\n",
       "      <th>Venta_uni_hoy</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>324600</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202</td>\n",
       "      <td>3303</td>\n",
       "      <td>3</td>\n",
       "      <td>327.600006</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1112</td>\n",
       "      <td>1</td>\n",
       "      <td>327360</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>303</td>\n",
       "      <td>1604</td>\n",
       "      <td>3</td>\n",
       "      <td>36.320000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1118</td>\n",
       "      <td>1</td>\n",
       "      <td>81569</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1309</td>\n",
       "      <td>1409</td>\n",
       "      <td>3</td>\n",
       "      <td>6.760000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1118</td>\n",
       "      <td>1</td>\n",
       "      <td>81688</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1242</td>\n",
       "      <td>1409</td>\n",
       "      <td>3</td>\n",
       "      <td>53.480000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1121</td>\n",
       "      <td>1</td>\n",
       "      <td>118819</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1064</td>\n",
       "      <td>1417</td>\n",
       "      <td>3</td>\n",
       "      <td>100.019997</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>324600</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202</td>\n",
       "      <td>3303</td>\n",
       "      <td>10</td>\n",
       "      <td>327.600006</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1112</td>\n",
       "      <td>1</td>\n",
       "      <td>327360</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>303</td>\n",
       "      <td>1604</td>\n",
       "      <td>11</td>\n",
       "      <td>36.320000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1118</td>\n",
       "      <td>1</td>\n",
       "      <td>81569</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1309</td>\n",
       "      <td>1409</td>\n",
       "      <td>10</td>\n",
       "      <td>6.760000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1118</td>\n",
       "      <td>1</td>\n",
       "      <td>81688</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1242</td>\n",
       "      <td>1409</td>\n",
       "      <td>11</td>\n",
       "      <td>53.480000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1121</td>\n",
       "      <td>1</td>\n",
       "      <td>118819</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1064</td>\n",
       "      <td>1417</td>\n",
       "      <td>10</td>\n",
       "      <td>100.019997</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>766465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35305</td>\n",
       "      <td>2802</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1342</td>\n",
       "      <td>1</td>\n",
       "      <td>2229028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43251</td>\n",
       "      <td>1207</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1235</td>\n",
       "      <td>1</td>\n",
       "      <td>711302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1220</td>\n",
       "      <td>1217</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1636</td>\n",
       "      <td>1</td>\n",
       "      <td>152283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37569</td>\n",
       "      <td>4410</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Agencia_ID  Canal_ID  Cliente_ID  Demanda_uni_equil  Dev_proxima  \\\n",
       "0         1110         7      324600                8.0          0.0   \n",
       "1         1112         1      327360                8.0          0.0   \n",
       "2         1118         1       81569                1.0          0.0   \n",
       "3         1118         1       81688                7.0          0.0   \n",
       "4         1121         1      118819                6.0          0.0   \n",
       "5         1110         7      324600                8.0          0.0   \n",
       "6         1112         1      327360                8.0          0.0   \n",
       "7         1118         1       81569                1.0          0.0   \n",
       "8         1118         1       81688                7.0          0.0   \n",
       "9         1121         1      118819                6.0          0.0   \n",
       "10        1631         1      766465                NaN          NaN   \n",
       "11        1342         1     2229028                NaN          NaN   \n",
       "12        1235         1      711302                NaN          NaN   \n",
       "13        1636         1      152283                NaN          NaN   \n",
       "\n",
       "    Dev_uni_proxima  Producto_ID  Ruta_SAK  Semana   Venta_hoy  Venta_uni_hoy  \\\n",
       "0               0.0          202      3303       3  327.600006            8.0   \n",
       "1               0.0          303      1604       3   36.320000            8.0   \n",
       "2               0.0         1309      1409       3    6.760000            1.0   \n",
       "3               0.0         1242      1409       3   53.480000            7.0   \n",
       "4               0.0         1064      1417       3  100.019997            6.0   \n",
       "5               0.0          202      3303      10  327.600006            8.0   \n",
       "6               0.0          303      1604      11   36.320000            8.0   \n",
       "7               0.0         1309      1409      10    6.760000            1.0   \n",
       "8               0.0         1242      1409      11   53.480000            7.0   \n",
       "9               0.0         1064      1417      10  100.019997            6.0   \n",
       "10              NaN        35305      2802      11         NaN            NaN   \n",
       "11              NaN        43251      1207      11         NaN            NaN   \n",
       "12              NaN         1220      1217      11         NaN            NaN   \n",
       "13              NaN        37569      4410      11         NaN            NaN   \n",
       "\n",
       "         id  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  \n",
       "5       NaN  \n",
       "6       NaN  \n",
       "7       NaN  \n",
       "8       NaN  \n",
       "9       NaN  \n",
       "10   6252.0  \n",
       "11  18978.0  \n",
       "12  30799.0  \n",
       "13  34135.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14 entries, 0 to 13\n",
      "Data columns (total 12 columns):\n",
      "Agencia_ID           14 non-null uint16\n",
      "Canal_ID             14 non-null uint8\n",
      "Cliente_ID           14 non-null uint32\n",
      "Demanda_uni_equil    10 non-null float64\n",
      "Dev_proxima          10 non-null float64\n",
      "Dev_uni_proxima      10 non-null float64\n",
      "Producto_ID          14 non-null uint16\n",
      "Ruta_SAK             14 non-null uint16\n",
      "Semana               14 non-null uint8\n",
      "Venta_hoy            10 non-null float64\n",
      "Venta_uni_hoy        10 non-null float64\n",
      "id                   4 non-null float64\n",
      "dtypes: float64(6), uint16(3), uint32(1), uint8(2)\n",
      "memory usage: 912.0 bytes\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "FeatureEngineering instance has no attribute 'test1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-54fe1d2477dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mFE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mFE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: FeatureEngineering instance has no attribute 'test1'"
     ]
    }
   ],
   "source": [
    "FE.ReadFirstNRowsOfACsv(5,'train')\n",
    "#FE.train.info()\n",
    "#FE.test1.info()\n",
    "FE.test1 = FE.train.copy()\n",
    "FE.test1[\"Semana\"] = np.array([10,11,10,11,10]).astype(\"uint8\")\n",
    "display(FE.train)\n",
    "display(FE.test1)\n",
    "FE.AppendTestToTrain()\n",
    "display(FE.train)\n",
    "FE.train.info()\n",
    "FE.test1.info()\n",
    "display(FE.train)\n",
    "display(FE.test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train to train and validation..Control memory usage.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.SplitTrainToTestUsingValidationStart()\n",
    "FE.train.info()\n",
    "FE.test1.info()\n",
    "FE.test2.info()\n",
    "display(FE.train)\n",
    "display(FE.test1)\n",
    "display(FE.test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess, Log(\"Demanda..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#FE.Preprocess('both', [[\"Demanda_uni_equil\",np.log1p,'float32']])\n",
    "display(FE.train)\n",
    "display(FE.test1)\n",
    "display(FE.test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Dataframe to HDF.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.SaveDataFrameToHdf('both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load from HDF, Test with big data!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.ReadHdf('both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.train.Demanda_uni_equil = FE.train.Demanda_uni_equil.astype(\"uint32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROD Load train and test CSV, preprocess and save as HDF.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.ReadCsv('both')\n",
    "FE.Preprocess('train', [[\"Demanda_uni_equil\",np.log1p,'float32']])\n",
    "FE.SaveDataFrameToHdf('both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train and test HDF!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.ReadHdf('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.test1.reset_index(inplace=True)\n",
    "FE.test1.drop(\"index\",inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.test1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.ReadFirstNRowsOfACsv(20,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#FE.train.to_csv('../../input/train_20.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameterDict = {\"ValidationStart\":8, \n",
    "    \"ValidationEnd\":9,\n",
    "    \"maxLag\":2,    \n",
    "    \"trainHdfPath\":'../../input/train_100.h5',\n",
    "    \"trainHdfFile\":\"train\",\n",
    "    \"testHdfPath1\":\"../../input/train_100_1.h5\",\n",
    "    \"testHdfPath2\":\"../../input/train_100_1.h5\",\n",
    "    \"testHdfFile\":\"test\", \n",
    "    \"trainTypes\" : {'Semana':np.uint8, 'Agencia_ID':np.uint16, 'Canal_ID':np.uint8,'Ruta_SAK':np.uint16, \n",
    "        'Cliente_ID':np.uint32, 'Producto_ID':np.uint16,'Venta_uni_hoy':np.uint16, 'Venta_hoy':np.float32,\n",
    "                    'Dev_proxima':np.float32,'Demanda_uni_equil':np.uint32}, \n",
    "    \"testTypes\" : {'id':np.uint32,'Semana':np.uint8, 'Agencia_ID':np.uint16, 'Canal_ID':np.uint8,'Ruta_SAK':np.uint16,\n",
    "        'Cliente_ID':np.uint32, 'Producto_ID':np.uint16},\n",
    "    \"trainCsvPath\":'../../input/train_100.csv'   ,\n",
    "    \"testCsvPath\":'../../input/test_100.csv'}\n",
    "\n",
    "FE = FeatureEngineering(**parameterDict)\n",
    "print FE.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.ReadCsv('train')\n",
    "FE.Preprocess('train', [[\"Demanda_uni_equil\",np.log1p,'float32']])\n",
    "FE.SaveDataFrameToHdf('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.ReadHdf('train')\n",
    "FE.SplitTrainToTestUsingValidationStart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(FE.test1.head(2))\n",
    "display(FE.test2.head(2))\n",
    "display(FE.train.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "FE.AddConfigurableFeaturesToTrain(configLag0Target1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "FE.AddConfigurableFeaturesToTrain(configLag2Target1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "FE.AddConfigurableFeaturesToTrain(configLag1Target1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "FE.AddConfigurableFeaturesToTrain(configLag1Target1F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test setup.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameterDict = {\"ValidationStart\":6, \n",
    "    \"ValidationEnd\":7,\n",
    "    \"maxLag\":2,    \n",
    "    \"trainHdfPath\":'../../input/train_100.h5',\n",
    "    \"trainHdfFile\":\"train\",\n",
    "    \"testHdfPath\":\"../../input/test.h5\",\n",
    "    \"testHdfFile\":\"test\", \n",
    "    \"trainTypes\" : {'Semana':np.uint8, 'Agencia_ID':np.uint16, 'Canal_ID':np.uint8,'Ruta_SAK':np.uint16, \n",
    "        'Cliente_ID':np.uint32, 'Producto_ID':np.uint16,'Venta_uni_hoy':np.uint16, 'Venta_hoy':np.float32,\n",
    "                    'Dev_proxima':np.float32,'Demanda_uni_equil':np.uint32}, \n",
    "    \"testTypes\" : {'id':np.uint32,'Semana':np.uint8, 'Agencia_ID':np.uint16, 'Canal_ID':np.uint8,'Ruta_SAK':np.uint16,\n",
    "        'Cliente_ID':np.uint32, 'Producto_ID':np.uint16},\n",
    "    \"trainCsvPath\":'../../input/train_100.csv'   ,\n",
    "    \"testCsvPath\":'../../input/test.csv'}\n",
    "\n",
    "FE = FeatureEngineering(**parameterDict)\n",
    "print FE.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#FE.ReadCsv('train')\n",
    "#FE.Preprocess('train', [[\"Demanda_uni_equil\",np.log1p,'float32']])\n",
    "#FE.SaveDataFrameToHdf('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.ReadHdf('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(FE.AddDemandaGeneralMean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qw = FE.train.loc[FE.train.loc[:,'Semana']>4]\n",
    "qw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.train.loc[:,'target'] = np.nan\n",
    "FE.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.train.loc[pd.isnull(FE.train['target']), 'target'] = FE.train.loc[pd.isnull(FE.train['target']), 'lag2P']\n",
    "FE.train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.train.loc[FE.train['Semana']>4,\"target\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.train.loc[FE.train['Semana']>4,\"target\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.train.loc[pd.isnull(FE.train['target']), 'target'] = FE.train.loc[pd.isnull(FE.train['target']), 'lag2Cl']\n",
    "FE.train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.train.loc[FE.train['Semana']>4,\"target\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"Semana\" not in FE.train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"{} haha {}\".format(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in FE.train.groupby('Canal_ID')['Demanda_uni_equil']:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FE.train[['Canal_ID','Demanda_uni_equil']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[\"Cliente_ID\",\"Producto_ID\"] + 'abc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "params = {}\n",
    "params['objective'] = \"reg:linear\"\n",
    "params['eta'] = 0.1\n",
    "params['max_depth'] = 5\n",
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 0.6\n",
    "params['silent'] = True\n",
    "'alpha': 0.0001, 'lambda': 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regres = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
