{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.datasets import load_iris, load_digits, load_boston\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
    "from collections import OrderedDict\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(31337)\n",
    "boston = load_boston()\n",
    "y = boston['target']\n",
    "X = boston['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-1, -1, -1, -1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = boston['data']\n",
    "y = boston['target']\n",
    "print X.shape\n",
    "print y.shape\n",
    "X_train = X[:400]\n",
    "X_test = X[400:]\n",
    "y_train = y[:400]\n",
    "y_test = y[400:]\n",
    "\n",
    "tempX = 400 * [-1] + y_test.shape[0] * [0]\n",
    "tempX[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSE(y_true,y_pred):\n",
    "    mse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print 'MSE: %2.3f' % mse\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't have early stop option!!!!!!!!So didn't use so far..\n",
    "## Semi-Automatic Hyperparameter Tuning, it can't predict. Only gives optimum parameter..\n",
    "## Predict doesn't work, because when refit = False, it doesn't assign best estimator!!!\n",
    "## Doesn't do 2 fold, this is what i want for Bimbo.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston Housing: regression\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "MSE: 5.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.PredefinedSplit(test_fold=[-1 -1 ...,  0  0]),\n",
       "       error_score='raise',\n",
       "       estimator=XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.4,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=5, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1.0),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [200]}, pre_dispatch='2*n_jobs',\n",
       "       refit=False, score_func=None,\n",
       "       scoring=make_scorer(RMSE, greater_is_better=False), verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Boston Housing: regression\")\n",
    "boston = load_boston()\n",
    "y = boston['target']\n",
    "X = boston['data']\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1729)\n",
    "\n",
    "\n",
    "'''base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
    "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=1\n",
    "        \n",
    "        \n",
    "learning_rate=0.1\n",
    "max_depth=3\n",
    "missing=np.nan, learning_rate=0.02, subsample=0.9, colsample_bytree=0.85\n",
    "'''\n",
    "\n",
    "#in order depth= 10, subsample=1.0, min_child_weight = 5, col_sample_bytree = 0.2, eta = 0.1, \n",
    "#col_sample_bytree = 0.4 - 1\n",
    "#gamma = 0.05,0.1 0.3, 0.5, 0.7, 1\n",
    "#lambda = 0.01, 0.1, 1\n",
    "#alpha = 0.01, 0.1, 1\n",
    "#n_estimators is last..\n",
    "\n",
    "#Start from 10 and play up down..\n",
    "depth = [12,8]\n",
    "subsample = [0.8,0.6]\n",
    "min_child_weight = [3,7]\n",
    "col_sample_bytree = [0.3,0.5,0.8,1]\n",
    "#lambdaa = [0.01, 0.1, 1]\n",
    "#alpha = [0.01, 0.1]\n",
    "#Use this eta to find the optimum iteration\n",
    "eta = [0.05]\n",
    "\n",
    "defaultParams = {\"max_depth\":10, \"subsample\":1., \"min_child_weight\":5, \"colsample_bytree\":0.4, \"missing\":np.nan}\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import PredefinedSplit\n",
    "#ps = PredefinedSplit(test_fold=[-1, -1, -1, 0,0])\n",
    "ps = PredefinedSplit(test_fold=tempX)\n",
    "\n",
    "#ps = PredefinedSplit(test_fold=[0, 1, 2, 1])\n",
    "#len(ps)\n",
    "\n",
    "\n",
    "\n",
    "#xgb_model.fit(X_train,y_train,eval_set=[(X_train, y_train),(X_test, y_test)],\n",
    " #        verbose=10, early_stopping_rounds = 50)\n",
    "\n",
    "cv_params = {'n_estimators': [200]}\n",
    "\n",
    "\n",
    "optimized_Xgb = GridSearchCV(xgb.XGBRegressor(**defaultParams), \n",
    "    cv_params, cv = ps, n_jobs = -1,verbose=1,refit=False, scoring = make_scorer(RMSE, greater_is_better=False)) \n",
    "\n",
    "optimized_Xgb.fit(X,y)\n",
    "\n",
    "#optimized_GBM.best_estimator_ = optimized_GBM.estimator\n",
    "\n",
    "#print(optimized_GBM.best_score_)\n",
    "#print(optimized_GBM.best_params_)\n",
    "\n",
    "\n",
    "#predictions = optimized_GBM.predict(X_train)\n",
    "#predictionsTest = optimized_GBM.predict(X_test)\n",
    "#print( np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "#print( np.sqrt(mean_squared_error(y_test, predictionsTest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle, Save Model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling sklearn API models\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "need to call fit beforehand",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e82f90905f3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_boston.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_boston.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# pylint: disable=missing-docstring,invalid-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mtest_dmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         return self.booster().predict(test_dmatrix,\n\u001b[0m\u001b[1;32m    205\u001b[0m                                       \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                                       ntree_limit=ntree_limit)\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mbooster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \"\"\"\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need to call fit beforehand'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: need to call fit beforehand"
     ]
    }
   ],
   "source": [
    "print(\"Pickling sklearn API models\")\n",
    "# must open in binary format to pickle\n",
    "pickle.dump(xgb_model, open(\"best_boston.pkl\", \"wb\"))\n",
    "clf2 = pickle.load(open(\"best_boston.pkl\", \"rb\"))\n",
    "print(np.allclose(xgb_model.predict(X_train), clf2.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manuel Hyperparameter Tuning Davut "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston Housing: regression\n",
      "trainResult:  5.94774586383\n",
      "testResult:  3.76469176192\n",
      "Best Iteration:  15\n",
      "Best Score:  3.764692\n",
      "Axes(0.125,0.125;0.775x0.775)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until validation_1 error hasn't decreased in 30 rounds.\n",
      "[0]\tvalidation_0-rmse:23.131414\tvalidation_1-rmse:14.183814\n",
      "[1]\tvalidation_0-rmse:20.966824\tvalidation_1-rmse:12.762135\n",
      "[2]\tvalidation_0-rmse:19.017046\tvalidation_1-rmse:11.396545\n",
      "[3]\tvalidation_0-rmse:17.309326\tvalidation_1-rmse:9.977957\n",
      "[4]\tvalidation_0-rmse:15.728290\tvalidation_1-rmse:8.827554\n",
      "[5]\tvalidation_0-rmse:14.333989\tvalidation_1-rmse:7.753925\n",
      "[6]\tvalidation_0-rmse:13.089965\tvalidation_1-rmse:6.812794\n",
      "[7]\tvalidation_0-rmse:11.976292\tvalidation_1-rmse:6.122922\n",
      "[8]\tvalidation_0-rmse:10.925667\tvalidation_1-rmse:5.568113\n",
      "[9]\tvalidation_0-rmse:9.959489\tvalidation_1-rmse:5.022428\n",
      "[10]\tvalidation_0-rmse:9.081215\tvalidation_1-rmse:4.615676\n",
      "[11]\tvalidation_0-rmse:8.308702\tvalidation_1-rmse:4.311479\n",
      "[12]\tvalidation_0-rmse:7.669021\tvalidation_1-rmse:4.077378\n",
      "[13]\tvalidation_0-rmse:7.041759\tvalidation_1-rmse:3.952145\n",
      "[14]\tvalidation_0-rmse:6.481558\tvalidation_1-rmse:3.870467\n",
      "[15]\tvalidation_0-rmse:5.947747\tvalidation_1-rmse:3.764692\n",
      "[16]\tvalidation_0-rmse:5.485374\tvalidation_1-rmse:3.765239\n",
      "[17]\tvalidation_0-rmse:5.069448\tvalidation_1-rmse:3.786620\n",
      "[18]\tvalidation_0-rmse:4.684884\tvalidation_1-rmse:3.775263\n",
      "[19]\tvalidation_0-rmse:4.352309\tvalidation_1-rmse:3.842848\n",
      "[20]\tvalidation_0-rmse:4.048081\tvalidation_1-rmse:3.867080\n",
      "[21]\tvalidation_0-rmse:3.766754\tvalidation_1-rmse:3.905899\n",
      "[22]\tvalidation_0-rmse:3.527300\tvalidation_1-rmse:3.948177\n",
      "[23]\tvalidation_0-rmse:3.291131\tvalidation_1-rmse:4.000016\n",
      "[24]\tvalidation_0-rmse:3.106033\tvalidation_1-rmse:4.136913\n",
      "[25]\tvalidation_0-rmse:2.919743\tvalidation_1-rmse:4.162389\n",
      "[26]\tvalidation_0-rmse:2.751752\tvalidation_1-rmse:4.335176\n",
      "[27]\tvalidation_0-rmse:2.604001\tvalidation_1-rmse:4.376230\n",
      "[28]\tvalidation_0-rmse:2.470059\tvalidation_1-rmse:4.417185\n",
      "[29]\tvalidation_0-rmse:2.332149\tvalidation_1-rmse:4.533206\n",
      "[30]\tvalidation_0-rmse:2.224444\tvalidation_1-rmse:4.595870\n",
      "[31]\tvalidation_0-rmse:2.118444\tvalidation_1-rmse:4.630688\n",
      "[32]\tvalidation_0-rmse:2.017338\tvalidation_1-rmse:4.682919\n",
      "[33]\tvalidation_0-rmse:1.923140\tvalidation_1-rmse:4.751122\n",
      "[34]\tvalidation_0-rmse:1.843365\tvalidation_1-rmse:4.779572\n",
      "[35]\tvalidation_0-rmse:1.775072\tvalidation_1-rmse:4.794268\n",
      "[36]\tvalidation_0-rmse:1.695288\tvalidation_1-rmse:4.887416\n",
      "[37]\tvalidation_0-rmse:1.628747\tvalidation_1-rmse:4.894354\n",
      "[38]\tvalidation_0-rmse:1.562230\tvalidation_1-rmse:4.923308\n",
      "[39]\tvalidation_0-rmse:1.518523\tvalidation_1-rmse:4.986403\n",
      "[40]\tvalidation_0-rmse:1.473880\tvalidation_1-rmse:5.004642\n",
      "[41]\tvalidation_0-rmse:1.414068\tvalidation_1-rmse:5.006896\n",
      "[42]\tvalidation_0-rmse:1.360603\tvalidation_1-rmse:5.037427\n",
      "[43]\tvalidation_0-rmse:1.308469\tvalidation_1-rmse:5.143317\n",
      "[44]\tvalidation_0-rmse:1.266907\tvalidation_1-rmse:5.154201\n",
      "[45]\tvalidation_0-rmse:1.241929\tvalidation_1-rmse:5.173134\n",
      "Stopping. Best iteration:\n",
      "[15]\tvalidation_0-rmse:5.947747\tvalidation_1-rmse:3.764692\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAFtCAYAAAD4VDh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X98zvX+x/HHZXNZc83sqmvNjx0ns0hKieJQ4kvEko7k\nxzGJ/KhjyZiR2DDSD2oJcaI6fhRqhDpSic6RyDlHpbCbDqPUNra2XZv9uvb5/uG4juXHpO1z+azn\n/XZza5/P9Xl/Pq/r1cXz8/lc712XzTAMAxEREbGUGr4uQERERH45BbiIiIgFKcBFREQsSAEuIiJi\nQQpwERERC1KAi4iIWJACXKSKNGvWjHvuuYfevXt7/0yZMuWS9/fll1+SkJBQiRWWt2XLFpKSkqps\n/+dz9OhRHnvsMdOPK2J1/r4uQKQ6W7ZsGXXr1q2UfR08eJD09PRK2de5dO7cmc6dO1fZ/s/n2LFj\nHDp0yPTjilidTR/kIlI1mjVrxo4dOwgJCTnrsW+//ZZZs2aRnZ1NWVkZ0dHR9OnTh7KyMmbNmsWX\nX35Jfn4+hmGQlJRE/fr16d+/P263m7vuuovevXszY8YMNmzYAMDOnTtJSkpiw4YNzJs3jz179pCZ\nmUmzZs145plnWLhwIR988AFlZWU0aNCAhIQEQkNDy9WUkpLC5s2befnll4mOjqZFixZ89tlnnDhx\ngsGDB3PixAl27drFyZMneeGFF7j22muJjo6mSZMm7N27l+zsbO69915iYmIA+PDDD5k/fz4ejweH\nw8HEiRO58cYby9UXGRnJV199RXp6Om3atOGVV17h5Zdf5qOPPqKoqIiTJ08SHx9Ply5dmDdvHt9/\n/z2ZmZkcO3YMp9PJ888/T2hoKIcOHWLq1KlkZ2djs9l45JFH6NGjB+np6cyYMYNjx45RWlpKz549\nGTlyZNX/zxcxgyEiVaJp06ZGVFSUce+993r/nDhxwigpKTF69OhhfP3114ZhGEZubq7Ro0cPY8+e\nPca///1vY8yYMd59LFq0yBg5cqRhGIaRkpLi/fmzzz4zoqKivNudufziiy8ad999t+HxeAzDMIy1\na9caY8eONUpLSw3DMIw333zTGD58+Fn1vv322979Dxo0yIiJiTEMwzC++OILo2nTpsbHH39sGIZh\nzJo1y5gyZYp3u5EjRxqlpaVGbm6u0b17d+Pjjz82Dh48aLRv3944evSoYRiGsWPHDqN9+/ZGXl7e\nWfXt3LnTW/t3331nPPjgg0ZRUZFhGIaxcePGcs+rS5cuhtvtNgzDMEaNGmW8+OKLhmEYRu/evY2V\nK1cahmEYP/zwg9GlSxcjLy/PiI6ONrZs2WIYhmEUFhYa0dHRxnvvvfcL/i+KXL50C12kCp3rFvrB\ngwc5evQoTzzxhHddUVER+/bto3///owZM4aVK1dy9OhRdu3ahcPhAMD4BTfLWrZsSY0ap6a4fPzx\nx3z11Vf06dMHAI/HQ1FRUYX7uOuuuwBo2LAhALfffjsA4eHh7Nq1y7tdv3798PPzIygoiO7du/OP\nf/yDxo0b065dO+/Ytm3bcuWVV/L1119js9nK1Xfm82rQoAGzZ8/mnXfe4ciRI+zZs4eTJ096H7/t\nttuoXbs2AM2bNycnJ4ecnBwOHDhA3759AQgLC+ODDz6goKCAzz//nNzcXJKTkwE4efIk+/fv5+67\n777oXopcrhTgIibzeDzUqVOHdevWededOHGCoKAgtm7dyqxZsxg6dChdunShcePGrF+//qx92Gy2\ncsFXUlJS7vHAwEDvz4ZhMGLECPr37w9AcXExubm5FdZpt9vLLfv5+ZU7/mmngxigrKyMGjVqYBjG\nWSccZWVllJaWnlXfmb7++mseffRRHnroITp06ECbNm1ITEz0Pl6rVq2zajhd15k1/ec//8HlcgGw\natUq77js7Oxy+xCxMs1CFzHZNddcg91u9wbzsWPHiIqKYu/evXz66ad06tSJ/v3706JFCz788EPK\nysqAU0F1OqidTifHjh0jKysLwzD48MMPz3u8Dh06sHr1atxuNwDJyclMmDChwjovdMV/5mPr16/H\nMAxycnLYtGkTnTt3pm3btmzfvp2jR48CsGPHDtLT02nZsuVZ+z3zeX3++efccMMNDBkyhNatW5d7\n/ueqwTAMHA4H119/PSkpKQD88MMPDBw4kKKiIlq2bMnSpUsByM3NpX///mzZsqXC5y5iBboCF6ki\nZ14Rnslut7NgwQJmzpzJK6+8QmlpKY8//jitWrWibt26jB8/nl69euHn50fr1q354IMPAGjVqhXJ\nycnExMQwb948+vXrR58+fXC5XNx5553ljnvmsfv27Ut6ejr9+vXDZrNRv359Zs+eXWG9Zy7//Ocz\nl4uKirj//vvJz89n4MCBtG3bFoCEhARiYmLweDxcccUVLFy4EIfDcdb4a6+9Fj8/Px544AHvZLue\nPXtSs2ZN2rVrR05ODvn5+WeNO3N5zpw5TJs2jeXLl2Oz2Zg5cyZXXXUVc+bMYcaMGdxzzz2UlJRw\nzz33EBUVdf7/aSIWolnoInLJoqOjiY6O9r5fLiLm0S10ERERC9IVuIiIiAXpClxERMSCFOAiIiIW\nZKlZ6KWlHrKzC3xdRrUXEhKoPptEvTaH+mwe9bpyuVxB533MUlfg/v5+FW8kv5r6bB712hzqs3nU\na/NYKsBFRETkFAW4iIiIBSnARURELEgBLiIiYkEKcBEREQtSgIuIiFiQAlxERMSCFOAiIiIWpAAX\nERGxIAW4iIiIBSnARURELEgBLiIiYkEKcBEREQtSgIuIiFiQAlxERMSCFOAiIiIWpAAXERGxIP+q\n2rHH42HIkCGUlpayaNEidu7cyaZNm5gzZw4AO3bsIDk5GX9/f5xOJ8888wwBAQFVVY6IiMh5vf/+\ne7zxxnJsNggICGDMmDiuueYa5sx5mgMH9lFWVkbz5i2IjY2nVq1a3nHHjn3PsGHRvPDCApo2bWZq\nzVUW4Onp6eTn55OSkkJSUhLbt2+nefPm3senTZvGypUrcTqdzJ07lzVr1hAdHX3BfaamppKV5a6q\nkuW/srMd6rNJ1GtzqM/msVKvw8MbYbfbOXLkMAsWvMirr67A6bySHTu288QT47n77igMw+D119+k\nrKyM6dOnsHz5awwbNhKAoqIiZsyYgsfj8Un9VRbgCQkJpKWlMXXqVNq1a0fXrl1ZtWqV9/Hly5fj\ndDoBKCkpuair7+hJKwkMDq2qkkVE5DeiICeD5LheREREYrfXYuLEKTidVwLQrNl1ZGdncdNNrQgL\nqwdAjRo1iIy8lsOHD3n3MXfu0/To0Yu//nWpT55DlQV4YmIisbGxTJ8+HYCdO3eWe/yqq64CYPPm\nzXz++eeMHTu2wn0GBofiCGlQ+cWKiMhvVlhYPW9QG4bBvHnP06FDR9q0uc27zY8//sCaNW8SHz8Z\ngA0b1lFWVsY99/SufgFuGEaF27z22mts3ryZV155BbvdXlWliIiIVOjkyZPMnJnI8eOZzJnzonf9\n/v37mDw5jj59+tGuXQcOHNjPO++kMH/+Yu82F5N5la3KArwiCxcu5JtvvuHVV18tNyFARETEDE6n\nA5crCIBjx44xevQoIiMjmTdvhfei8t1332X69OlMnTqVnj17AvCXv3xAYWEBo0cPB+D48UxmzpxK\nfHw8nTp1Mq3+Kg1wm81W7ufTy8ePH2f+/Pm0aNGChx9+GIAePXowYMCAC+6vICej6ooVEZHfjIKc\nDLKy3GRm5pGbm8OwYdH07NmLIUMeJienCCji448/ZO7cZ5gz5yWaNm1GZmYeAMOHxzB8eIx3X337\n9uLJJ2eU26aynD7BOBeb4Yvr/kukWejmcDqtM4vU6tRrc6jP5rFSr0/PQn/99SUsXbqYxo0jyj1+\n8mQh+flu75wtgBtvvImxYyeU265v314kJT1TJb9GVm0CHKj0sxs5m8sVpD6bRL02h/psHvW6cl0o\nwPVJbCIiIhakABcREbEgBbiIiIgFKcBFREQsSAEuIiJiQQpwERERC1KAi4iIWJACXERExIIU4CIi\nIhakABcREbEgBbiIiIgFKcBFREQsSAEuIiJiQQpwERERC1KAi4hUAcMwmDkzkTfeWO5dl5KyhqFD\nBzFoUF9mzJhCSUlJuTHHjn3P3Xd35sCB/WaXKxbkb/YBPR4PQ4YMoaSkhBtuuIG9e/dSXFxMTEwM\nd955p9nliIhUusOHDzF37tN8881eIiKaALBt2xZSUlazcOFSHA4HU6bEs2rVCgYNGgJAUVERM2ZM\nwePx+LBysRLTAzw9PZ38/Hyio6P58ssveeONN0hPT2fTpk0Vjk1NTSUry21Clb9t2dkO9dkk6rU5\nzOpzeHgj7HY7a9euISrqXsLC6nkf27TpXfr3H0RQUBAA48c/QWnp/67A5859mh49evHXvy6t8jql\nejA9wBMSEkhLS2Pt2rX84Q9/YOTIkRiGwZQpUyocGz1pJYHBoSZUKSLyyxTkZJAc14uIiEjGjp0A\nwO7du7yPHz16lOzsLMaNe4zjxzNp2fImHn10DAAbNqyjrKyMe+7prQCXi2Z6gCcmJhIbG4u/vz9H\njhxh0aJFfP7550yaNInly5dfcGxgcCiOkAYmVSoiUnlKS0vYvXsXTz01B7vdTlJSAosXz6dbt568\n804K8+cv9m5rGIYPKxWrMD3AT78w69at633Pu02bNhw+fNjsUkREKpXT6cDlCvIuBwTUxOEIwOUK\non79enTr1o1Gja4G4IEH+jB//nyuuMJOYWEBo0cPB+D48UxmzpxKfHw8nTp18snz+LXO7IFUHdMD\n/LRbbrmFbdu2cdddd7F//37q169f4ZiCnAwTKhMR+eUKcjLIynKTmZnnXVdYWEJeXiGZmXm0b9+R\n9es3cued3bHb7WzY8B6Rkc0YPjyG4cNjvGP69u3Fk0/OoGnTZuX2ZRUuV5Al675cXehkyCcBbrPZ\n6Nu3L4mJifTr1w+AadOmVThu2VMDNeHHBE6nJlaZRb02h1l9Dg9vdNY6m+3Uf++7ry+5ubkMGxZN\nWZmHpk2vIyYmtsprkurLZljszRad2VU9nUGbR702h/psHvW6cl3oClwf5CIiImJBCnARERELUoCL\niIhYkAJcRETEghTgIiIiFqQAFxERsSAFuIiIiAUpwEVERCxIAS4iImJBCnARERELUoCLiIhYkAJc\nRETEghTgIiIiFqQAFxERsSAFuIiIiAUpwEVEfgXDMJg5M5E33ljuXZeSsoahQwcxaFBfZsyYQklJ\nSbkxGze+Q3z8WLNLlWrG3+wDejwehgwZwu7du7n22mupU6cOubm5nDhxgn/84x8XHJuamkpWltuk\nSn+7srMd6rNJ1GtzVHafw8MbYbfbOXz4EHPnPs033+wlIqIJANu2bSElZTULFy7F4XAwZUo8q1at\nYNCgIeTm5rBo0Xw2b/4brVq1rrR65LfJ9ABPT08nPz+fffv2edeNGjWK+Pj4CsdGT1pJYHBoVZYn\nInJBBTkZJMf1IiIikrVr1xAVdS9hYfW8j2/a9C79+w8iKCgIgPHjn6C0tBSALVs+xOUK5c9/HsOn\nn273Sf1SfZge4AkJCaSlpZGQkMC0adPYvHkzwcHB/OEPf6hwbGBwKI6QBiZUKSJSsbFjJwCwe/cu\n77qjR4+SnZ3FuHGPcfx4Ji1b3sSjj44BoHfvPgC8994G84uVasf098ATExNp0qQJ06ZNA2Dx4sWM\nHj3a7DJERKpEaWkJu3fvYsaM2SxZsozc3FwWL57v67KkGjL9CtwwDO/PBw8epE6dOoSHh5tdhojI\nJXM6HbhcQd7lgICaOBwBuFxB1K9fj27dutGo0dUA9O37RxYsWFBu+6CgAGrV8i+3rjqprs/rcmN6\ngJ/p008/5Y477rjo7QtyMqqwGhGRihXkZJCV5SYzM8+7rrCwhLy8QjIz82jfviPr12/kzju7Y7fb\n2bjxb0RGNiu3fV5eIUVFpeXWVRcuV1C1fF6+cqGTIZ8EuM1mA+Dw4cO0b9/+oscte2qgZuyawOnU\nzGizqNfmqOw+h4c3Omvdf/9Z4777+pKbm8uwYdGUlXlo2vQ6YmJif7atzbu9yKWyGWfe07YAndlV\nPZ1Bm0e9Nof6bB71unJd6ApcH+QiIiJiQQpwERERC1KAi4iIWJACXERExIIU4CIiIhakABcREbEg\nBbiIiIgFKcBFREQsSAEuIiJiQQpwERERC1KAi4iIWJACXERExIIU4CIiIhakABcREbEgBbiIiIgF\n+Zt9QI/Hw5AhQygpKeHAgQO0aNECgJtvvpnY2NgKRouIVA7DMJg1axqNGzdhwIBBAERFdcHlCvVu\nM3DgYLp27e5d3rjxHf7+9608/fTzptcr8nOmB3h6ejr5+fm88MILzJo1i5dffvmix6amppKV5a7C\n6gQgO9uhPptEvTbH6T6HhzfCbrdz+PAh5s59mm++2UtERBMAjhw5TFBQHV59deVZ43Nzc1i0aD6b\nN/+NVq1am12+yDmZHuAJCQmkpaXx0EMPERwczODBgwkICGDSpElcc801FxwbPWklgcGhF9xGRORc\nCnIySI7rRUREJGvXriEq6l7CwuphGKce/+qrL/Hz8+Oxx0aRk5NDp07/x+DBQ6lRowZbtnyIyxXK\nn/88hk8/3e7bJyLyX6YHeGJiIrGxscTFxXHixAm6devGP//5T+Li4njrrbcuODYwOBRHSAOTKhWR\n6mrs2AkA7N69C5vt1LqysjLatGnLn/88hsLCQuLixhAYWJsHHhhA7959AHjvvQ2+KlnkLKYHuPHf\n090WLVrg5+cHwC233EJGRobZpYjIb4zT6cDlCvIuBwTUpHbtWrhcQQwdGl1u2xEjHmbZsmX8+c8j\nvOuCggKoVcu/3D7kbOqPOUwP8NNeeukl6taty8MPP8z+/fupX7++r0oRkd+IrCw3mZl53uXCwhLy\n84vIzMxj06Z3iYxs6n1P/Kef8ikro9z2eXmFFBWVllsn5blcQepPJbrQyZBPAtxmszFy5EjGjx/P\ntm3b8Pf356mnnqpwXEGOrtJF5NKc79+P0++BHzr0H7Zt+5iZM5+hpKSYlJQ1dOt2t4kVivwypgd4\nw4YNefPNNwFYtGjRLxq77KmBmrFrAqdTM6PNol6b43Sfw8MbnfXY6ffAhw4dzty5zzB4cH9KS0vp\n3LkLUVG9f7atzbu9iK/ZjNNvSluEbs1UPd0CM496bQ712TzqdeW60C10fRKbiIiIBSnARURELEgB\nLiIiYkEKcBEREQtSgIuIiFiQAlxERMSCFOAiIiIWpAAXERGxIAW4iIiIBSnARURELEgBLiIiYkEK\ncBEREQtSgIuIiFiQAlxERMSCTP8+cBGR8zEMg1mzptG4cRMGDBiE2+1m9uzpHDmSRlmZwd139+RP\nf3oQgNzcHJ5//lnS0g5RVFTE4MFD6dath4+fgYh5TA9wj8fDkCFDcLvdBAcHU1JSQu3atZk9ezZO\np9PsckTkMnH48CHmzn2ab77ZS0REEwBeeeVlrr46jKSkZygsLCQ6+gFuuukWrr++BTNnJnLNNREk\nJCSRmZnB4MH9ueWWNlx1lcvHz0TEHKYHeHp6Ovn5+dx777243W5Gjx7Ne++9x8KFC5k8efIFx6am\nppKV5Tap0t+u7GyH+mwS9RrCwxtht9tZu3YNUVH3EhZWD8M49djjj4/H4/EAkJmZQXFxMQ6Hg9zc\nHHbv3sX06bMBcLlC+ctfXicoKMhXT0PEdKYHeEJCAmlpaWzZsoXx48cDcPvtt7NgwYIKx0ZPWklg\ncGhVlygiJinIySA5rhcREZGMHTsBgN27d5Xbxs/Pj+nTp7B16xY6duxEePjv2L//G6688irefHM5\nn332KSUlJQwYMIiGDcN98TREfML0AE9MTCQ2NhZ/f39q164NQO3atcnLy6twbGBwKI6QBlVdoohc\nZqZOnUFc3BNMnjyBV1/9C7fe2pYffjiGw+Fg4cIlfP/9dzz66MM0bPg7mjZt5utyRUxheoAb/703\n5nA4yM/PByA/P586deqYXYqIXAacTgcu1/9ufQcE1CQoKACXK4i///3vNG3alNDQUCCI++7rxebN\nmxk0qD8A0dEDqF27Ni7XdbRp05qjRw/SoUObcx7nzGNI1VKvzeGzWeitWrXik08+4cYbb+STTz6h\ndevWFY4pyMkwoTIRMUtBTgZZWW4yM/93B66wsAS3u5DMzDzWrduAn997xMU9QXFxMe+8s4Fbb21H\nrVrBXHttM5Yte4M+ffqRlXWCf/7zX9x//5/K7es0lyvonOul8qnXletCJ0M+CXCbzUb//v2Jj49n\n4MCB2O125syZU+G4ZU8N/M1P+DGD06mJVWZRr09NYjuf0aPH8uyzsxg8uB82m4077ujEAw8MAGDW\nrGeZO/dp1q17G8MweOih4TRrdp1ZZYv4nM04fU/bInRmV/V0Bm0e9doc6rN51OvKdaErcH0Sm4iI\niAUpwEVERCxIAS4iImJBCnARERELUoCLiIhYkAJcRETEghTgIiIiFqQAFxERsSAFuIiIiAUpwEVE\nRCxIAS4iImJBCnARERELqjDAv/jiC5YuXUpxcTFDhw7ltttuY9OmTWbUJiIiIudRYYAnJSXRokUL\n3n//fWrVqsXatWtZvHixGbWJiIjIeVQY4GVlZdx6661s3bqVbt26Ub9+fcrKysyoTURERM6jwgC/\n4oorWLJkCZ999hl33nknr7/+OrVr177oA3g8HqKjoxkwYAC5ubl88MEHjBs3rtw2r732GnPmzPnl\n1YvIJTEMg5kzE3njjeXedXl5eTz4YH/279/nXffttwfp2vV2HnpooPfPkSNpvihZRH7Gv6INnnvu\nOd566y3mzZtH3bp1ycjI+EVhm56eTn5+PikpKSQlJbF9+3aaN28OQGFhIZMnT2bv3r1069atwn2l\npqaSleW+6GPLpcnOdqjPJjGz1+HhjbDb7Rw+fIi5c5/mm2/2EhHRBIAdO/5BcvJcMjJ+xGazecd8\n9dUXdO3anQkTJptSo4hcvAoDPCwsjLZt23LgwAGuv/56OnbsSFhY2EUfICEhgbS0NKZOnUq7du3o\n2rUrq1atAqC4uJg//vGPdOjQgf/85z8V7it60koCg0Mv+tgickpBTgbJcb2IiIhk7do1REXdS1hY\nPe/jb721miefnMa0aeWDeu/eL/nhh2MMH/4gAIMGDaFjx06m1i4i51ZhgL/22mt89NFHZGRk0L17\ndxISEujTpw8PP/zwRR0gMTGR2NhYpk+fDsDOnTu9j9WpU4f27duzdu3ai9pXYHAojpAGF7WtiJzb\n2LETANi9exeGcWrdnDkvnnPbK64IpGvX7vTu3Ye0tMPExIwkLKweTZs2M6tcETmPCt8DX7t2LUuW\nLOGKK64gJCSENWvW8Pbbb1/0AYzT/0KIiOWMGxdP7959AGjU6Pd07tyFf/xjm4+rEhG4iCtwPz8/\n7Ha7dzkgIAB//wqHichlxul04HIFeZcDAmricNQqt65GDRshIYG4XEGUlZWxaNEiBg8e7J24WquW\nP3Xrlt+PVVixZqtSr81RYRK3adOG2bNnU1BQwIcffsiqVau47bbbftFBzpwUY7PZyi2fa5vzKcjJ\n+EXHFZFTCnIyyMpyk5mZ511XWFiC211Ubl1ZmUF2doF33ebNH1JaCv37D+LHH39g06b3mTfv5XJj\nrMDlCrJczValXleuC50M2YwK7nGXlZWxatUqduzYQVlZGW3btqV///4+uQrXLHRzOJ2ahW4WM3t9\nehb6abNmTaNx4wj69x/kXde3by+Skp7xvsf9/fff8eyzs8jOzsLjKWPo0BF07tzFlHork0LFPOp1\n5fpVAT506FCWLl1a6UVdKr0wqp7+AppHvTaH+mwe9bpyXSjAK5zEVlhYyLFjxyq1IBEREfl1KrwP\nnpWVRefOnbnyyiupVasWcOr96o8++qjKixMREZFzqzDAlyxZctavgl3MhDMRERGpOhUG+K5du84Z\n2A0a6ANVREREfKXCAN+5c6c3wEtKSvjnP/9J69at6d27d5UXJyIiIudWYYDPnj273PJPP/3E448/\nXmUFiYiISMUqnIX+c4GBgXz//fdVUYuIiIhcpAqvwKOjo8stHz16lI4dO1ZZQSIiIlKxCgM8JibG\nOwvdZrMREhJCZGRklRcmIiIi51fhLfT333+f2267jdtuu41bb72VyMhI4uPjzahNREREzuO8V+CT\nJ0/myJEj7N27l9TUVO96j8dDXp4+Jk9ERMSXzhvgo0aN4tixYyQlJZW7je7n50eTJk1MK1BERETO\ndt4ADw8PJzw8nA0bNvDTTz9x8uRJDMPA4/Gwb98+2rVrZ2adIiIicoYKJ7HNmTOHlStXUlJSQkhI\nCOnp6dxwww2sWbPGjPpERETkHCqcxPbuu++ydetWevTowbJly3jttdcICQkxozYRERE5jwoD3OVy\nERQUxLXXXsu+ffto27Ytx48fv+QDejweoqOjGTBgAHl5eXz77be0bt2a4uLiS96niJybYRjMnJnI\nG28s967Ly8vjwQf7s3//Pu+67747yuOPP8pDDw1k0KAHePPN5efanYhcRiq8he5wOFi3bh3Nmzdn\n+fLlhIaG/qpZ6Onp6eTn55OSkoLb7ebpp5/2fk1pRVJTU8nKcl/yseXiZGc71GeTVFWvw8MbcezY\n98yd+zTffLOXiIhTE0937PgHyclzycj4sdyXFM2aNY0ePe4hKupe8vPdPPzwYK69thmtWrWu9NpE\npHJUGOCzZs3i3XffpXfv3mzdupWEhIRf9VnoCQkJpKWlMXXqVNxuN7GxsTz66KMXNTZ60koCg0Mv\n+dgivwUFORkkx/Vi/fq1REXdS1hYPe9jb721miefnMa0aZPLjbnnnt507twFgNq1HTRsGE56+o+m\n1i0iv0yFAX711VfTr18/9u/fz4QJEzh58iS1a9e+5AMmJiYSGxtLaGgot9xyC82aNbvosYHBoThC\n9DWmIhdj7NgJAOzevYv//hYoc+a8eM5t7747yvvzZ599yldffcmkSVOrvEYRuXQVBviOHTuYOnUq\nHo+HN994OGFDAAAYzUlEQVR8k169evHss89y++23X9IBT/8++fr167n66qt56623OH78OMOGDWPZ\nsmWXtE8RKc/pdOByBQEQEFATh6OWdxmgRg0bISGB5dYBrF27lqeffpqXXppH06a/N7PkKvfz5ypV\nR702x0X9GtmKFSsYMWIEoaGhLFu2jNjY2EsO8NM2b97s/blz584sWbLkV+1PRP4nK8tNZuapuSqF\nhSW43UXeZYCyMoPs7ALvOsMweOmlF/jkk495/vkFNGkSWW57q3O5gqrV87mcqdeV60InQxUGeFlZ\nGaGh/3vfOTIystzkl0vx8/EXu7+CnIxfdVyR34JL+XuSnPwcX3/9FX/5y1+pW7duFVQlIpWtwgCv\nV68eW7ZsASA3N5cVK1ZQv379Sz5gw4YNefPNN8ut++ijjy5q7LKnBmp2tAmcTs1CN0tV9To8vFG5\n5QudI6en/0hKyhrCwuoxduz/JpQ+8MDAcu+Ni8jlxWacflP6Z3788UfCwsI4fvw4s2bNYvv27RiG\nQdu2bXnyySfLXZWbSbdmqp5ugZlHvTaH+mwe9bpyXdIt9FGjRrFu3Tquuuoqrr/+eubOnVslxYmI\niMgvV+EnsQFs2LChqusQERGRX+CiAlxEREQuLwpwERERCzrve+AHDx6kc+fOAGRkZHh/hlO/9nWx\nM8dFRESk8p03wDdt2mRmHSIiIvILnDfAGzZsaGYdIiIi8gvoPXARERELUoCLiIhYkAJcRETEghTg\nIiIiFqQAFxERsSAFuIiIiAUpwEVERCyowu8DF5Fz27btY5YuXUyNGjaCguoQH/8kQUFBPPfcbA4e\nTCUg4Ap69ryHPn36+bpUEamGTA9wj8fDkCFDyMrKon79+uTn51O3bl2SkpJwOp0XHJuamkpWltuk\nSn+7srMd6vN5hIc3wm63U1RUyIwZU3j99Tdp0KAhq1evJDn5OYKD61K7dm1WrHgLj8fDpEnjqFev\nAX/4Qwdfly4i1YzpAZ6enk5+fj533HEHISEhjBgxgh07djB37lySkpIuODZ60koCg0NNqlSkvIKc\nDJLjehEREYnHUwaA233qRKegoAC73c6BA/uIjY3HZrPh7+9P27bt2br1IwW4iFQ60wM8ISGBtLQ0\nHA4HkyZNAuDmm29m+vTpFY4NDA7FEdKgqksUqVBgYCDjxk3kkUeGUqdOMIZRxoIFS1i27FU2bXqX\nFi1upLi4mG3btlCzpt3X5YpINWT6JLbExESaNGnCzTff7P1Gsy1btlBYWGh2KSKX7NtvD/L660tY\nvnwN69b9jejoh5g8eQKjR4/FZrMxdOifmDw5jjZt2uLv7+frckWkGjL9CtwwDABGjBhBUlISgwYN\nomPHjoSFhZldisgv5nQ6cLmCWL/+X7Rp05qWLZsBMGLEUObNe56AAJgy5QmCg4MBWLx4Mdde2wSX\nK+i8+7zQY1J51GfzqNfm8Nks9N27d/PAAw9w88038/7773PLLbdUOKYgJ8OEykTOrSAng6wsN5mZ\neTRs2Jhly5aTmppGSIiTrVs/ol69+ixZ8joFBfmMHTuBrKwTrFq1msTEWWRm5p1zny5X0Hkfk8qj\nPptHva5cFzoZ8kmA22w2rrnmGiZMmABAWFgYM2fOrHDcsqcGana0CZxOzUI/n/DwRgC0atWaAQOi\niYkZib9/TYKDg5k9ey6hoVczY8ZUBg/uh2EYDB06kmbNrvNx1SJSHdmM0/e0LUJndlVPZ9DmUa/N\noT6bR72uXBe6AtcnsYmIiFiQAlxERMSCFOAiIiIWpAAXERGxIAW4iIiIBSnARURELEgBLiIiYkEK\ncBEREQtSgIuIiFiQAlxERMSCFOAiIiIWpAAXERGxIAW4iIiIBSnARURELEgBLiIiYkH+Zh/Q4/Ew\nZMgQ3G43V199Nfn5+ZSUlDBx4kRuuukms8sRuWTbtn3M0qWLqVHDRlBQHeLjnyQoKIjnnpvNwYOp\nBARcQc+e99CnTz9flyoi1ZDpAZ6enk5+fj6dO3cmODiYwYMHc+jQIcaNG0dKSsoFx6amppKV5Tap\n0t+u7GyH+nwe4eGNsNvtFBUVMmPGFF5//U0aNGjI6tUrSU5+juDgutSuXZsVK97C4/EwadI46tVr\nwB/+0MHXpYtINWN6gCckJJCWlsbx48cZOXIkAKWlpdSqVavCsdGTVhIYHFrVJYqcU0FOBslxvYiI\niMTjKQPA7T51olNQUIDdbufAgX3ExsZjs9nw9/enbdv2bN36kQJcRCqd6QGemJhIbGws06ZNAyAz\nM5MJEyYwefLkCscGBofiCGlQ1SWKVCgwMJBx4ybyyCNDqVMnGMMoY8GCJSxb9iqbNr1LixY3Ulxc\nzLZtW6hZ0+7rckWkGjI9wA3D8P584MABxo0bR3x8PK1btza7FJFfzOl04HIFceDAAZYvf5X33nuP\n8PBwli1bRkLCRJYvX87TTz/NiBGDcblcdOrUkX/961+4XEHn3eeFHpPKoz6bR702h+kBftrBgwcZ\nM2YMycnJNG3a1FdliPwiWVluMjPz2LTpI5o3v4GAgLpkZubRtes9PPXUU6Sl/chDDz1CnTp1AFi+\n/DVCQ+uTmZl3zv25XEHnfUwqj/psHvW6cl3oZMj0ALfZbADMnTuXkpISkpKSAKhTpw7z58+/4NiC\nnIwqr0/kfM58/TVrdh1r164hOzuLkBAnf//7VurVq8+6dW9TUJDP2LETyMo6wcaN75CYOMuHVYtI\ndWUzzrynfZnTLHRzOJ2ahX4+p2ehA6SkrCElZTX+/jUJDg5m7NgJhIZezYwZU/n++6MYhkF09FDu\nuqv7efenqxVzqM/mUa8r14WuwC0V4IBeGCbQX0DzqNfmUJ/No15XrgsFuD6JTURExIIU4CIiIhak\nABcREbEgBbiIiIgFKcBFREQsSAEuIiJiQQpwERERC1KAi4iIWJACXERExIIU4CIiIhakABcREbEg\nBbiIiIgFKcBFREQsSAEuIiJiQf6+LkCksmza9C6rVq3wLrvdbjIzM1i79m+EhIQA8MQTcbhcLsaO\nneCrMkVEKkWVBbjH42HIkCGUlpayaNEidu7cyaZNm5gzZw4Ae/bsYdasWfj5+dG+fXtGjx5dVaXI\nb0T37j3p3r0nAKWlpYwePYLo6Ie84b1ixet8+eUeunS5y5dliohUiioL8PT0dPLz80lJSSEpKYnt\n27fTvHlz7+OJiYnMmzeP8PBwRowYwb59+7juuusuuM/U1FSystxVVbL8V3a2w1J9Dg9vhN1uL7du\n+fLXCAlx0qvXfQD861+72bXrM3r37kNeXq4vyhQRqVRVFuAJCQmkpaUxdepU2rVrR9euXVm1ahVw\n6tZmcXEx4eHhAHTo0IFPP/20wgCPnrSSwODQqipZLKggJ4PkuF5ERER61/3000+sWrWSV189dTv9\n+PFMkpPn8PzzL7Fu3du+KlVEpFJVWYAnJiYSGxvL9OnTAdi5c6f3MbfbjcPh8C7Xrl2bo0ePVrjP\nwOBQHCENKr9YqVbWr0/h9ts7EhZWj9LSUhISnmDMmHE4nVdiGIavyxMRqRRVFuAX+ofS4XCQn5/v\nXXa73dSpU6eqSpFqzul04HIFeZc/+WQLU6ZMweUK4t///jcZGT+ycGEyAMePH8fj8eDnBzNmzPBV\nyeWcWbtUHfXZPOq1OXwyC93hcFCzZk2OHj1Kw4YN2b59+0VNYivIyTChOrGSgpwMsrLcZGbmAZCb\nm0taWhoNGzYhMzOPhg2bsGbNBu/2S5cuJjc3h8cei/OO8SWXK+iyqKO6U5/No15XrgudDFVpgNts\ntnI/n7k8bdo0xo8fj8fjoUOHDtx4440V7m/ZUwMtNbnKqpxO601iO+37749y5ZUu/Pz8fFiRiEjV\nsxkWe1NQZ3ZVT2fQ5lGvzaE+m0e9rlwXugLXJ7GJiIhYkAJcRETEghTgIiIiFqQAFxERsSAFuIiI\niAUpwEVERCxIAS4iImJBCnARERELUoCLiIhYkAJcRETEghTgIiIiFqQAFxERsSAFuIiIiAUpwEVE\nRCxIAS4iImJB/r44qMfjYciQIZSWlrJo0SJ27tzJpk2bmDNnji/KMd3777/HG28sx2aDgIAAxoyJ\no1mz60hJWcPGje9QXFxE06bNmDhxKjVr1vR1uSIichnySYCnp6eTn59PSkoKSUlJbN++nebNm1c4\nLjU1lawstwkVVr7w8EbY7XaOHDnMggUv8uqrK3A6r2THju1MnhzHY4+NIyVlNQsXLsXhcDBlSjyr\nVq1g0KAhvi5dREQuQz4J8ISEBNLS0pg6dSrt2rWja9eurFq1qsJx0ZNWEhgcakKFlasgJ4PkuF5E\nRERit9di4sQpOJ1XAtCs2XVkZZ1g48Z19O8/iKCgIADGj3+C0tISX5YtIiKXMZ8EeGJiIrGxsUyf\nPh2AnTt3XtS4wOBQHCENqrK0KhcWVo+wsHoAGIbBvHnP0779HRw+fIjs7CzGjXuM48czadnyJh59\ndIyPqxURkcuVTyaxGYbhi8NeVk6ePMmUKRM5dux7Jk6cQmlpCbt372LGjNksWbKM3NxcFi+e7+sy\nRUTkMuWTK/DfIqfTgct16vb4sWPHGD16FJGRkcybtwK73U79+vXo1q0bjRpdDUDfvn9kwYIF3jFm\n89Vxf4vUa3Ooz+ZRr83hswC32Wzlfj5z+XwKcjKqsqQqU5CTQVaWm8zMPHJzcxg2LJqePXsxZMjD\n5OQUAUW0b9+R9es3cued3bHb7Wzc+DciI5uRmZlner0uV5BPjvtbpF6bQ302j3pduS50MmQzLHQ/\nuzrMQn/99SUsXbqYxo0jvI/ZbDZeeGEBb7+9mo8++oCyMg9Nm15HXNwTBAYGml6r/gKaR702h/ps\nHvW6clWbAAf0wjCB/gKaR702h/psHvW6cl0owPVJbCIiIhakABcREbEgBbiIiIgFKcBFREQsSAEu\nIiJiQQpwERERC1KAi4iIWJACXERExIIU4CIiIhakABcREbEgBbiIiIgFKcBFREQsSAEuIiJiQQpw\nERERC1KAi4iIWJC/2Qf0eDwMGTIEt9vNVVddRUFBAXa7nWeffZarrrrK7HKq1Pvvv8cbbyzHZoOA\ngADGjImjYcNwZs+ezpEjaZSVGdx9d0/+9KcHfV2qiIhYjOkBnp6eTn5+Pvfddx8ZGRmMHz+eNWvW\nsGTJEuLj4y84NjU1lawst0mVXprw8EbY7XaOHDnMggUv8uqrK3A6r2THju088cR47rijE1dfHUZS\n0jMUFhYSHf0AN910C9df38LXpYuIiIWYHuAJCQmkpaWxYsUK2rVrB0BeXh41a9ascGz0pJUEBodW\ndYmXrCAng+S4XkRERGK312LixCk4nVcC0KzZdWRnZzF69OPYbDYAMjMzKC4uxuFw+LJsERGxINMD\nPDExkdjYWKZNm0ZMTAw9e/YkJyeHFStWVDg2MDgUR0gDE6r89cLC6hEWVg8AwzCYN+95OnToiL//\nqZZPnz6FrVu30LFjJ8LDf+fLUkVExIJMD3DDMACYP38+w4cP54EHHuDAgQPExMSwfv16s8updE6n\nA5cryLtcUFDAxIkTyczM4JVXXvFebc+b9wIFBQXExMSwevVfiYmJ8VXJ53Tmc5CqpV6bQ302j3pt\nDtMD/LTg4GBvmDmdTtzuy/u97YuVleUmMzMPgB9//JH4+LFcc01j5syZz8mTBlu3biYiItI7Ye+O\nO/6Pbdu2eMdcDlyuoMuqnupMvTaH+mwe9bpyXehkyCcBbrPZeOyxx3jyySdZuXIlpaWlzJw5s8Jx\nBTkZJlR36c6sLzc3h5iYEfTs2YshQx72rv/44w/55JOPiYt7guLiYrZs+YBbb23ni3JFRMTCbMbp\ne9oWYKVZ6K+/voSlSxfTuHGE9zGbzcYLLyxkzpzZHDr0LTabjTvu6MSwYSN9WPHZdAZtHvXaHOqz\nedTrynWhK3BLBTigF4YJ9BfQPOq1OdRn86jXletCAa5PYhMREbEgBbiIiIgFKcBFREQsSAEuIiJi\nQQpwERERC1KAi4iIWJACXERExIIU4CIiIhakABcREbEgBbiIiIgFKcBFREQsSAEuIiJiQQpwERER\nC1KAi4iIWJACXERExIIU4CIiIhakABcREbEgBbiIiIgFKcBFREQsyGYYhuHrIkREROSX0RW4iIiI\nBSnARURELEgBLiIiYkEKcBEREQtSgIuIiFiQAlxERMSC/H1dQEXKyspITEwkNTWVmjVrMnPmTH73\nu9/5uqxq5b777sPhcAAQHh7OyJEjmThxIjVq1CAyMpKEhARsNpuPq7SuL774gueee45ly5aRlpZ2\nzt6uXr2aVatW4e/vzyOPPMKdd97p67It6cxef/PNN4waNYpGjRoBMHDgQO6++271+lcqKSnhiSee\n4NixYxQXF/PII48QERGh17UvGJe5999/35g4caJhGIaxZ88e45FHHvFxRdVLYWGh0bt373LrRo4c\naezatcswDMOYOnWq8cEHH/iitGph8eLFRlRUlNGvXz/DMM7d24yMDCMqKsooLi428vLyjKioKKOo\nqMiXZVvSz3u9evVqY+nSpeW2Ua9/vbffftuYNWuWYRiG8dNPPxkdO3Y0Ro0apde1D1z2t9D/9a9/\ncfvttwPQsmVL9u7d6+OKqpf9+/dz8uRJhg0bxoMPPsiePXv45ptvaNOmDQB33HEHn376qY+rtK5G\njRrx0ksvYfz385LO1duvvvqKVq1aUbNmTRwOB40aNeLAgQO+LNuSft7rvXv3snXrVgYNGsTkyZPJ\nz8/nyy+/VK9/pe7du/PYY48Bp+6Q+vv763XtI5d9gLvdbu/tXQA/Pz/Kysp8WFH1csUVVzBs2DCW\nLFnCtGnTGD9+fLnHAwMDycvL81F11nfXXXfh5+fnXTbO+ODD2rVrk5eXh9vtJigoqNx6t9ttap3V\nwc973bJlS+Lj41m+fDnh4eG89NJL5Ofnq9e/UmBgoLdvY8aM4fHHHy/3b7Je1+a57APc4XCQn5/v\nXS4rK6NGjcu+bMv4/e9/T69evbw/161blxMnTngfz8/Pp06dOr4qr9o587XrdrupU6fOWa9x9bxy\ndO3alebNm3t/3rdvn3pdSX744QcefPBBevfuTVRUlF7XPnLZJ2GrVq345JNPANizZw9Nmzb1cUXV\ny9tvv83s2bMBSE9PJz8/n/bt27Nr1y4APvnkE1q3bu3LEquV66677qze3njjjezevZvi4mLy8vL4\n9ttviYyM9HGl1jds2DC+/PJLAD799FNatGihXleC48ePM3ToUOLi4vjjH/8I6HXtK5f9LPSuXbuy\nfft2+vfvD8BTTz3l44qql/vvv5+JEycycOBAbDYbTz31FHXr1mXKlCmUlJQQERFB9+7dfV2m5Z2e\nxT9x4sSzemuz2Rg8eDADBw6krKyM2NhY7Ha7jyu2rtO9TkxMZMaMGfj7+xMaGsr06dOpXbu2ev0r\nvfzyy+Tl5TF//nzmz58PwOTJk5k5c6Ze1ybTt5GJiIhY0GV/C11ERETOpgAXERGxIAW4iIiIBSnA\nRURELEgBLiIiYkEKcBEREQu67H8PXEQu3XfffUf37t1p0qRJufWLFi3i6quv9lFVIlIZFOAi1Vxo\naCjr1q3zdRkiUskU4CLChg0bWLJkCTVq1KBhw4Y899xz1KxZk+eee44PP/wQf39/+vXrx+DBgzl0\n6BBTp04lJyeHwMBAJk+ezA033MDEiRP56aefOHLkCBMmTMDpdDJ79mwKCwsJCQlh2rRpNGzY0NdP\nVaTaUICLVHMZGRn07t3bu9yrVy+GDh1abpvk5GRWr16N0+nkhRde4D//+Q+HDh3i3//+Nxs3bqSk\npISBAwfSo0cP4uLiGDVqFF26dOGLL75gzJgxbNq0CYCQkBBefvlliouLuf/++1m8eDFhYWH8/e9/\nZ8qUKbz66qumPneR6kwBLlLNXcwt9E6dOjFgwAD+7//+j27dutGsWTPWrFlDjx49qFmzJjVr1mTd\nunXk5+dz9OhRunTpApz6ys7g4GAOHTqEzWajZcuWABw+fJijR48yatQo7zHO/GYqEfn1FOAiwuTJ\nk7n//vvZtm0bcXFxjB49Gn9//3LfX/7dd98RHBzMz78+wTAMPB4PALVq1QJOfe1veHi498ShrKyM\n48ePm/RsRH4b9GtkIr9xpaWldOvWjZCQEEaMGMG9997Lvn37aNOmDZs3b6a0tJSTJ08yfPhwTpw4\nQXh4OB988AFw6it+jx8/ftbXRDZu3JicnBx2794NwFtvvcW4ceNMf24i1ZmuwEWqudNfr3k+/v7+\nPPbYYzz00EMEBAQQHBzM7NmzCQ0N5auvvuK+++7DMAwefPBBfv/73/Pss8+SkJDAiy++SK1atXjp\npZeoWbNmuWPZ7XaSk5OZOXMmRUVFBAUFeb93XkQqh75OVERExIJ0C11ERMSCFOAiIiIWpAAXERGx\nIAW4iIiIBSnARURELEgBLiIiYkEKcBEREQtSgIuIiFjQ/wPqMfp/FBQHwwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112c482d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Boston Housing: regression\")\n",
    "#y = boston['target']\n",
    "#X = boston['data']\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1729)\n",
    "\n",
    "\n",
    "'''base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
    "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=1\n",
    "        \n",
    "        \n",
    "learning_rate=0.1\n",
    "max_depth=3\n",
    "missing=np.nan, learning_rate=0.02, subsample=0.9, colsample_bytree=0.85\n",
    "'''\n",
    "\n",
    "#in order depth= 10, subsample=1.0, min_child_weight = 5, col_sample_bytree = 0.2, eta = 0.1, \n",
    "\n",
    "#col_sample_bytree = 0.4 - 1\n",
    "#gamma = 0.05,0.1 0.3, 0.5, 0.7, 1\n",
    "#lambda = 0.01, 0.1, 1\n",
    "#alpha = 0.01, 0.1, 1\n",
    "#n_estimators is last..\n",
    "\n",
    "\n",
    "defaultParams = {\"max_depth\":10, \"subsample\":1., \"min_child_weight\":5, \"colsample_bytree\":0.4, \"missing\":np.nan\n",
    "                ,\"n_estimators\":300}\n",
    "xgb_model = xgb.XGBRegressor(**defaultParams) \n",
    "\n",
    "\n",
    "xgb_model.fit(X_train,y_train,eval_set=[(X_train, y_train),(X_test, y_test)],\n",
    "         verbose=1, early_stopping_rounds = 30)\n",
    "\n",
    "\n",
    "predictions = xgb_model.predict(X_train,ntree_limit  = xgb_model.best_iteration+1)\n",
    "predictionsTest = xgb_model.predict(X_test,ntree_limit  = xgb_model.best_iteration+1)\n",
    "\n",
    "print \"trainResult: \", np.sqrt(mean_squared_error(y_train, predictions))\n",
    "print \"testResult: \", np.sqrt(mean_squared_error(y_test, predictionsTest))\n",
    "print \"Best Iteration: \", xgb_model.best_iteration\n",
    "print \"Best Score: \", xgb_model.best_score\n",
    "print xgb.plot_importance(xgb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GiveBestParameterWithoutCV(defaultParams, testParams, X_train, X_test, Y_train, Y_test, fitParams):\n",
    "    xgb_model = xgb.XGBRegressor(**defaultParams) \n",
    "    \n",
    "    minRmse = 10000\n",
    "    minRmseParameter = 10000\n",
    "    bestIteration = 1000\n",
    "        \n",
    "    for key,values in testParams:\n",
    "        minRmseParameter = xgb_model.get_xgb_params()[key]\n",
    "        \n",
    "        for value in values:\n",
    "            \n",
    "            xgb_model.set_params(**{key:value})\n",
    "            xgb_model.fit(X_train,Y_train, eval_set=[(X_train, Y_train),(X_test, Y_test)],\n",
    "                  **fitParams)\n",
    "            if xgb_model.best_score < minRmse:\n",
    "                minRmse = xgb_model.best_score\n",
    "                minRmseParameter = value\n",
    "                bestIteration = xgb_model.best_iteration\n",
    "                \n",
    "        xgb_model.set_params(**{key:minRmseParameter})\n",
    "        print \"Parameters are finished for {}. Best Iteration is {}\".format(key, bestIteration)\n",
    "        print \"Minimum Rmse : {}, optimum parameter is {} between {}\".format(minRmse, minRmseParameter, values)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5eafe16c60ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfitParams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"verbose\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"early_stopping_rounds\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mGiveBestParameterWithoutCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaultParams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitParams\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "defaultParams = {\"max_depth\":10, \"subsample\":1., \"min_child_weight\":5, \"colsample_bytree\":0.4, \"missing\":np.nan\n",
    "                ,\"n_estimators\":300, \"learning_rate\":0.1}\n",
    "testParams = [(\"max_depth\",[12,8,6,14]), (\"subsample\",[0.9,0.8,0.6]), (\"min_child_weight\",[1,3,7]),\n",
    "                  (\"colsample_bytree\",[0.3,0.5,0.6, 0.8,1]), (\"learning_rate\",[0.05])]\n",
    "fitParams = {\"verbose\":10, \"early_stopping_rounds\": 50}\n",
    "\n",
    "GiveBestParameterWithoutCV(defaultParams,testParams, X_train, X_test, y_train, y_test, fitParams )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Start from 10 and play up down..\n",
    "max_depth = [12,8]\n",
    "subsample = [0.8,0.6]\n",
    "min_child_weight = [3,7]\n",
    "colsample_bytree = [0.3,0.5,0.8,1]\n",
    "#lambdaa = [0.01, 0.1, 1]\n",
    "#alpha = [0.01, 0.1]\n",
    "#Use this eta to find the optimum iteration\n",
    "eta = [0.05]\n",
    "\n",
    "xgb_model.fit(X_train,y_train,eval_set=[(X_train, y_train),(X_test, y_test)],\n",
    "         verbose=1, early_stopping_rounds = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "3.764692"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-77f616839564>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.4,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=4, missing=None, n_estimators=300, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1.0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.set_params(**{\"min_child_weight\":4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.get_xgb_params()[\"min_child_weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = OrderedDict({\"max_depth\":10, \"subsample\":1., \"min_child_weight\":5, \"colsample_bytree\":0.4, \"missing\":np.nan\n",
    "                ,\"n_estimators\":300, \"learning_rate\":0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('colsample_bytree', 0.4), ('missing', nan), ('learning_rate', 0.1), ('min_child_weight', 5), ('n_estimators', 300), ('subsample', 1.0), ('max_depth', 10)])\n",
      "OrderedDict([('colsample_bytree', 0.4), ('missing', nan), ('learning_rate', 0.1), ('min_child_weight', 5), ('n_estimators', 300), ('subsample', 1.0), ('max_depth', 10)])\n",
      "OrderedDict([('colsample_bytree', 0.4), ('missing', nan), ('learning_rate', 0.1), ('min_child_weight', 5), ('n_estimators', 300), ('subsample', 1.0), ('max_depth', 10)])\n",
      "OrderedDict([('colsample_bytree', 0.4), ('missing', nan), ('learning_rate', 0.1), ('min_child_weight', 5), ('n_estimators', 300), ('subsample', 1.0), ('max_depth', 10)])\n",
      "OrderedDict([('colsample_bytree', 0.4), ('missing', nan), ('learning_rate', 0.1), ('min_child_weight', 5), ('n_estimators', 300), ('subsample', 1.0), ('max_depth', 10)])\n",
      "OrderedDict([('colsample_bytree', 0.4), ('missing', nan), ('learning_rate', 0.1), ('min_child_weight', 5), ('n_estimators', 300), ('subsample', 1.0), ('max_depth', 10)])\n",
      "OrderedDict([('colsample_bytree', 0.4), ('missing', nan), ('learning_rate', 0.1), ('min_child_weight', 5), ('n_estimators', 300), ('subsample', 1.0), ('max_depth', 10)])\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qwe = [(\"max_depth\",[12,8]), (\"subsample\",[0.8,0.6]), (\"min_child_weight\",[3,7]),\n",
    "                  (\"colsample_bytree\",[0.3,0.5,0.8,1]), (\"learning_rate\",[0.05])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('max_depth', [12, 8])\n",
      "('subsample', [0.8, 0.6])\n",
      "('min_child_weight', [3, 7])\n",
      "('colsample_bytree', [0.3, 0.5, 0.8, 1])\n",
      "('learning_rate', [0.05])\n"
     ]
    }
   ],
   "source": [
    "for i in qwe:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
