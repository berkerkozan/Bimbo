{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import nltk.corpus\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import datasets, linear_model\n",
    "import scipy.sparse as sps\n",
    "from scipy.sparse import coo_matrix, hstack, vstack, csr_matrix\n",
    "from scipy import io\n",
    "from datetime import datetime\n",
    "import gc\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline\n",
    "from IPython.display import display, HTML\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureEngineering:\n",
    "    #ValidationStart = 0\n",
    "    #lag = 0\n",
    "    #trainHdfPath = \"\"\n",
    "    #trainHdfFile = \"\"\n",
    "    #testHdfPath = \"\"\n",
    "    #testHdfFile = \"\"\n",
    "    #train = pd.DataFrame()\n",
    "    #test = pd.DataFrame()\n",
    "    \n",
    "    def __init__(self, ValidationStart, ValidationSmallerThan, trainHdfPath, trainHdfFile, testHdfPath, testHdfFile, \n",
    "                 testTypes, trainTypes, trainCsvPath, testCsvPath, maxLag=0):\n",
    "        self.ValidationStart = ValidationStart\n",
    "        self.ValidationSmallerThan = ValidationSmallerThan\n",
    "        self.maxLag = maxLag\n",
    "        self.trainHdfPath = trainHdfPath\n",
    "        self.trainHdfFile = trainHdfFile\n",
    "        self.testHdfPath = testHdfPath\n",
    "        self.testHdfFile = testHdfFile\n",
    "        self.testTypes = testTypes\n",
    "        self.trainTypes = trainTypes\n",
    "        self.trainCsvPath = trainCsvPath\n",
    "        self.testCsvPath = testCsvPath\n",
    "        \n",
    "    @staticmethod\n",
    "    def __printDataFrameBasics__(data):\n",
    "        display(data.head(2))\n",
    "        #print data.dtypes\n",
    "        gc.collect()\n",
    "        print(data.info(memory_usage=True))\n",
    "        \n",
    "    @staticmethod    \n",
    "    def __changeIndexTypeToLowerMemory(data):\n",
    "        ##########\n",
    "        #This is very critical, i accept max number is 2^32. Also, if don't do that, memory gets so much higher..\n",
    "        ##########\n",
    "        data.index = data.index.astype('uint32')\n",
    "        \n",
    "    def ReadHdf(self, trainOrTestOrBoth):\n",
    "        '''Reads and holds Df in object memory'''\n",
    "        if trainOrTestOrBoth == '':\n",
    "            raise \"qweqweq\"\n",
    "            \n",
    "        if trainOrTestOrBoth == 'train' or trainOrTestOrBoth=='both':\n",
    "            self.train = pd.read_hdf(self.trainHdfPath,self.trainHdfFile)\n",
    "            FeatureEngineering.__changeIndexTypeToLowerMemory(self.train)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.train)\n",
    "        if trainOrTestOrBoth == 'test' or trainOrTestOrBoth=='both':\n",
    "            self.test = pd.read_hdf(self.testHdfPath,self.testHdfFile)\n",
    "            FeatureEngineering.__changeIndexTypeToLowerMemory(self.test)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test)\n",
    "        \n",
    "    def ReadCsv(self, trainOrTestOrBoth):\n",
    "        '''Reads and holds Df in object memory'''\n",
    "        if trainOrTestOrBoth == '':\n",
    "            raise \"qweqweq\"  \n",
    "        if trainOrTestOrBoth == 'train' or trainOrTestOrBoth=='both':\n",
    "            self.train = pd.read_csv(self.trainCsvPath, usecols=self.trainTypes.keys(), dtype=self.trainTypes)\n",
    "            #__changeIndexTypeToLowerMemory(self.train)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.train)\n",
    "        if trainOrTestOrBoth == 'test' or trainOrTestOrBoth=='both':\n",
    "            self.test = pd.read_csv(self.testCsvPath, usecols=self.testTypes.keys(), dtype=self.testTypes)\n",
    "            #__changeIndexTypeToLowerMemory(self.test)\n",
    "            FeatureEngineering.__printDataFrameBasics__(self.test)\n",
    "\n",
    "    @staticmethod\n",
    "    def ConvertCsvToHdf(csvPath, HdfPath, HdfName, ColumnTypeDict ):\n",
    "        tempDf = pd.read_csv(csvPath, usecols=ColumnTypeDict.keys(), dtype=ColumnTypeDict)\n",
    "        tempDf.to_hdf(HdfPath, HdfName, format='t')\n",
    "        print \"ConvertCsvToHdf is done..\"\n",
    "\n",
    "    def Preprocess(self, trainOrTestOrBoth, columnFunctionTypeList):\n",
    "        '''columnFunctionTypeList = [ ['C1',Func1,Type], ['C2',Func2,Type],..    ]'''\n",
    "        for column, func, localType in columnFunctionTypeList:\n",
    "            if trainOrTestOrBoth == 'train' or trainOrTestOrBoth=='both':\n",
    "                self.train.loc[:,column] =  self.train[column].apply(func).astype(localType)\n",
    "            elif trainOrTestOrBoth == 'test' or trainOrTestOrBoth=='both':\n",
    "                self.test.loc[:,column] =  self.test[column].apply(func).astype(localType)\n",
    "            \n",
    "    def SaveDataFrameToHdf(self,trainOrTestOrBoth):\n",
    "        if trainOrTestOrBoth == 'train' or trainOrTestOrBoth=='both':\n",
    "            self.train.to_hdf(self.trainHdfPath, self.trainHdfFile, format='t')\n",
    "        if trainOrTestOrBoth == 'test' or trainOrTestOrBoth=='both':\n",
    "            self.test.to_hdf(self.testHdfPath, self.testHdfFile, format='t')\n",
    "        \n",
    "    def AddDemandaGeneralMean(self):\n",
    "        DemandaMeanWithoutLag = self.train.loc[self.train.loc[:,'Semana'] < self.ValidationStart]\n",
    "        self.train.loc[:,\"DemandaGeneralMean\"] = DemandaMeanWithoutLag['Demanda_uni_equil'].mean()\n",
    "        self.train.loc[:,\"DemandaGeneralMean\"] = self.train.loc[:,\"DemandaGeneralMean\"].astype('float32')\n",
    "        display(self.train)\n",
    "        \n",
    "    def AddConfigurableFeaturesToTrain(self, config):\n",
    "        if config.lag > self.maxLag:\n",
    "            self.maxLag = config.lag\n",
    "        \n",
    "        lag = 0 if config.lag == 0 else config.lag-1\n",
    "        tempData = self.train.loc[self.train.loc[:,'Semana'] < self.ValidationStart - lag]\n",
    "        #display(tempData)\n",
    "        if(config.lag != 0):\n",
    "            tempData.loc[:,'Semana'] = tempData.loc[:,'Semana'].apply(lambda x:x + config.lag)\n",
    "        #display(tempData)\n",
    "        \n",
    "        #Means iterative.. eliminate as long as np.nan exists..If there is already one, don't create, use the existing\n",
    "        if config.targetVariable != \"\" and  config.targetVariable not in self.train.columns:\n",
    "            self.train.loc[:,config.targetVariable] = np.nan\n",
    "        \n",
    "        for name,groups in config.nameAndGroups:\n",
    "            if name not in self.train.columns:\n",
    "                print \"{} is not in columns..\".format(name)\n",
    "                \n",
    "                ##First, select columns not to fill memory..then groupby..\n",
    "                \n",
    "                groupedDataframe =  pd.DataFrame({name:tempData[groups+['Demanda_uni_equil']].groupby(groups)\n",
    "                    ['Demanda_uni_equil'].mean().astype('float32')})\n",
    "                #join..\n",
    "                \n",
    "                display(groupedDataframe)\n",
    "                self.train = self.train.merge( groupedDataframe, left_on=groups,\n",
    "                                  right_index=True, how='left', sort=False,copy=False)\n",
    "            else:\n",
    "                print \"{} is in columns..\".format(name)\n",
    "            \n",
    "            display(self.train)\n",
    "            \n",
    "            #Means iterative..!!!!!\n",
    "            if config.targetVariable != \"\":\n",
    "                self.train.loc[pd.isnull(self.train[config.targetVariable]), \n",
    "                    config.targetVariable] = self.train.loc[pd.isnull(self.train[config.targetVariable]), name]\n",
    "                count = self.train.loc[self.train['Semana'] >= self.ValidationStart,config.targetVariable].isnull().sum()\n",
    "                print \"Count of missing numbers after {} in validation part in column {} is {}\".format(name, \n",
    "                    config.targetVariable,str(count))\n",
    "                #display(self.train)\n",
    "                #If column is already in Dataframe and we want to fill target variable, this deletes columns!!!\n",
    "                if(config.deleteColumns):\n",
    "                    self.train.drop(name, axis=1, inplace=True)\n",
    "                gc.collect()\n",
    "                if count == 0:\n",
    "                    break\n",
    "        display(self.train)        \n",
    "        gc.collect()\n",
    "        return \n",
    "    def DeleteLaggedWeeksFromTrain(self):\n",
    "        self.train = self.train.loc[self.train.loc[:,'Semana']>= 3 + self.maxLag]\n",
    "        display(self.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'maxLag': 2, 'testTypes': {'Cliente_ID': <type 'numpy.uint32'>, 'Ruta_SAK': <type 'numpy.uint16'>, 'Canal_ID': <type 'numpy.uint8'>, 'Producto_ID': <type 'numpy.uint16'>, 'Agencia_ID': <type 'numpy.uint16'>, 'Semana': <type 'numpy.uint8'>, 'id': <type 'numpy.uint32'>}, 'testHdfFile': 'test', 'trainTypes': {'Dev_proxima': <type 'numpy.float32'>, 'Venta_uni_hoy': <type 'numpy.uint16'>, 'Cliente_ID': <type 'numpy.uint32'>, 'Demanda_uni_equil': <type 'numpy.uint32'>, 'Ruta_SAK': <type 'numpy.uint16'>, 'Canal_ID': <type 'numpy.uint8'>, 'Venta_hoy': <type 'numpy.float32'>, 'Producto_ID': <type 'numpy.uint16'>, 'Agencia_ID': <type 'numpy.uint16'>, 'Dev_uni_proxima': <type 'numpy.uint32'>, 'Semana': <type 'numpy.uint8'>}, 'trainCsvPath': '../../input/train.csv', 'testHdfPath': '../../input/test.h5', 'testCsvPath': '../../input/test.csv', 'ValidationStart': 6, 'trainHdfFile': 'train', 'trainHdfPath': '../../input/train.h5', 'ValidationSmallerThan': 7}\n"
     ]
    }
   ],
   "source": [
    "parameterDict =       {\"ValidationStart\":6, \n",
    " \"ValidationSmallerThan\":7,\n",
    "   \"maxLag\":2,\n",
    "    \"trainHdfPath\":'../../input/train.h5',\n",
    "    \"trainHdfFile\":\"train\",\n",
    "    \"testHdfPath\":\"../../input/test.h5\",\n",
    "    \"testHdfFile\":\"test\", \n",
    "    \"trainTypes\" : {'Semana':np.uint8, 'Agencia_ID':np.uint16, 'Canal_ID':np.uint8,'Ruta_SAK':np.uint16, \n",
    "        'Cliente_ID':np.uint32, 'Producto_ID':np.uint16,'Venta_uni_hoy':np.uint16, 'Venta_hoy':np.float32,\n",
    "                    'Dev_uni_proxima': np.uint32, 'Dev_proxima':np.float32,'Demanda_uni_equil':np.uint32}, \n",
    "    \"testTypes\" : {'id':np.uint32,'Semana':np.uint8, 'Agencia_ID':np.uint16, 'Canal_ID':np.uint8,'Ruta_SAK':np.uint16,\n",
    "        'Cliente_ID':np.uint32, 'Producto_ID':np.uint16},\n",
    "    \"trainCsvPath\":'../../input/train.csv'   ,\n",
    "    \"testCsvPath\":'../../input/test.csv'}\n",
    "\n",
    "FE = FeatureEngineering(**parameterDict)\n",
    "print FE.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Venta_uni_hoy</th>\n",
       "      <th>Venta_hoy</th>\n",
       "      <th>Dev_uni_proxima</th>\n",
       "      <th>Dev_proxima</th>\n",
       "      <th>Demanda_uni_equil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1212</td>\n",
       "      <td>3</td>\n",
       "      <td>25.139999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.386294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1216</td>\n",
       "      <td>4</td>\n",
       "      <td>33.520000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID  \\\n",
       "0       3        1110         7      3301       15766         1212   \n",
       "1       3        1110         7      3301       15766         1216   \n",
       "\n",
       "   Venta_uni_hoy  Venta_hoy  Dev_uni_proxima  Dev_proxima  Demanda_uni_equil  \n",
       "0              3  25.139999                0            0           1.386294  \n",
       "1              4  33.520000                0            0           1.609438  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 74180464 entries, 0 to 74180463\n",
      "Data columns (total 11 columns):\n",
      "Semana               uint8\n",
      "Agencia_ID           uint16\n",
      "Canal_ID             uint8\n",
      "Ruta_SAK             uint16\n",
      "Cliente_ID           uint32\n",
      "Producto_ID          uint16\n",
      "Venta_uni_hoy        uint16\n",
      "Venta_hoy            float32\n",
      "Dev_uni_proxima      uint32\n",
      "Dev_proxima          float32\n",
      "Demanda_uni_equil    float32\n",
      "dtypes: float32(3), uint16(4), uint32(2), uint8(2)\n",
      "memory usage: 2.3 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "FE.ReadHdf('train')\n",
    "FE.train.loc[:,'log_Demanda_uni_equil'] =  FE.train.loc[:,'Demanda_uni_equil'].apply(lambda x:round(np.expm1(x))).astype('uint32')\n",
    "FE.train.drop(\"Demanda_uni_equil\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Semana                   74180464\n",
       "Agencia_ID               74180464\n",
       "Canal_ID                 74180464\n",
       "Ruta_SAK                 74180464\n",
       "Cliente_ID               74180464\n",
       "Producto_ID              74180464\n",
       "Venta_uni_hoy            74180464\n",
       "Venta_hoy                74180464\n",
       "Dev_uni_proxima          74180464\n",
       "Dev_proxima              74180464\n",
       "log_Demanda_uni_equil    74180464\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE.train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FE.test = FE.train[ FE.train.Semana>=8 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FE.train = FE.train[ FE.train.Semana<8 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Venta_uni_hoy</th>\n",
       "      <th>Venta_hoy</th>\n",
       "      <th>Dev_uni_proxima</th>\n",
       "      <th>Dev_proxima</th>\n",
       "      <th>log_Demanda_uni_equil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53364883</th>\n",
       "      <td>8</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1212</td>\n",
       "      <td>4</td>\n",
       "      <td>33.520000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53364884</th>\n",
       "      <td>8</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1216</td>\n",
       "      <td>5</td>\n",
       "      <td>41.900002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID  \\\n",
       "53364883       8        1110         7      3301       15766         1212   \n",
       "53364884       8        1110         7      3301       15766         1216   \n",
       "\n",
       "          Venta_uni_hoy  Venta_hoy  Dev_uni_proxima  Dev_proxima  \\\n",
       "53364883              4  33.520000                0            0   \n",
       "53364884              5  41.900002                0            0   \n",
       "\n",
       "          log_Demanda_uni_equil  \n",
       "53364883                      4  \n",
       "53364884                      5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE.test[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Ruta_SAK</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>Venta_uni_hoy</th>\n",
       "      <th>Venta_hoy</th>\n",
       "      <th>Dev_uni_proxima</th>\n",
       "      <th>Dev_proxima</th>\n",
       "      <th>log_Demanda_uni_equil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1212</td>\n",
       "      <td>3</td>\n",
       "      <td>25.139999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>3301</td>\n",
       "      <td>15766</td>\n",
       "      <td>1216</td>\n",
       "      <td>4</td>\n",
       "      <td>33.520000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Semana  Agencia_ID  Canal_ID  Ruta_SAK  Cliente_ID  Producto_ID  \\\n",
       "0       3        1110         7      3301       15766         1212   \n",
       "1       3        1110         7      3301       15766         1216   \n",
       "\n",
       "   Venta_uni_hoy  Venta_hoy  Dev_uni_proxima  Dev_proxima  \\\n",
       "0              3  25.139999                0            0   \n",
       "1              4  33.520000                0            0   \n",
       "\n",
       "   log_Demanda_uni_equil  \n",
       "0                      3  \n",
       "1                      4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE.train[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train include Test datas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producto_ID Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testP = set(FE.test.Producto_ID)\n",
    "trainP = set(FE.train.Producto_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileP = set(pd.read_csv(\"../../input/producto_tabla.csv\").Producto_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1634\n",
      "1737\n",
      "2592\n"
     ]
    }
   ],
   "source": [
    "print len(testP)\n",
    "print len(trainP)\n",
    "print len(fileP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([])\n",
      "set([])\n",
      "62\n",
      "set([47123, 35713, 31618, 36995, 43398, 37639, 43193, 36873, 48138, 2060, 2062, 2064, 37011, 48023, 48232, 37402, 40987, 30595, 37149, 36131, 35240, 48297, 37469, 30877, 35761, 37363, 3509, 33208, 37667, 37690, 36671, 37403, 33735, 37576, 4169, 37578, 32207, 42192, 37587, 37590, 37689, 36699, 37468, 37242, 37470, 37264, 40929, 35301, 35304, 34665, 35306, 35308, 35310, 1277, 37379, 35441, 35442, 37139, 3446, 37241, 122, 43389])\n"
     ]
    }
   ],
   "source": [
    "print trainP - fileP\n",
    "print testP - fileP\n",
    "print len(testP - trainP)\n",
    "print testP - trainP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cliente_ID Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testCl = set(FE.test.Cliente_ID)\n",
    "trainCl = set(FE.train.Cliente_ID)\n",
    "fileCl = set(pd.read_csv(\"../../input/cliente_tabla.csv\").Cliente_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([])\n",
      "set([])\n",
      "18337\n"
     ]
    }
   ],
   "source": [
    "print trainCl - fileCl\n",
    "print testCl - fileCl\n",
    "print len(testCl - trainCl)\n",
    "#print testCl - trainCl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agencia_ID Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testA = set(FE.test.Agencia_ID)\n",
    "trainA = set(FE.train.Agencia_ID)\n",
    "fileA = set(pd.read_csv(\"../../input/town_state.csv\").Agencia_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([])\n",
      "set([])\n",
      "set([])\n"
     ]
    }
   ],
   "source": [
    "print trainA - fileA\n",
    "print testA - fileA\n",
    "print testA - trainA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ruta_SAK Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testR = set(FE.test.Ruta_SAK)\n",
    "trainR = set(FE.train.Ruta_SAK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "set([8193, 8196, 9228, 8205, 3096, 9757, 7198, 9759, 3108, 9774, 9266, 7737, 7743, 9286, 1099, 9229, 7762, 8278, 8633, 9816, 7777, 7780, 7270, 8295, 7271, 8813, 7280, 8041, 8843, 9871, 7314, 8131, 9877, 8860, 8867, 9383, 9386, 7855, 7368, 2226, 7861, 9928, 8910, 8913, 7382, 7387, 7901, 7397, 9958, 8937, 7402, 8429, 8950, 7935, 3968, 7938, 8463, 9504, 9435, 7478, 7480, 9532, 9534, 9023, 7493, 8518, 8520, 7497, 9548, 9552, 9554, 8508, 9582, 6004, 6005, 6008, 3962, 8059, 3964, 3965, 3967, 9600, 3969, 8173, 8087, 8088, 8091, 4001, 4003, 4004, 8103, 9129, 4012, 4013, 9657, 8126, 8643, 9157, 7113, 4558, 8146, 8170, 9810, 8691, 9206, 9722, 7338, 9727])\n",
      "596\n"
     ]
    }
   ],
   "source": [
    "print len(testR - trainR)\n",
    "print testR - trainR\n",
    "print len(trainR - testR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testCh = set(FE.test.Canal_ID)\n",
    "trainCh = set(FE.train.Canal_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([])\n",
      "set([])\n"
     ]
    }
   ],
   "source": [
    "print testCh - trainCh\n",
    "print trainCh - testCh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Producto_ID Cliente_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testPC = pd.unique(FE.test[['Producto_ID', 'Cliente_ID']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "liste = [1,412,32,12,567,12451,23,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.60233\n",
      "[  1.00000000e+00   4.11999969e+02   3.20000038e+01   1.19999990e+01\n",
      "   5.67000122e+02   1.24510049e+04   2.30000000e+01   1.00000000e+00\n",
      "   0.00000000e+00]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "liste32 =  np.log1p(liste).astype(\"float32\")\n",
    "print np.mean(liste32)\n",
    "print np.expm1(liste32)\n",
    "print np.array([ round(i) for i in   np.expm1(liste32)]) - liste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6035\n",
      "[  1.00000000e+00   4.12000000e+02   3.19843750e+01   1.19921875e+01\n",
      "   5.68000000e+02   1.24480000e+04   2.30000000e+01   1.00000000e+00\n",
      "   0.00000000e+00]\n",
      "[ 0.  0.  0.  0.  1. -3.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "liste32 =  np.log1p(liste).astype(\"float16\")\n",
    "print np.mean(liste32)\n",
    "print np.expm1(liste32)\n",
    "print np.array([ round(i) for i in   np.expm1(liste32)]) - liste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-561a3b289ebe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliste32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "round(np.expm1(liste32)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
