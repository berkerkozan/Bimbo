{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, datas (excels) should be downloaded from \n",
    "https://www.kaggle.com/c/grupo-bimbo-inventory-demand/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import nltk.corpus\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import datasets, linear_model\n",
    "import scipy.sparse as sps\n",
    "from scipy.sparse import coo_matrix, hstack, vstack, csr_matrix\n",
    "from scipy import io\n",
    "from datetime import datetime\n",
    "import gc\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Product Features\n",
    "\n",
    "Products on excel -> 9,Capuccino Moka 750g NES 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>brand</th>\n",
       "      <th>weight</th>\n",
       "      <th>pieces</th>\n",
       "      <th>short_name_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>NES</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>capuccin mok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>BIM</td>\n",
       "      <td>480.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>bimboll ext sajonjoli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>LON</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>burrit sincr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>TR</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>div tir mini doradit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73</td>\n",
       "      <td>BIM</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pan multigran linaz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Producto_ID brand  weight  pieces   short_name_processed\n",
       "1            9   NES   750.0     1.0           capuccin mok\n",
       "2           41   BIM   480.0     6.0  bimboll ext sajonjoli\n",
       "3           53   LON   170.0     1.0           burrit sincr\n",
       "4           72    TR    45.0     4.0   div tir mini doradit\n",
       "5           73   BIM   540.0     1.0    pan multigran linaz"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All columns can fit one line..\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "\n",
    "products = pd.read_csv(\"../../input/producto_tabla.csv\")\n",
    "products['short_name'] = products.NombreProducto.str.extract('^(\\D*)', expand=True)\n",
    "products['brand'] = products.NombreProducto.str.extract('^.+\\s(\\D+) \\d+$', expand=False)\n",
    "w = products.NombreProducto.str.extract('(\\d+)(Kg|g)', expand=True)\n",
    "w.head(3)\n",
    "products['weight'] = w[0].astype('float') * w[1].map({'Kg': 1000, 'g': 1})\n",
    "products['pieces'] = products.NombreProducto.str.extract('(\\d+)p ', expand=False).astype('float')\n",
    "products['short_name_processed'] = (products['short_name'].map(\n",
    "    lambda x: \" \".join([i for i in x.lower().split() if i not in nltk.corpus.stopwords.words(\"spanish\")])))\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "products['short_name_processed'] = (\n",
    "products['short_name_processed'].map(lambda x: \" \".join([stemmer.stem(i) for i in x.lower().split()])))\n",
    "products[\"pieces\"].fillna(1, inplace=True)\n",
    "products.drop(0,inplace=True)\n",
    "products.drop([\"short_name\",\"NombreProducto\"],axis=1,inplace=True)\n",
    "products.fillna(products.mean(),inplace=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types = {'Semana':np.uint8, 'Agencia_ID':np.uint16, 'Canal_ID':np.uint8,\n",
    "         'Cliente_ID':np.uint32, 'Producto_ID':np.uint16,\n",
    "         'Demanda_uni_equil':np.uint32}\n",
    "\n",
    "typesTest = {'id':np.uint32, 'Semana':np.uint8, 'Agencia_ID':np.uint16, 'Canal_ID':np.uint8,\n",
    "         'Cliente_ID':np.uint32, 'Producto_ID':np.uint16}\n",
    "\n",
    "train = pd.read_csv('../../input/train.csv', usecols=types.keys(), dtype=types)\n",
    "                                                      \n",
    "test = pd.read_csv('../../input/test.csv',usecols=typesTest.keys(), dtype=typesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74180464 entries, 0 to 74180463\n",
      "Data columns (total 6 columns):\n",
      "Semana               uint8\n",
      "Agencia_ID           uint16\n",
      "Canal_ID             uint8\n",
      "Cliente_ID           uint32\n",
      "Producto_ID          uint16\n",
      "Demanda_uni_equil    uint32\n",
      "dtypes: uint16(2), uint32(2), uint8(2)\n",
      "memory usage: 990.4 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6999251 entries, 0 to 6999250\n",
      "Data columns (total 6 columns):\n",
      "id             uint32\n",
      "Semana         uint8\n",
      "Agencia_ID     uint16\n",
      "Canal_ID       uint8\n",
      "Cliente_ID     uint32\n",
      "Producto_ID    uint16\n",
      "dtypes: uint16(2), uint32(2), uint8(2)\n",
      "memory usage: 93.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train.info(memory_usage=True))\n",
    "print(test.info(memory_usage=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate x and y of train data, append test to train to align them to have same sparse product features order. If they don't have the same column order, training gives false results.. Then merge this joined data with products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana</th>\n",
       "      <th>Agencia_ID</th>\n",
       "      <th>Canal_ID</th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>Producto_ID</th>\n",
       "      <th>brand</th>\n",
       "      <th>weight</th>\n",
       "      <th>pieces</th>\n",
       "      <th>short_name_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>15766</td>\n",
       "      <td>1212</td>\n",
       "      <td>BIM</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rol canel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>15766</td>\n",
       "      <td>1216</td>\n",
       "      <td>BIM</td>\n",
       "      <td>135.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rol glass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>15766</td>\n",
       "      <td>1238</td>\n",
       "      <td>BIM</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>panquecit got choc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>15766</td>\n",
       "      <td>1240</td>\n",
       "      <td>BIM</td>\n",
       "      <td>125.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>mantec vainill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>15766</td>\n",
       "      <td>1242</td>\n",
       "      <td>BIM</td>\n",
       "      <td>105.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>donit espolvor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Semana  Agencia_ID  Canal_ID  Cliente_ID  Producto_ID brand  weight  pieces short_name_processed\n",
       "0       3        1110         7       15766         1212   BIM   120.0     2.0            rol canel\n",
       "1       3        1110         7       15766         1216   BIM   135.0     2.0            rol glass\n",
       "2       3        1110         7       15766         1238   BIM   140.0     2.0   panquecit got choc\n",
       "3       3        1110         7       15766         1240   BIM   125.0     4.0       mantec vainill\n",
       "4       3        1110         7       15766         1242   BIM   105.0     6.0       donit espolvor"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testIds = test['id']\n",
    "test.drop(['id'],axis = 1,inplace=True)\n",
    "trainY = train.loc[:,'Demanda_uni_equil']\n",
    "trainX = train.loc[:,test.columns.values]\n",
    "trainTest = trainX.append(test,ignore_index=True)\n",
    "mergedTrainedTestProduct = trainTest.merge(products,on=\"Producto_ID\",how=\"left\")\n",
    "mergedTrainedTestProduct.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semana                    uint8\n",
      "Agencia_ID               uint16\n",
      "Canal_ID                  uint8\n",
      "Cliente_ID               uint32\n",
      "Producto_ID              uint16\n",
      "brand                    object\n",
      "weight                  float64\n",
      "pieces                  float64\n",
      "short_name_processed     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print mergedTrainedTestProduct.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garbage Collection to free memory.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowsize = test.shape[0]\n",
    "del trainTest,test,trainX\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use count vectorizer on short_name_processed column to create sparse count-word matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<81179715x542 sparse matrix of type '<type 'numpy.int8'>'\n",
       "\twith 145774286 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvec = CountVectorizer()\n",
    "shortname_sparse =  countvec.fit_transform(mergedTrainedTestProduct.short_name_processed)\n",
    "shortname_sparse = shortname_sparse.astype(np.int8)\n",
    "shortname_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145774286"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortname_sparse.data.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use count vectorizer on brand column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<81179715x33 sparse matrix of type '<type 'numpy.int8'>'\n",
       "\twith 81179715 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_sparse = countvec.fit_transform(mergedTrainedTestProduct.brand)\n",
    "brand_sparse = brand_sparse.astype(np.int8)\n",
    "brand_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping unnecessary columns from merged Train-Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 81179715 entries, 0 to 81179714\n",
      "Data columns (total 2 columns):\n",
      "weight    float16\n",
      "pieces    float16\n",
      "dtypes: float16(2)\n",
      "memory usage: 929.0 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>pieces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight  pieces\n",
       "0   120.0     2.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedTrainedTestProduct.drop(mergedTrainedTestProduct.columns[[0,1,2,3,4,5,8]],axis=1,inplace=True)\n",
    "mergedTrainedTestProduct = mergedTrainedTestProduct.astype(np.float16)\n",
    "print mergedTrainedTestProduct.info()\n",
    "mergedTrainedTestProduct.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging train-test data with brand and short name sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<81179715x577 sparse matrix of type '<type 'numpy.float32'>'\n",
       "\twith 389313431 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedTrainedTestProduct_sparse = coo_matrix(mergedTrainedTestProduct)\n",
    "\n",
    "del mergedTrainedTestProduct\n",
    "gc.collect()\n",
    "\n",
    "completeSparseData = hstack((mergedTrainedTestProduct_sparse, shortname_sparse,brand_sparse), format='csr')\n",
    "completeSparseData\n",
    "#io.mmwrite(\"../../sparse/completeSparseData.mtx\", completeSparseData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garbage Collection.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del  shortname_sparse, brand_sparse\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train-test to train and test again as sparse matrices.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6999251x577 sparse matrix of type '<type 'numpy.float32'>'\n",
       "\twith 33593313 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sparse = completeSparseData[0:train.shape[0]]\n",
    "test_sparse = completeSparseData[train.shape[0]:]\n",
    "test_sparse\n",
    "#io.mmwrite(\"../../sparse/test_sparse.mtx\", test_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Garbage Collection.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del completeSparseData\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root mean square logarithmic square evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle_eval(y, y0):\n",
    "    y0=y0.get_label()    \n",
    "    assert len(y) == len(y0)\n",
    "    return 'error',np.sqrt(np.mean(np.power(np.log1p(y)-np.log1p(y0), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using XGBoost to predict target variable while using custom evaluation metric above.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until train error hasn't decreased in 20 rounds.\n",
      "[0]\ttrain-error:1.363313\n",
      "[10]\ttrain-error:0.918269\n",
      "[20]\ttrain-error:0.792863\n",
      "[30]\ttrain-error:0.765580\n",
      "[40]\ttrain-error:0.768304\n",
      "[50]\ttrain-error:0.782227\n",
      "Stopping. Best iteration:\n",
      "[34]\ttrain-error:0.764148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "params = {}\n",
    "params['objective'] = \"reg:linear\"\n",
    "params['eta'] = 0.025\n",
    "params['max_depth'] = 5\n",
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 0.6\n",
    "params['silent'] = True\n",
    "\n",
    "test_preds = np.zeros(rowsize)\n",
    "\n",
    "xg_train = xgb.DMatrix(train_sparse, label=trainY)\n",
    "xg_test = xgb.DMatrix(test_sparse)\n",
    "\n",
    "del train_sparse,test_sparse,trainY\n",
    "gc.collect()\n",
    "\n",
    "watchlist = [(xg_train, 'train')]\n",
    "num_rounds = 100\n",
    "\n",
    "\n",
    "xgclassifier = xgb.train(params, xg_train, num_rounds, watchlist, feval = rmsle_eval, \n",
    "                         early_stopping_rounds= 20, verbose_eval = 10)\n",
    "#fold_preds = np.around(xgclassifier.predict(xg_test, ntree_limit=xgclassifier.best_iteration))\n",
    "fold_preds = np.rint(xgclassifier.predict(xg_test, ntree_limit=xgclassifier.best_iteration))\n",
    "\n",
    "test_preds += fold_preds\n",
    "\n",
    "submission = pd.DataFrame({'id':testIds, 'Demanda_uni_equil': test_preds})\n",
    "submission[[\"id\",\"Demanda_uni_equil\"]].to_csv('../../submissions/' + \n",
    "                                              datetime.now().strftime('%Y-%m-%d-%H-%M-%S') +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6999251 entries, 0 to 6999250\n",
      "Data columns (total 2 columns):\n",
      "Demanda_uni_equil    float64\n",
      "id                   uint32\n",
      "dtypes: float64(1), uint32(1)\n",
      "memory usage: 80.1 MB\n"
     ]
    }
   ],
   "source": [
    "submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}