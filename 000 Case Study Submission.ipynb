{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import nltk.corpus\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from ml_metrics import rmsle\n",
    "import xgboost as xgb\n",
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import datasets, linear_model\n",
    "import scipy.sparse as sps\n",
    "from scipy.sparse import coo_matrix, hstack, vstack, csr_matrix\n",
    "from scipy import io\n",
    "from datetime import datetime\n",
    "import gc\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Data...\n"
     ]
    }
   ],
   "source": [
    "print ('')\n",
    "print ('Loading Data...')\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "\n",
    "    labels = dtrain.get_label()\n",
    "    assert len(preds) == len(labels)\n",
    "    labels = labels.tolist()\n",
    "    preds = preds.tolist()\n",
    "    terms_to_sum = [(math.log(labels[i] + 1) - math.log(max(0,preds[i]) + 1)) ** 2.0 for i,pred in enumerate(labels)]\n",
    "    return 'error', (sum(terms_to_sum) * (1.0/len(preds))) ** 0.5\n",
    "\n",
    "train = pd.read_csv('../input/train_1000.csv', usecols=['Cliente_ID', 'Producto_ID', 'Demanda_uni_equil'])\n",
    "test = pd.read_csv('../input/test_1000.csv', usecols=['id', 'Cliente_ID', 'Producto_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product csv read complete\n",
      "('products shape:', (2592, 965))\n",
      "product features generated\n"
     ]
    }
   ],
   "source": [
    "# Process product data.\n",
    "\n",
    "products = pd.read_csv(\"../input/producto_tabla.csv\")\n",
    "\n",
    "print('product csv read complete')\n",
    "\n",
    "products['short_name'] = products.NombreProducto.str.extract('^(\\D*)', expand=False)\n",
    "# products['brand'] = products.NombreProducto.str.extract('^.+\\s(\\D+) \\d+$', expand=False)\n",
    "w = products.NombreProducto.str.extract('(\\d+)(Kg|g)', expand=True)\n",
    "products['weight'] = w[0].astype('float') * w[1].map({'Kg': 1000, 'g': 1})\n",
    "products['pieces'] = products.NombreProducto.str.extract('(\\d+)p ', expand=False).astype('float')\n",
    "\n",
    "products['short_name_processed'] = (products['short_name'].map(lambda x: \" \".join([i for i in x.lower().split() if i not in nltk.corpus.stopwords.words(\"spanish\")])))\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "products['short_name_processed'] = (\n",
    "products['short_name_processed'].map(lambda x: \" \".join([stemmer.stem(i) for i in x.lower().split()])))\n",
    "short_name_processed_list = products['short_name_processed'].unique()\n",
    "\n",
    "products = pd.concat([products.drop(['short_name', 'short_name_processed', 'NombreProducto'], axis=1), pd.get_dummies(short_name_processed_list)], axis=1)\n",
    "products = products.drop([''], axis=1)\n",
    "\n",
    "#products = products.astype(np.int8, )\n",
    "products.fillna(value=0, inplace=True)\n",
    "\n",
    "print('products shape:', products.shape)\n",
    "print('product features generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join data and products\n",
    "train = train.join(products, on='Producto_ID', lsuffix='_t')\n",
    "train.fillna(value=0, inplace=True)\n",
    "\n",
    "print('train data joined')\n",
    "\n",
    "test = test.join(products, on='Producto_ID', lsuffix='_t')\n",
    "test.fillna(value=0, inplace=True)\n",
    "\n",
    "print('test data joined')\n",
    "print('train shape', train.shape)\n",
    "print('test shape', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = test['id']\n",
    "test = test.drop(['id'],axis = 1)\n",
    "\n",
    "y = train['Demanda_uni_equil']\n",
    "X = train[test.columns.values]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1729)\n",
    "\n",
    "print ('Division_Set_Shapes:', X.shape, y.shape)\n",
    "print ('Validation_Set_Shapes:', X_train.shape, X_test.shape)\n",
    "\n",
    "params = {}\n",
    "params['objective'] = \"reg:linear\"\n",
    "params['eta'] = 0.025\n",
    "params['max_depth'] = 5\n",
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 0.6\n",
    "params['silent'] = True\n",
    "\n",
    "print ('')\n",
    "\n",
    "test_preds = np.zeros(test.shape[0])\n",
    "xg_train = xgb.DMatrix(X_train, label=y_train)\n",
    "xg_test = xgb.DMatrix(X_test)\n",
    "\n",
    "watchlist = [(xg_train, 'train')]\n",
    "num_rounds = 100\n",
    "\n",
    "xgclassifier = xgb.train(params, xg_train, num_rounds, watchlist, feval = evalerror, early_stopping_rounds= 20, verbose_eval = 10)\n",
    "preds = xgclassifier.predict(xg_test, ntree_limit=xgclassifier.best_iteration)\n",
    "\n",
    "print ('RMSLE Score:', rmsle(y_test, preds))\n",
    "\n",
    "fxg_test = xgb.DMatrix(test)\n",
    "fold_preds = np.around(xgclassifier.predict(fxg_test, ntree_limit=xgclassifier.best_iteration), decimals = 1)\n",
    "test_preds += fold_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':ids, 'Demanda_uni_equil': test_preds})\n",
    "\n",
    "submission[[\"id\",\"Demanda_uni_equil\"]].to_csv('../submissions/' +\n",
    "                                              datetime.now().strftime('%Y-%m-%d-%H-%M-%S') +'.csv', index=False)\n",
    "\n",
    "print ('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
