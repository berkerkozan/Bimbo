{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from ml_metrics import rmsle\n",
    "import xgboost as xgb\n",
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import datasets, linear_model\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_features(bimbo_dataframe):\n",
    "  \"\"\"This function takes an input dataframe and returns a version of it that has\n",
    "  various features selected and pre-processed.  The input dataframe contains\n",
    "  data from the california_housing data set.\"\"\"\n",
    "  # Select fewer columns to allow training a bit faster.\n",
    "  output_features = bimbo_dataframe[\n",
    "    [\"d1\",\n",
    "     \"d2\",\n",
    "     \"d3\",\n",
    "     \"d4\",\n",
    "     \"d5\",\n",
    "     \"d6\",\n",
    "     \"p_total_demand\",\n",
    "     \"total_demand\"]].copy()\n",
    "  return output_features\n",
    "\n",
    "\n",
    "def preprocess_targets(bimbo_dataframe):\n",
    "  \"\"\"This function selects and potentially transforms the output target from\n",
    "  an input dataframe containing data from the california_housing data set.\n",
    "  The object returned is a pandas Series.\"\"\"\n",
    "  output_targets = pd.DataFrame()\n",
    "  # Scale the target to be in units of thousands of dollars.\n",
    "  output_targets[\"Demanda_uni_equil\"] = (\n",
    "    bimbo_dataframe[\"Demanda_uni_equil\"])\n",
    "  return output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_joined = pd.read_csv('../input/train_1000000_alld_totals.csv')\n",
    "test_joined = pd.read_csv('../input/test_1000000_alld_totals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomize the data before selecting train / validation splits.\n",
    "raw_training_df = train_joined.reindex(np.random.permutation(\n",
    "  train_joined.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_examples = preprocess_features(raw_training_df.head(100000))\n",
    "training_targets = preprocess_targets(raw_training_df.head(100000))\n",
    "\n",
    "validation_examples = preprocess_features(raw_training_df.tail(500))\n",
    "validation_targets = preprocess_targets(raw_training_df.tail(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_examples=training_examples.replace(-999,np.NaN)\n",
    "validation_examples=training_examples.replace(-999,np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples summary:\n",
      "                 d1            d2            d3            d4            d5  \\\n",
      "count  85162.000000  70330.000000  55896.000000  42091.000000  28287.000000   \n",
      "mean       6.033454      4.616053      4.518284      4.425578      4.348110   \n",
      "std      159.630247     16.348238     17.292253     17.025387     16.123085   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        2.000000      1.000000      0.000000      0.000000      0.000000   \n",
      "75%        5.000000      4.000000      4.000000      4.000000      4.000000   \n",
      "max    46326.000000   1820.000000   2008.000000   1706.000000    732.000000   \n",
      "\n",
      "                 d6  p_total_demand  total_demand  \n",
      "count  14142.000000    1.000000e+05  1.000000e+05  \n",
      "mean       4.072974    4.899412e+06  1.909206e+03  \n",
      "std       15.329737    5.343123e+06  8.005744e+04  \n",
      "min        0.000000    0.000000e+00  0.000000e+00  \n",
      "25%        0.000000    8.954640e+05  3.490000e+02  \n",
      "50%        0.000000    2.940053e+06  7.720000e+02  \n",
      "75%        4.000000    7.229285e+06  1.589000e+03  \n",
      "max     1012.000000    2.372867e+07  1.786622e+07  \n",
      "Validation examples summary:\n",
      "                 d1            d2            d3            d4            d5  \\\n",
      "count  85162.000000  70330.000000  55896.000000  42091.000000  28287.000000   \n",
      "mean       6.033454      4.616053      4.518284      4.425578      4.348110   \n",
      "std      159.630247     16.348238     17.292253     17.025387     16.123085   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        2.000000      1.000000      0.000000      0.000000      0.000000   \n",
      "75%        5.000000      4.000000      4.000000      4.000000      4.000000   \n",
      "max    46326.000000   1820.000000   2008.000000   1706.000000    732.000000   \n",
      "\n",
      "                 d6  p_total_demand  total_demand  \n",
      "count  14142.000000    1.000000e+05  1.000000e+05  \n",
      "mean       4.072974    4.899412e+06  1.909206e+03  \n",
      "std       15.329737    5.343123e+06  8.005744e+04  \n",
      "min        0.000000    0.000000e+00  0.000000e+00  \n",
      "25%        0.000000    8.954640e+05  3.490000e+02  \n",
      "50%        0.000000    2.940053e+06  7.720000e+02  \n",
      "75%        4.000000    7.229285e+06  1.589000e+03  \n",
      "max     1012.000000    2.372867e+07  1.786622e+07  \n",
      "Training targets summary:\n",
      "       Demanda_uni_equil\n",
      "count      100000.000000\n",
      "mean            7.387680\n",
      "std           151.875623\n",
      "min             0.000000\n",
      "25%             2.000000\n",
      "50%             3.000000\n",
      "75%             6.000000\n",
      "max         47722.000000\n",
      "Validation targets summary:\n",
      "       Demanda_uni_equil\n",
      "count          500.00000\n",
      "mean             6.75200\n",
      "std             12.75413\n",
      "min              0.00000\n",
      "25%              2.00000\n",
      "50%              4.00000\n",
      "75%              6.00000\n",
      "max            184.00000\n"
     ]
    }
   ],
   "source": [
    "# Sanity check that we've done the right thing.\n",
    "print(\"Training examples summary:\")\n",
    "print(training_examples.describe())\n",
    "print(\"Validation examples summary:\")\n",
    "print(validation_examples.describe())\n",
    "\n",
    "print(\"Training targets summary:\")\n",
    "print(training_targets.describe())\n",
    "print(\"Validation targets summary:\")\n",
    "print(validation_targets.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1 = tf.contrib.layers.real_valued_column(\"d1\")\n",
    "d2 = tf.contrib.layers.real_valued_column(\"d2\")\n",
    "d3 = tf.contrib.layers.real_valued_column(\"d3\")\n",
    "d4 = tf.contrib.layers.real_valued_column(\"d4\")\n",
    "d5 = tf.contrib.layers.real_valued_column(\"d5\")\n",
    "d6 = tf.contrib.layers.real_valued_column(\"d6\")\n",
    "\n",
    "p_total_demand = tf.contrib.layers.real_valued_column(\"p_total_demand\")\n",
    "total_demand = tf.contrib.layers.real_valued_column(\"total_demand\")\n",
    "\n",
    "\n",
    "feature_columns=set([\n",
    "  d1,\n",
    "  d2,\n",
    "  d3,\n",
    "  d4,\n",
    "  d5,\n",
    "  d6,\n",
    "  p_total_demand,\n",
    "  total_demand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#@test {\"output\": \"ignore\"}\n",
    "\n",
    "def _input_fn(examples_df, targets_df):\n",
    "  # Converts a pair of examples/targets DataFrames to Tensors. The Tensors are\n",
    "  # reshaped into (N,1) where N is number of examples in the DataFrames.\n",
    "  # -1 is a special value to tf.reshape that means \"replace me with whatever\n",
    "  # size allows all the input values to fit into the output tensor.\"\n",
    "  features = {}\n",
    "  for column_name in examples_df.keys():\n",
    "    features[column_name] = tf.to_float(\n",
    "      tf.reshape(tf.constant(examples_df[column_name].values), [-1,1]))\n",
    "  label_tensor = tf.to_float(\n",
    "    tf.reshape(tf.constant(targets_df[targets_df.keys()[0]].values), [-1,1]))\n",
    "\n",
    "  # Return a dict of feature Tensors and label Tensor.\n",
    "  return features, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "RMSE (on training data):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Model diverged with loss = NaN.\n"
     ]
    },
    {
     "ename": "NanLossDuringTrainingError",
     "evalue": "NaN loss during training.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNanLossDuringTrainingError\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-6457368bff3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m   linear_regressor.fit(\n\u001b[0;32m     27\u001b[0m     \u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_period\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m   )\n\u001b[0;32m     30\u001b[0m   training_predictions = linear_regressor.predict(\n",
      "\u001b[1;32m/home/can/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, input_fn, steps, batch_size, monitors)\u001b[0m\n\u001b[0;32m    180\u001b[0m                              \u001b[0mfeed_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m                              \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m                              monitors=monitors)\n\u001b[0m\u001b[0;32m    183\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/can/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.pyc\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, steps, feed_fn, init_op, init_feed_fn, init_fn, device_fn, monitors, log_every_steps, fail_on_nan_loss)\u001b[0m\n\u001b[0;32m    482\u001b[0m           \u001b[0mmax_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m           \u001b[0mfail_on_nan_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfail_on_nan_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m           monitors=monitors)\n\u001b[0m\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extract_metric_update_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/can/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(graph, output_dir, train_op, loss_op, global_step_tensor, init_op, init_feed_dict, init_fn, log_every_steps, supervisor_is_chief, supervisor_master, supervisor_save_model_secs, supervisor_save_summaries_steps, feed_fn, max_steps, fail_on_nan_loss, monitors)\u001b[0m\n\u001b[0;32m    326\u001b[0m       \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mexcinfo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m           \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mexcinfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/can/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(graph, output_dir, train_op, loss_op, global_step_tensor, init_op, init_feed_dict, init_fn, log_every_steps, supervisor_is_chief, supervisor_master, supervisor_save_model_secs, supervisor_save_summaries_steps, feed_fn, max_steps, fail_on_nan_loss, monitors)\u001b[0m\n\u001b[0;32m    262\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mfail_on_nan_loss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailure_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mNanLossDuringTrainingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailure_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNanLossDuringTrainingError\u001b[0m: NaN loss during training."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#@test {\"output\": \"ignore\", \"timeout\": 180}\n",
    "\n",
    "LEARNING_RATE = 0.0000001  #@param\n",
    "STEPS = 500000  #@param\n",
    "# No batch size - train expects input_fn to batch the data, but\n",
    "# here we'll just train on the full set for simplicity.\n",
    "periods = 100\n",
    "steps_per_period = STEPS / periods\n",
    "\n",
    "# Build a linear regression model, making sure we pass\n",
    "# our explicit list of feature columns.\n",
    "\n",
    "#linear_regressor = tf.contrib.learn.LinearRegressor(feature_columns=feature_columns, optimizer=tf.train.FtrlOptimizer(LEARNING_RATE))\n",
    "\n",
    "linear_regressor = tf.contrib.learn.LinearRegressor(feature_columns=feature_columns, optimizer=tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE),)\n",
    "\n",
    "# Train and evaluate the model.\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "print(\"Training model...\")\n",
    "print(\"RMSE (on training data):\")\n",
    "training_rmse = []\n",
    "validation_rmse = []\n",
    "for period in range (0, periods):\n",
    "  # Train the model, starting from the prior state.\n",
    "  linear_regressor.fit(\n",
    "    input_fn=lambda: _input_fn(training_examples, training_targets),\n",
    "    steps=steps_per_period\n",
    "  )\n",
    "  training_predictions = linear_regressor.predict(\n",
    "    input_fn=lambda: _input_fn(training_examples, training_targets))\n",
    "  validation_predictions = linear_regressor.predict(\n",
    "    input_fn=lambda: _input_fn(validation_examples, validation_targets))\n",
    "  training_root_mean_squared_error = math.sqrt(\n",
    "    metrics.mean_squared_error(training_predictions, training_targets))\n",
    "  validation_root_mean_squared_error = math.sqrt(\n",
    "    metrics.mean_squared_error(validation_predictions, validation_targets))\n",
    "  print \"  period %02d : %0.2f\" % (period, training_root_mean_squared_error)\n",
    "  training_rmse.append(training_root_mean_squared_error)\n",
    "  validation_rmse.append(validation_root_mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.ylabel(\"RMSE\")\n",
    "plt.xlabel(\"Periods\")\n",
    "plt.title(\"Root Mean Squared Error vs. Periods\")\n",
    "plt.tight_layout()\n",
    "plt.plot(training_rmse, label=\"training\")\n",
    "plt.plot(validation_rmse, label=\"validation\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Final RMSE (on training data): %0.2f\" % (\n",
    "  training_root_mean_squared_error))\n",
    "print(\"Final RMSE (on validation data): %0.2f\" % (\n",
    "  validation_root_mean_squared_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}